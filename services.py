"""Ğ’Ğ½ĞµÑˆĞ½Ğ¸Ğµ ÑĞµÑ€Ğ²Ğ¸ÑÑ‹: Google Sheets (ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³), Google Drive (Ñ„Ğ¾Ñ‚Ğ¾), Telegram, N8N."""

import asyncio
import logging
import re
import time
import json
from functools import lru_cache

import httpx

from config import (
    GOOGLE_CREDENTIALS_FILE,
    GOOGLE_DRIVE_PHOTOS_FOLDER_ID,
    CATALOG_SHEETS_ID,
    TELEGRAM_ALERT_BOT_TOKEN,
    TELEGRAM_ALERT_CHAT_ID,
    N8N_ORDER_WEBHOOK_URL,
    ORDER_GROUP_CHAT_ID,
)

logger = logging.getLogger(__name__)

# â”€â”€ Google Auth â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_google_service_sheets = None
_google_service_drive = None


def _get_google_creds():
    from google.oauth2 import service_account
    return service_account.Credentials.from_service_account_file(
        GOOGLE_CREDENTIALS_FILE,
        scopes=[
            "https://www.googleapis.com/auth/spreadsheets.readonly",
            "https://www.googleapis.com/auth/drive.readonly",
        ],
    )


def _sheets_service():
    global _google_service_sheets
    if _google_service_sheets is None:
        from googleapiclient.discovery import build
        _google_service_sheets = build("sheets", "v4", credentials=_get_google_creds())
    return _google_service_sheets


def _drive_service():
    global _google_service_drive
    if _google_service_drive is None:
        from googleapiclient.discovery import build
        _google_service_drive = build("drive", "v3", credentials=_get_google_creds())
    return _google_service_drive


# â”€â”€ ĞšĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³ (Google Sheets) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_catalog_cache: list[dict] = []
_catalog_cache_ts: float = 0
CATALOG_TTL = 300  # 5 Ğ¼Ğ¸Ğ½


async def get_catalog() -> list[dict]:
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ² Ğ¸Ğ· Google Sheets. ĞšÑÑˆ 5 Ğ¼Ğ¸Ğ½.

    ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒĞµÑ‚ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸ Sheet â†’ ĞµĞ´Ğ¸Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚:
      product_name, category, price, colors, description, sizes, quantity
    Ğ Ğ°Ğ·Ğ¼ĞµÑ€Ñ‹ Ğ°Ğ³Ñ€ĞµĞ³Ğ¸Ñ€ÑƒÑÑ‚ÑÑ Ğ¸Ğ· Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ñ… ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº (35-42) Ñ ĞºĞ¾Ğ»-Ğ²Ğ¾Ğ¼ > 0.
    """
    global _catalog_cache, _catalog_cache_ts
    if _catalog_cache and (time.time() - _catalog_cache_ts) < CATALOG_TTL:
        return _catalog_cache

    if not CATALOG_SHEETS_ID:
        logger.warning("CATALOG_SHEETS_ID not set")
        return _catalog_cache

    # ĞœĞ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ² Sheet â†’ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ¼ĞµĞ½Ğ°
    _HEADER_MAP = {
        "name": "product_name",
        "Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ": "product_name",
        "product_name": "product_name",
        "category": "category",
        "ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ": "category",
        "price": "price",
        "Ñ†ĞµĞ½Ğ°": "price",
        "colors": "colors",
        "Ñ†Ğ²ĞµÑ‚Ğ°": "colors",
        "color": "colors",
        "Ñ†Ğ²ĞµÑ‚": "colors",
        "descriptions": "description",
        "description": "description",
        "Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ": "description",
        "sizes": "sizes",
        "Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ñ‹": "sizes",
        "quantity": "quantity",
        "ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾": "quantity",
        "ĞºĞ¾Ğ»-Ğ²Ğ¾": "quantity",
        "ĞºĞ¾Ğ»-Ğ²Ğ¾ ÑÑƒĞ¼ĞºĞ¸": "bag_quantity",
        "ÑĞ¿ĞµÑ† Ñ†ĞµĞ½Ğ°": "special_price",
        "ÑĞ¿ĞµÑ†. Ñ†ĞµĞ½Ğ°": "special_price",
        "special_price": "special_price",
    }
    # ĞšĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸-Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ñ‹ (Ñ‡Ğ¸ÑĞ»Ğ° = Ğ½Ğ¾Ğ¼ĞµÑ€Ğ° Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ¾Ğ² Ğ¾Ğ±ÑƒĞ²Ğ¸)
    _SIZE_COLUMNS = {"35", "36", "37", "38", "39", "40", "41", "42", "43", "44"}

    try:
        def _load():
            svc = _sheets_service()
            result = svc.spreadsheets().values().get(
                spreadsheetId=CATALOG_SHEETS_ID,
                range="A:Z",
            ).execute()
            rows = result.get("values", [])
            if len(rows) < 2:
                return []
            raw_headers = [h.strip() for h in rows[0]]
            items = []
            for row in rows[1:]:
                raw = {}
                for i, h in enumerate(raw_headers):
                    raw[h] = row[i].strip() if i < len(row) else ""

                # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼ Ğ¿Ğ¾Ğ»Ñ
                item = {}
                size_avail = {}  # Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ â†’ ĞºĞ¾Ğ»-Ğ²Ğ¾
                for h, val in raw.items():
                    h_lower = h.lower()
                    if h_lower in _SIZE_COLUMNS:
                        try:
                            qty = int(val) if val else 0
                        except ValueError:
                            qty = 0
                        if qty > 0:
                            size_avail[h_lower] = qty
                    elif h_lower in _HEADER_MAP:
                        item[_HEADER_MAP[h_lower]] = val

                # ĞĞ³Ñ€ĞµĞ³Ğ¸Ñ€ÑƒĞµĞ¼ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ñ‹
                if size_avail:
                    item["sizes"] = ", ".join(sorted(size_avail.keys(), key=int))
                    item["quantity"] = str(sum(size_avail.values()))
                elif not item.get("sizes"):
                    # Ğ”Ğ»Ñ ÑÑƒĞ¼Ğ¾Ğº/Ğ°ĞºÑĞµÑÑÑƒĞ°Ñ€Ğ¾Ğ² â€” Ğ±ĞµÑ€Ñ‘Ğ¼ bag_quantity
                    bag_qty = item.pop("bag_quantity", "0")
                    item["sizes"] = ""
                    if not item.get("quantity"):
                        item["quantity"] = bag_qty
                item.pop("bag_quantity", None)

                if item.get("product_name"):
                    items.append(item)
            return items

        _catalog_cache = await asyncio.get_event_loop().run_in_executor(None, _load)
        _catalog_cache_ts = time.time()
        logger.info(f"Catalog loaded: {len(_catalog_cache)} items")
    except Exception as e:
        logger.error(f"Failed to load catalog: {e}")

    return _catalog_cache


def format_catalog_for_prompt(catalog: list[dict]) -> str:
    """Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³Ğ° Ğ´Ğ»Ñ system prompt."""
    if not catalog:
        return "ĞšĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³ Ğ¿ÑƒÑÑ‚ â€” ÑĞºĞ°Ğ¶Ğ¸ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ñƒ, Ñ‡Ñ‚Ğ¾ ÑĞµĞ¹Ñ‡Ğ°Ñ ÑƒÑ‚Ğ¾Ñ‡Ğ½Ğ¸ÑˆÑŒ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ."
    lines = []
    for item in catalog:
        name = item.get("product_name", "?")
        category = item.get("category", "")
        price = item.get("price", "")
        sizes = item.get("sizes", "")
        colors = item.get("colors", "")
        qty = item.get("quantity", "")
        line = f"- {name}"
        if category:
            line += f" ({category})"
        if price:
            line += f" | {price}"
        if sizes:
            line += f" | Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ñ‹: {sizes}"
        if colors:
            line += f" | Ñ†Ğ²ĞµÑ‚Ğ°: {colors}"
        if qty:
            line += f" | Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ: {qty}"
        special_price = item.get("special_price", "")
        if special_price:
            line += f" | ÑĞ¿ĞµÑ†Ñ†ĞµĞ½Ğ°: {special_price} (Ğ´Ğ¾ 1 Ğ¼Ğ°Ñ€Ñ‚Ğ°)"
        lines.append(line)
    return "\n".join(lines)


# â”€â”€ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ñ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def check_stock(product: str, size: str = "", color: str = "") -> dict:
    """ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ° Ğ² ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³Ğµ.

    Ğ˜Ñ‰ĞµÑ‚ Ğ¿Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ¸ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ° Ğ¸ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸ (Ñ‚ÑƒÑ„Ğ»Ğ¸, ÑÑƒĞ¼ĞºĞ°, ĞºÑ€Ğ¾ÑÑĞ¾Ğ²ĞºĞ¸ Ğ¸ Ñ‚.Ğ´.).
    """
    catalog = await get_catalog()
    product_lower = product.lower()
    matches = []
    for item in catalog:
        name = item.get("product_name", "").lower()
        category = item.get("category", "").lower()
        # ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ¸ Ğ¸Ğ»Ğ¸ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸
        if (product_lower in name or name in product_lower
                or product_lower in category or category in product_lower):
            matches.append(item)

    if not matches:
        return {"available": False, "message": f"Ğ¢Ğ¾Ğ²Ğ°Ñ€ '{product}' Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ² ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³Ğµ"}

    # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ²ÑĞµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğµ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ñ‹
    available_items = []
    for item in matches:
        item_sizes = item.get("sizes", "").lower()
        item_colors = item.get("colors", "").lower().strip()
        item_qty = item.get("quantity", "0")

        size_ok = not size or size.lower() in item_sizes
        color_ok = not color or color.lower() in item_colors
        in_stock = str(item_qty).strip() not in ("0", "")

        if size_ok and color_ok and in_stock:
            available_items.append({
                "product": item.get("product_name"),
                "price": item.get("price", ""),
                "special_price": item.get("special_price", ""),
                "sizes": item.get("sizes", ""),
                "colors": item.get("colors", ""),
            })

    if available_items:
        return {"available": True, "items": available_items}

    return {"available": False, "message": f"Ğ¢Ğ¾Ğ²Ğ°Ñ€ '{product}' Ğ² ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ğ¾Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚"}


# â”€â”€ Ğ¤Ğ¾Ñ‚Ğ¾ (Google Drive) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_photo_index: dict[str, list[dict]] = {}  # product_key -> [{file_id, name}]
_photo_bytes: dict[str, bytes] = {}  # file_id -> image bytes
_photo_index_ts: float = 0
PHOTO_INDEX_TTL = 1800  # 30 Ğ¼Ğ¸Ğ½


def get_photo_bytes(file_id: str) -> bytes | None:
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ±Ğ°Ğ¹Ñ‚Ñ‹ Ñ„Ğ¾Ñ‚Ğ¾ Ğ¸Ğ· in-memory ĞºÑÑˆĞ°."""
    return _photo_bytes.get(file_id)


async def load_photo_index():
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ¸Ğ½Ğ´ĞµĞºÑ + Ğ±Ğ°Ğ¹Ñ‚Ñ‹ Ğ²ÑĞµÑ… Ñ„Ğ¾Ñ‚Ğ¾ Ğ¸Ğ· Google Drive Ğ² Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ. Retry Ğ´Ğ¾ 3 Ñ€Ğ°Ğ·."""
    global _photo_index, _photo_bytes, _photo_index_ts
    if _photo_index and (time.time() - _photo_index_ts) < PHOTO_INDEX_TTL:
        return _photo_index

    if not GOOGLE_DRIVE_PHOTOS_FOLDER_ID:
        return _photo_index

    def _load():
        from io import BytesIO
        from googleapiclient.http import MediaIoBaseDownload

        svc = _drive_service()

        # 1. Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ¸Ğ½Ğ´ĞµĞºÑ (Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ)
        folders = svc.files().list(
            q=f"'{GOOGLE_DRIVE_PHOTOS_FOLDER_ID}' in parents and mimeType='application/vnd.google-apps.folder'",
            fields="files(id, name)",
            pageSize=200,
        ).execute().get("files", [])

        index = {}
        all_file_ids = []

        if folders:
            for folder in folders:
                photos = svc.files().list(
                    q=f"'{folder['id']}' in parents and mimeType contains 'image/'",
                    fields="files(id, name)",
                    pageSize=50,
                ).execute().get("files", [])
                if photos:
                    key = folder["name"].lower().strip()
                    index[key] = [{"file_id": p["id"], "name": p["name"]} for p in photos]
                    all_file_ids.extend(p["id"] for p in photos)
        else:
            images = svc.files().list(
                q=f"'{GOOGLE_DRIVE_PHOTOS_FOLDER_ID}' in parents and mimeType contains 'image/'",
                fields="files(id, name)",
                pageSize=500,
            ).execute().get("files", [])
            for img in images:
                name = img["name"]
                base = re.sub(r'\.\w+$', '', name)
                key = re.sub(r'\s+\d+$', '', base).lower().strip()
                if key not in index:
                    index[key] = []
                index[key].append({"file_id": img["id"], "name": name})
                all_file_ids.append(img["id"])

        # 2. Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ²ÑĞµ Ñ„Ğ¾Ñ‚Ğ¾ Ğ² Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ (Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾, Ğ¾Ğ´Ğ¸Ğ½ Drive service)
        bytes_cache = {}
        for fid in all_file_ids:
            try:
                request = svc.files().get_media(fileId=fid)
                buf = BytesIO()
                downloader = MediaIoBaseDownload(buf, request)
                done = False
                while not done:
                    _, done = downloader.next_chunk()
                bytes_cache[fid] = buf.getvalue()
            except Exception as e:
                logger.warning(f"Failed to download photo {fid}: {e}")

        return index, bytes_cache

    max_attempts = 3
    for attempt in range(1, max_attempts + 1):
        try:
            index, bytes_cache = await asyncio.get_event_loop().run_in_executor(None, _load)
            if index:
                _photo_index = index
                _photo_bytes = bytes_cache
                _photo_index_ts = time.time()
                total_mb = sum(len(b) for b in bytes_cache.values()) / 1024 / 1024
                logger.info(f"Photo cache loaded: {len(index)} products, {len(bytes_cache)} files, {total_mb:.1f} MB")
                return _photo_index
            else:
                logger.warning(f"Photo index empty (attempt {attempt}/{max_attempts})")
                if attempt < max_attempts:
                    await asyncio.sleep(2 * attempt)
        except Exception as e:
            logger.error(f"Failed to load photo index (attempt {attempt}/{max_attempts}): {e}")
            if attempt < max_attempts:
                await asyncio.sleep(2 * attempt)

    logger.error("Photo index: all attempts failed, returning cached or empty")
    return _photo_index


_RUSSIAN_COLORS = {
    "Ñ‡ĞµÑ€Ğ½Ğ°Ñ", "Ñ‡ĞµÑ€Ğ½Ñ‹Ğµ", "Ñ‡Ñ‘Ñ€Ğ½Ğ°Ñ", "Ñ‡Ñ‘Ñ€Ğ½Ñ‹Ğµ", "Ñ‡ĞµÑ€Ğ½Ñ‹Ğ¹",
    "Ğ±ĞµĞ»Ğ°Ñ", "Ğ±ĞµĞ»Ñ‹Ğµ", "Ğ±ĞµĞ»Ñ‹Ğ¹",
    "Ğ±ĞµĞ¶ĞµĞ²Ğ°Ñ", "Ğ±ĞµĞ¶ĞµĞ²Ñ‹Ğµ", "Ğ±ĞµĞ¶ĞµĞ²Ñ‹Ğ¹",
    "Ñ€Ğ¾Ğ·Ğ¾Ğ²Ğ°Ñ", "Ñ€Ğ¾Ğ·Ğ¾Ğ²Ñ‹Ğµ", "Ñ€Ğ¾Ğ·Ğ¾Ğ²Ñ‹Ğ¹",
    "ĞºÑ€Ğ°ÑĞ½Ğ°Ñ", "ĞºÑ€Ğ°ÑĞ½Ñ‹Ğµ", "ĞºÑ€Ğ°ÑĞ½Ñ‹Ğ¹",
    "ÑĞ¸Ğ½ÑÑ", "ÑĞ¸Ğ½Ğ¸Ğµ", "ÑĞ¸Ğ½Ğ¸Ğ¹",
    "Ğ³Ğ¾Ğ»ÑƒĞ±Ğ°Ñ", "Ğ³Ğ¾Ğ»ÑƒĞ±Ñ‹Ğµ", "Ğ³Ğ¾Ğ»ÑƒĞ±Ğ¾Ğ¹",
    "ÑĞµÑ€Ğ°Ñ", "ÑĞµÑ€Ñ‹Ğµ", "ÑĞµÑ€Ñ‹Ğ¹",
    "Ğ·ĞµĞ»ĞµĞ½Ğ°Ñ", "Ğ·ĞµĞ»ĞµĞ½Ñ‹Ğµ",
    "ĞºĞ¾Ñ€Ğ¸Ñ‡Ğ½ĞµĞ²Ğ°Ñ", "ĞºĞ¾Ñ€Ğ¸Ñ‡Ğ½ĞµĞ²Ñ‹Ğµ",
    "Ğ±Ğ¾Ñ€Ğ´Ğ¾Ğ²Ğ°Ñ", "Ğ±Ğ¾Ñ€Ğ´Ğ¾Ğ²Ñ‹Ğµ",
    "ÑĞµÑ€ĞµĞ±Ñ€ÑĞ½Ğ°Ñ", "ÑĞµÑ€ĞµĞ±Ñ€ÑĞ½Ñ‹Ğµ", "ÑĞµÑ€ĞµĞ±Ñ€Ğ¸ÑÑ‚Ğ°Ñ", "ÑĞµÑ€ĞµĞ±Ñ€Ğ¸ÑÑ‚Ñ‹Ğµ",
    "Ğ·Ğ¾Ğ»Ğ¾Ñ‚Ğ°Ñ", "Ğ·Ğ¾Ğ»Ğ¾Ñ‚Ñ‹Ğµ", "Ğ·Ğ¾Ğ»Ğ¾Ñ‚Ğ¸ÑÑ‚Ğ°Ñ", "Ğ·Ğ¾Ğ»Ğ¾Ñ‚Ğ¸ÑÑ‚Ñ‹Ğµ",
    "Ğ¼Ğ¾Ğ»Ğ¾Ñ‡Ğ½Ğ°Ñ", "Ğ¼Ğ¾Ğ»Ğ¾Ñ‡Ğ½Ñ‹Ğµ",
    "Ğ¿ÑƒĞ´Ñ€Ğ¾Ğ²Ğ°Ñ", "Ğ¿ÑƒĞ´Ñ€Ğ¾Ğ²Ñ‹Ğµ",
    "Ğ½ÑĞ´Ğ¾Ğ²Ğ°Ñ", "Ğ½ÑĞ´Ğ¾Ğ²Ñ‹Ğµ",
}


def _extract_color_from_filename(filename: str) -> str:
    """Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ Ñ€ÑƒÑÑĞºĞ¾Ğµ ÑĞ»Ğ¾Ğ²Ğ¾ Ñ†Ğ²ĞµÑ‚Ğ° Ğ¸Ğ· Ğ¸Ğ¼ĞµĞ½Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ğ° Ñ„Ğ¾Ñ‚Ğ¾."""
    base = re.sub(r'\.\w+$', '', filename)
    for word in base.lower().split():
        if word in _RUSSIAN_COLORS:
            return word
    return ""


def _make_photo_caption(product_key: str, catalog: list[dict], color: str = "") -> str:
    """Ğ¡Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑÑŒ Ğº Ñ„Ğ¾Ñ‚Ğ¾: Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ° + Ñ†Ğ²ĞµÑ‚."""
    display_name = product_key.title()

    # ĞŸĞ¾Ğ¸ÑĞº Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³Ğµ Ğ¿Ğ¾ Ğ¿ĞµÑ€ĞµÑĞµÑ‡ĞµĞ½Ğ¸Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²
    key_tokens = set(product_key.lower().split())
    best_overlap = 0
    for item in catalog:
        name = item.get("product_name", "").lower()
        name_tokens = set(name.split())
        overlap = len(key_tokens & name_tokens)
        if overlap > best_overlap:
            best_overlap = overlap
            display_name = item.get("product_name", display_name)

    if color:
        return f"{display_name}, {color}"
    return display_name


async def find_photos(product: str, color: str = "", max_photos: int = 6) -> list[dict]:
    """ĞĞ°Ğ¹Ñ‚Ğ¸ Ñ„Ğ¾Ñ‚Ğ¾ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ°. Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ [{file_id, filename, caption}].

    Ğ•ÑĞ»Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ¾Ğ±Ñ‰Ğ¸Ğ¹ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ "Ñ‚ÑƒÑ„Ğ»Ğ¸"), Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¿Ğ¾ 1 Ñ„Ğ¾Ñ‚Ğ¾ Ğ¾Ñ‚ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾
    Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰ĞµĞ³Ğ¾ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ°. Ğ•ÑĞ»Ğ¸ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğ¹ ("Chanel slingbacks"), Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚
    Ğ²ÑĞµ Ñ„Ğ¾Ñ‚Ğ¾ ÑÑ‚Ğ¾Ğ³Ğ¾ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ°.
    """
    index = await load_photo_index()
    if not index:
        return []

    product_lower = product.lower().strip()
    color_lower = color.lower().strip() if color else ""
    query_tokens = set(product_lower.split())

    # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ²ÑĞµ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğµ ĞºĞ»ÑÑ‡Ğ¸ Ñ score
    matched: list[tuple[str, int]] = []
    for key in index:
        if product_lower == key:
            matched.append((key, 100))  # Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ
            continue
        # Ğ¡Ğ»Ğ¾Ğ²Ğ¾-Ğ²-ÑĞ»Ğ¾Ğ²Ğ¾ overlap
        key_tokens = set(key.split())
        overlap = len(query_tokens & key_tokens)
        if overlap > 0:
            matched.append((key, overlap))
        elif product_lower in key or key in product_lower:
            matched.append((key, 1))

    if not matched:
        return []

    # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ score desc
    matched.sort(key=lambda x: x[1], reverse=True)

    # ĞÑ‚ÑĞµĞºĞ°ĞµĞ¼ ÑĞ»Ğ°Ğ±Ñ‹Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ñ (score 1) ĞºĞ¾Ğ³Ğ´Ğ° ĞµÑÑ‚ÑŒ ÑĞ¸Ğ»ÑŒĞ½Ñ‹Ğµ (score >= 2)
    best_score = matched[0][1]
    if best_score >= 2:
        matched = [(k, s) for k, s in matched if s >= 2]

    # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞµĞ¹ (Ñ†ĞµĞ½Ğ°)
    catalog = await get_catalog()

    # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ñ„Ğ¾Ñ‚Ğ¾
    result = []
    # ĞšĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğ¹ Ñ‚Ğ¾Ğ²Ğ°Ñ€: 1 Ğ¼Ğ°Ñ‚Ñ‡, Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ğ¼Ğ°Ñ‚Ñ‡, Ğ¸Ğ»Ğ¸ Ğ¾Ğ´Ğ¸Ğ½ ÑĞ²Ğ½Ñ‹Ğ¹ Ğ»Ğ¸Ğ´ĞµÑ€ Ğ¿Ğ¾ score
    is_specific = (
        len(matched) == 1
        or matched[0][1] == 100
        or (len(matched) >= 2 and matched[0][1] > matched[1][1])
    )
    if is_specific:
        # ĞšĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğ¹ Ñ‚Ğ¾Ğ²Ğ°Ñ€ â€” Ğ²ÑĞµ ĞµĞ³Ğ¾ Ñ„Ğ¾Ñ‚Ğ¾ Ñ Ñ†Ğ²ĞµÑ‚Ğ¾Ğ¼ Ğ¸Ğ· Ğ¸Ğ¼ĞµĞ½Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ğ°
        key = matched[0][0]
        photos = index[key]
        if color_lower:
            filtered = [p for p in photos if color_lower in p["name"].lower()]
            if filtered:
                photos = filtered
        for p in photos[:max_photos]:
            photo_color = _extract_color_from_filename(p["name"])
            caption = _make_photo_caption(key, catalog, photo_color)
            result.append({"file_id": p["file_id"], "filename": p["name"], "caption": caption})
    else:
        # ĞĞ±Ñ‰Ğ¸Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ (Ñ‚ÑƒÑ„Ğ»Ğ¸, ÑÑƒĞ¼ĞºĞ¸) â€” Ğ¿Ğ¾ 1 Ñ„Ğ¾Ñ‚Ğ¾ Ğ¾Ñ‚ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ° Ñ Ñ†Ğ²ĞµÑ‚Ğ¾Ğ¼
        for key, _ in matched:
            photos = index[key]
            if color_lower:
                filtered = [p for p in photos if color_lower in p["name"].lower()]
                if filtered:
                    photos = filtered
            if photos:
                photo_color = _extract_color_from_filename(photos[0]["name"])
                caption = _make_photo_caption(key, catalog, photo_color)
                result.append({"file_id": photos[0]["file_id"], "filename": photos[0]["name"], "caption": caption})
            if len(result) >= max_photos:
                break

    return result




# â”€â”€ Telegram Ğ°Ğ»ĞµÑ€Ñ‚Ñ‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_last_alert: dict[str, float] = {}
ALERT_THROTTLE = 600


async def notify_error(error_type: str, message: str):
    if not TELEGRAM_ALERT_BOT_TOKEN or not TELEGRAM_ALERT_CHAT_ID:
        return
    now = time.time()
    if now - _last_alert.get(error_type, 0) < ALERT_THROTTLE:
        return
    _last_alert[error_type] = now
    text = f"âš ï¸ Sales Ottenok\n\nType: {error_type}\n{message[:1000]}"
    try:
        async with httpx.AsyncClient(timeout=10) as client:
            await client.post(
                f"https://api.telegram.org/bot{TELEGRAM_ALERT_BOT_TOKEN}/sendMessage",
                json={"chat_id": TELEGRAM_ALERT_CHAT_ID, "text": text},
            )
    except Exception as e:
        logger.warning(f"Telegram alert failed: {e}")


async def notify_order(order: dict):
    """Ğ£Ğ²ĞµĞ´Ğ¾Ğ¼Ğ¸Ñ‚ÑŒ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€Ğ° Ğ¾ Ğ½Ğ¾Ğ²Ğ¾Ğ¼ Ğ·Ğ°ĞºĞ°Ğ·Ğµ Ñ‡ĞµÑ€ĞµĞ· Telegram."""
    if TELEGRAM_ALERT_BOT_TOKEN and TELEGRAM_ALERT_CHAT_ID:
        text = f"ğŸ› ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ·Ğ°ĞºĞ°Ğ·!\n\n"
        text += f"Ğ¢Ğ¾Ğ²Ğ°Ñ€: {order.get('product', '?')}\n"
        text += f"Ğ Ğ°Ğ·Ğ¼ĞµÑ€: {order.get('size', '-')}\n"
        text += f"Ğ¦Ğ²ĞµÑ‚: {order.get('color', '-')}\n"
        text += f"Ğ“Ğ¾Ñ€Ğ¾Ğ´: {order.get('city', '?')}\n"
        text += f"ĞĞ´Ñ€ĞµÑ: {order.get('address', '?')}\n"
        text += f"ĞšĞ»Ğ¸ĞµĞ½Ñ‚: {order.get('client_phone', '?')}"
        try:
            async with httpx.AsyncClient(timeout=10) as client:
                await client.post(
                    f"https://api.telegram.org/bot{TELEGRAM_ALERT_BOT_TOKEN}/sendMessage",
                    json={"chat_id": TELEGRAM_ALERT_CHAT_ID, "text": text},
                )
        except Exception as e:
            logger.warning(f"Order notification failed: {e}")


async def notify_order_whatsapp(order: dict):
    """ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ ÑĞ²Ğ¾Ğ´ĞºÑƒ Ğ·Ğ°ĞºĞ°Ğ·Ğ° Ğ² WhatsApp-Ğ³Ñ€ÑƒĞ¿Ğ¿Ñƒ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€Ğ¾Ğ²."""
    if not ORDER_GROUP_CHAT_ID:
        return
    from greenapi_client import send_text
    text = (
        f"ğŸ› ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ·Ğ°ĞºĞ°Ğ·!\n\n"
        f"Ğ¢Ğ¾Ğ²Ğ°Ñ€: {order.get('product', '?')}\n"
        f"Ğ Ğ°Ğ·Ğ¼ĞµÑ€: {order.get('size', '-')}\n"
        f"Ğ¦Ğ²ĞµÑ‚: {order.get('color', '-')}\n"
        f"Ğ“Ğ¾Ñ€Ğ¾Ğ´: {order.get('city', '?')}\n"
        f"ĞĞ´Ñ€ĞµÑ: {order.get('address', '?')}\n"
        f"Ğ¢ĞµĞ»ĞµÑ„Ğ¾Ğ½ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°: {order.get('client_phone', '?')}"
    )
    try:
        await send_text(ORDER_GROUP_CHAT_ID, text)
        logger.info(f"Order sent to WhatsApp group: {order.get('product')}")
    except Exception as e:
        logger.error(f"WhatsApp group notification failed: {e}")


# â”€â”€ N8N webhook â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def send_order_to_n8n(order: dict):
    if not N8N_ORDER_WEBHOOK_URL:
        return
    try:
        async with httpx.AsyncClient(timeout=15) as client:
            await client.post(N8N_ORDER_WEBHOOK_URL, json=order)
        logger.info(f"Order sent to N8N: {order.get('product')}")
    except Exception as e:
        logger.error(f"N8N webhook failed: {e}")
