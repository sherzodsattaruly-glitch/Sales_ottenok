"""
AI-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä: —Å–≤—è–∑—ã–≤–∞–µ—Ç RAG, GPT –∏ Google Drive.
–ì–ª–∞–≤–Ω–∞—è —Ç–æ—á–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π.
"""

import asyncio
import json
import logging
import re
import time

from openai import AsyncOpenAI

from ai.prompts import SYSTEM_PROMPT
from ai.rag import search_products, search_scripts
from db.conversations import (
    get_conversation_history,
    save_message,
    has_sent_product_photos,
    has_any_sent_photos,
    mark_product_photos_sent,
    get_handoff_state,
    set_handoff_state,
    get_order_context,
    upsert_order_context,
    reset_nudge_state,
    update_last_client_message,
    get_order_pending_confirm,
    set_order_pending_confirm,
)
from gdrive.photo_mapper import find_product_photos, tokenize_text, select_photos_with_color_variety
from inventory.stock_checker import check_product_availability, format_availability_message
from greenapi.client import send_text, send_multiple_images
from notifications import notify_error
from integrations.n8n import notify_order_confirmed
from integrations.order_notifications import notify_order_to_group
from ai.order_manager import (
    _normalize_product_type,
    _infer_product_type_from_text,
    _merge_order_context,
    _contains_order_confirm,
    _strip_order_confirm,
    _build_missing_fields,
    _question_for_missing,
    _has_question,
    _has_order_intent,
    _assistant_already_requests_missing,
    _strip_checkout_prompts,
    _get_product_color_overrides,
    _is_order_confirmation,
    _is_negative_or_undecided,
    _build_order_summary,
    _build_item_desc,
    _ORDER_CONFIRM_TEXT,
)
from config import (
    OPENAI_API_KEY,
    OPENAI_MODEL,
    MAX_PHOTOS_PER_MESSAGE,
    MAX_PHOTOS_PRODUCT_SHOWCASE,
    MAX_PHOTOS_PER_COLOR,
    MANAGER_CHAT_IDS,
)

logger = logging.getLogger(__name__)

openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)


async def transcribe_voice(audio_bytes: bytes, mime_type: str = "audio/ogg") -> str | None:
    """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —á–µ—Ä–µ–∑ OpenAI Whisper."""
    ext = "ogg"
    if "mpeg" in mime_type or "mpga" in mime_type:
        ext = "mp3"
    try:
        transcript = await openai_client.audio.transcriptions.create(
            model="whisper-1",
            file=(f"voice.{ext}", audio_bytes),
            language="ru",
        )
        text = transcript.text.strip()
        logger.info(f"Whisper transcription ({len(audio_bytes)} bytes): {text[:100]}")
        return text if text else None
    except Exception as e:
        logger.error(f"Whisper transcription failed: {e}", exc_info=True)
        return None


_PHOTO_REQUEST_PATTERNS = [
    "—Ñ–æ—Ç–æ", "—Ñ–æ—Ç–∫—É", "—Ñ–æ—Ç–∫–∏", "—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é", "—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é", "—Å–Ω–∏–º–æ–∫",
    "–ø–æ–∫–∞–∂–∏", "–ø–æ–∫–∞–∂–∏—Ç–µ", "–ø–æ–∫–∞–∂–µ—à—å", "–ø–æ–∫–∞–∑–∞—Ç—å", "–ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å",
    "—Å–∫–∏–Ω—å", "—Å–∫–∏–Ω—å—Ç–µ", "–ø—Ä–∏—à–ª–∏", "–ø—Ä–∏—à–ª–∏—Ç–µ", "–∫–∏–Ω—å", "–∫–∏–Ω—å—Ç–µ",
    "–æ—Ç–ø—Ä–∞–≤—å", "–æ—Ç–ø—Ä–∞–≤—å—Ç–µ",
]

_PRODUCT_HINT_TOKENS = {
    "chanel", "—à–∞–Ω–µ–ª", "—à–∞–Ω–µ–ª—å", "miu", "miu miu", "–¥–∂–∏–º–º–∏", "jimmy", "choo",
    "gucci", "dior", "saint", "laurent", "golden", "goose", "jimbo", "–¥–∂—É–º–±–æ",
    "classic", "flap", "arcadie", "azia", "saeda", "opyum", "25", "yves",
}
_PRODUCT_RAW_HINTS = [
    "—à–∞–Ω–µ–ª", "chanel", "–¥–∂—É–º–±–æ", "jumbo", "–∫–ª–∞—Å—Å–∏–∫", "classic", "flap",
    "–¥–∂–∏–º–º–∏", "jimmy", "—á—É", "choo", "—Å–∞–µ–¥–∞", "saeda", "–∞–∑–∏—è", "azia",
    "–º–∏—É", "miu", "arcadie", "—Å–ª–∏–Ω–≥–±—ç–∫", "slingback",
]

# –°–ª–æ–≤–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Ç–æ–≤–∞—Ä–æ–≤ ‚Äî –µ—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç —É–ø–æ–º–∏–Ω–∞–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é, —ç—Ç–æ –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å, –∞ –Ω–µ follow-up
_CATEGORY_WORDS = {
    "—Å—É–º–∫–∞", "—Å—É–º–∫–∏", "—Å—É–º–∫—É", "—Å—É–º–æ–∫", "—Å—É–º–æ—á–∫–∞", "—Å—É–º–æ—á–∫—É",
    "–∫—Ä–æ—Å—Å–æ–≤–∫–∏", "–∫—Ä–æ—Å—Å–æ–≤–æ–∫", "–∫—Ä–æ—Å—Å–æ–≤–∫—É",
    "—Ç—É—Ñ–ª–∏", "—Ç—É—Ñ–µ–ª—å", "—Ç—É—Ñ–ª–µ–π", "—Ç—É—Ñ–ª—è—Ö",
    "–±–∞–ª–µ—Ç–∫–∏", "–±–∞–ª–µ—Ç–æ–∫", "–±–∞–ª–µ—Ç–∫—É",
    "–æ–±—É–≤—å", "–æ–±—É–≤–∏",
}


def _is_category_browsing(user_message: str) -> bool:
    """–ö–ª–∏–µ–Ω—Ç –ø—Ä–æ—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é ('–∫–∞–∫–∏–µ —Å—É–º–∫–∏ –µ—Å—Ç—å', '–ø–æ–∫–∞–∂–∏—Ç–µ –∫—Ä–æ—Å—Å–æ–≤–∫–∏').
    –ù–ï —Å—á–∏—Ç–∞–µ—Ç—Å—è –∫–∞—Ç–µ–≥–æ—Ä–∏–µ–π, –µ—Å–ª–∏ —É–ø–æ–º—è–Ω—É—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –±—Ä–µ–Ω–¥/–º–æ–¥–µ–ª—å.
    """
    words = re.findall(r'[–∞-—è–ê-–Ø—ë–Åa-zA-Z]+', user_message.lower())
    has_category = any(w in _CATEGORY_WORDS for w in words)
    if not has_category:
        return False
    # –ï—Å–ª–∏ –µ—Å—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –±—Ä–µ–Ω–¥/–º–æ–¥–µ–ª—å ‚Äî —ç—Ç–æ –∑–∞–ø—Ä–æ—Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞, –Ω–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—è
    has_product_hint = any(w in _PRODUCT_HINT_TOKENS for w in words)
    if has_product_hint:
        return False
    return True


def _detect_browsing_category(user_message: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞ –∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç product_type –∏–ª–∏ ''."""
    text_l = user_message.lower()
    if any(w in text_l for w in ("—Å—É–º–∫", "—Å—É–º–æ—á")):
        return "bag"
    if any(w in text_l for w in ("–∫—Ä–æ—Å—Å–æ–≤–∫", )):
        return "shoes"
    if any(w in text_l for w in ("—Ç—É—Ñ–ª", )):
        return "shoes"
    if any(w in text_l for w in ("–±–∞–ª–µ—Ç–∫", )):
        return "shoes"
    if any(w in text_l for w in ("–æ–±—É–≤—å", "–æ–±—É–≤–∏")):
        return "shoes"
    return ""


def _is_vague_followup(text: str) -> bool:
    """–°–æ–æ–±—â–µ–Ω–∏–µ ‚Äî —Ä–∞—Å–ø–ª—ã–≤—á–∞—Ç—ã–π follow-up –±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏ ('–ö–∞–∫–∏–µ?', '–ü–æ–∫–∞–∂–∏', '–î–∞–≤–∞–π')."""
    t = text.strip().lower()
    t = re.sub(r'[^\w\s]', '', t)  # —É–±–∏—Ä–∞–µ–º –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
    words = t.split()
    if not words or len(words) > 4:
        return False
    vague_patterns = {
        "–∫–∞–∫–∏–µ", "–∫–∞–∫–æ–µ", "–∫–∞–∫—É—é", "–∫–∞–∫–æ–π", "–∫–∞–∫–∏—Ö",
        "–ø–æ–∫–∞–∂–∏", "–ø–æ–∫–∞–∂–∏—Ç–µ", "–¥–∞–≤–∞–π", "–¥–∞–≤–∞–π—Ç–µ",
        "–Ω—É", "–∞", "—Ö–æ—á—É", "–∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ", "–µ—Å—Ç—å",
        "—á—Ç–æ", "–µ—â—ë", "–µ—â–µ", "–º–æ–∂–Ω–æ", "–¥–∞",
    }
    return all(w in vague_patterns for w in words)


def _infer_product_type_from_assistant_message(text: str) -> str:
    """–ò–∑–≤–ª–µ—á—å —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞ –∏–∑ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞."""
    t = (text or "").lower()
    if any(x in t for x in ["–æ–±—É–≤", "—Ç—É—Ñ–ª", "–∫—Ä–æ—Å—Å–æ–≤–∫", "–±–∞–ª–µ—Ç–∫", "–ª–æ—Ñ–µ—Ä", "–±–æ—Ç–∏–Ω", "–∫–∞–±–ª—É–∫"]):
        return "shoes"
    if any(x in t for x in ["—Å—É–º–∫", "—Å—É–º–æ—á", "–∫–ª–∞—Ç—á", "—Ä—é–∫–∑–∞–∫"]):
        return "bag"
    if any(x in t for x in ["–∞–∫—Å–µ—Å—Å—É–∞—Ä", "—É–∫—Ä–∞—à–µ–Ω", "—Ä–µ–º–µ–Ω", "—Ä–µ–º–Ω", "–∫–æ—à–µ–ª—ë–∫", "–∫–æ—à–µ–ª–µ–∫"]):
        return "accessory"
    return ""


def _extract_search_hint_from_assistant(text: str) -> str:
    """–ò–∑–≤–ª–µ—á—å –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ñ–æ—Ç–æ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞."""
    t = (text or "").lower()
    for pattern, query in [
        ("–∫—Ä–æ—Å—Å–æ–≤–∫", "–∫—Ä–æ—Å—Å–æ–≤–∫–∏"),
        ("—Ç—É—Ñ–ª", "—Ç—É—Ñ–ª–∏"),
        ("–±–∞–ª–µ—Ç–∫", "–±–∞–ª–µ—Ç–∫–∏"),
        ("–ª–æ—Ñ–µ—Ä", "–ª–æ—Ñ–µ—Ä—ã"),
        ("–±–æ—Ç–∏–Ω", "–±–æ—Ç–∏–Ω–∫–∏"),
        ("–æ–±—É–≤", "–æ–±—É–≤—å"),
        ("—Å—É–º–æ—á", "—Å—É–º–æ—á–∫–∞"),
        ("—Å—É–º–∫", "—Å—É–º–∫–∞"),
        ("–∫–ª–∞—Ç—á", "–∫–ª–∞—Ç—á"),
        ("–∞–∫—Å–µ—Å—Å—É–∞—Ä", "–∞–∫—Å–µ—Å—Å—É–∞—Ä—ã"),
    ]:
        if pattern in t:
            return query
    return ""


def _is_photo_request(text: str) -> bool:
    t = text.lower()
    if any(p in t for p in _PHOTO_REQUEST_PATTERNS):
        return True
    if re.search(r"–∫–∞–∫\s+–æ–Ω\s+–≤—ã–≥–ª—è–¥", t):
        return True
    if re.search(r"–∫–∞–∫\s+–≤—ã–≥–ª—è–¥–∏—Ç", t):
        return True
    return False


def _build_product_key(user_tokens: set[str], photos: list[dict]) -> str:
    if photos:
        tokens = tokenize_text(photos[0].get("filename", ""))
    else:
        tokens = set(user_tokens)
    tokens = [t for t in tokens if t]
    if not tokens:
        return ""
    return "|".join(sorted(tokens))


def _should_use_active_product_query(user_message: str, active_product: str) -> bool:
    if not active_product:
        return False
    user_tokens = tokenize_text(user_message)
    product_tokens = tokenize_text(active_product)
    if user_tokens & product_tokens:
        return False
    text_l = user_message.lower()
    if any(h in text_l for h in _PRODUCT_RAW_HINTS):
        return False
    # If user explicitly names another product/brand, keep current message as query.
    if any(tok in _PRODUCT_HINT_TOKENS for tok in user_tokens):
        return False
    # –ö–ª–∏–µ–Ω—Ç —É–ø–æ–º–∏–Ω–∞–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ç–æ–≤–∞—Ä–∞ ("—Å—É–º–∫–∏", "–∫—Ä–æ—Å—Å–æ–≤–∫–∏", "—Ç—É—Ñ–ª–∏") ‚Äî —ç—Ç–æ –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
    if any(w in _CATEGORY_WORDS for w in re.findall(r'[–∞-—è–ê-–Ø—ë–Åa-zA-Z]+', text_l)):
        return False
    return True


def _dedupe_photos(photos: list[dict]) -> list[dict]:
    seen = set()
    result = []
    for p in photos:
        key = p.get("file_id") or p.get("filename") or p.get("direct_url")
        if not key or key in seen:
            continue
        seen.add(key)
        result.append(p)
    return result


def _normalize_photo_captions(photos: list[dict]) -> list[dict]:
    """–û—Å—Ç–∞–≤–ª—è–µ—Ç –ø–æ–¥–ø–∏—Å—å —É –∫–∞–∂–¥–æ–π —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ (–Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏)."""
    if not photos:
        return photos
    normalized = []
    for p in photos:
        item = dict(p)
        # –ë–æ–ª—å—à–µ –Ω–µ –æ—á–∏—â–∞–µ–º –ø–æ–¥–ø–∏—Å—å –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö —Ñ–æ—Ç–æ, –∫–∞–∫ –ø—Ä–æ—Å–∏–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
        normalized.append(item)
    return normalized


def _extract_chat_id(text: str) -> str:
    # Prefer explicit chatId
    m = re.search(r"(\d{8,15})@c\.us", text)
    if m:
        return f"{m.group(1)}@c.us"
    # Fallback to digits
    digits = re.findall(r"\d{8,15}", text)
    if digits:
        return f"{digits[-1]}@c.us"
    # Fallback: join all digits (handles spaces in phone numbers)
    digits_all = re.sub(r"\D", "", text)
    if 8 <= len(digits_all) <= 15:
        return f"{digits_all}@c.us"
    return ""


def _parse_handoff_command(text: str) -> tuple[str | None, str | None]:
    t = text.strip().lower()
    if not (t.startswith("/handoff") or t.startswith("handoff") or t.startswith("/human") or t.startswith("human")):
        return None, None
    if " on" in t or t.endswith(" on"):
        action = "on"
    elif " off" in t or t.endswith(" off"):
        action = "off"
    elif " status" in t or t.endswith(" status"):
        action = "status"
    else:
        action = None
    target = _extract_chat_id(text)
    return action, target


_GREETING_WORDS = ["–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ", "–ø—Ä–∏–≤–µ—Ç", "–¥–æ–±—Ä—ã–π –¥–µ–Ω—å", "–¥–æ–±—Ä—ã–π –≤–µ—á–µ—Ä", "–¥–æ–±—Ä–æ–µ —É—Ç—Ä–æ"]

_TRUST_MSG_MARKERS = [
    "–Ω–µ –±–∞–π–µ—Ä—ã", "–Ω–µ –±–∞–π–µ—Ä", "–Ω–µ –ø–µ—Ä–µ–∫—É–ø—â–∏–∫",
    "–µ—Å—Ç—å –º–∞–≥–∞–∑–∏–Ω, –ø—Ä–∏–º–µ—Ä–∫–∞", "–ø—Ä–∏–º–µ—Ä–∫–∞, –æ–±–º–µ–Ω –∏ –≤–æ–∑–≤—Ä–∞—Ç",
    "—Ä–∞–±–æ—Ç–∞–µ–º –Ω–∞–ø—Ä—è–º—É—é —Å –ª—É—á—à–∏–º–∏ —Ñ–∞–±—Ä–∏–∫–∞–º–∏",
    "–≤–∞–∂–Ω—ã–π –º–æ–º–µ–Ω—Ç, —á—Ç–æ–±—ã –≤—ã –Ω–µ –ø–µ—Ä–µ–∂–∏–≤–∞–ª–∏",
]

_COLOR_REQUIREMENT_CACHE: dict[str, tuple[bool, float]] = {}
_COLOR_CACHE_TTL = 1800  # 30 minutes
_AVAILABILITY_HINTS = [
    "–µ—Å—Ç—å", "–∏–º–µ–µ—Ç—Å—è", "–≤ –Ω–∞–ª–∏—á–∏–∏", "–±—ã–≤–∞–µ—Ç", "–±—ã–ª–∏", "–±—É–¥–µ—Ç",
]
_MODEL_QUERY_IGNORE_TOKENS = {
    "–µ—Å—Ç—å", "–∫–∞–∫–æ–π", "–∫–∞–∫–∞—è", "–∫–∞–∫–∏–µ", "–Ω—É–∂–µ–Ω", "–Ω—É–∂–Ω–∞", "–Ω—É–∂–Ω—ã",
    "–ø–æ–∫–∞–∂–∏", "–ø–æ–∫–∞–∑–∞—Ç—å", "–ø—Ä–∏—à–ª–∏", "—Å–∫–∏–Ω—å", "–º–æ–¥–µ–ª—å", "–º–æ–¥–µ–ª–∏",
    "—Ü–≤–µ—Ç", "—Ä–∞–∑–º–µ—Ä", "—Ä–∞–∑–º–µ—Ä—ã", "–≥–æ—Ä–æ–¥", "–∞–¥—Ä–µ—Å", "—Å—É–º–∫–∞", "—Å—É–º–∫–∏", "—Ç—É—Ñ–ª–∏",
    "–æ–±—É–≤—å", "–∞–∫—Å–µ—Å—Å—É–∞—Ä", "–∞–∫—Å–µ—Å—Å—É–∞—Ä—ã", "–≤", "–Ω–∞", "–∏", "–∏–ª–∏",
    "–µ—â–µ", "–µ—â—ë", "—Ü–µ–Ω–∞", "—Ü–µ–Ω—ã", "—Å–∫–æ–ª—å–∫–æ", "—Å—Ç–æ–∏—Ç", "–Ω–∞–ª–∏—á–∏–∏", "–Ω–∞–ª–∏—á–∏–µ",
    "–∫—Ä–æ—Å—Å–æ–≤–∫–∏", "–∫—Ä–æ—Å–æ–≤–∫–∏", "–∫–µ–¥—ã", "–±–∞–ª–µ—Ç–∫–∏", "–ª–æ—Ñ–µ—Ä—ã", "—Å–ª–∏–Ω–≥–±—ç–∫–∏", "—Å–ª–∏–Ω–≥–±—ç–∫",
    "chanel", "saint", "laurent", "ysl", "yves", "jimmy", "choo", "miu",
    "louis", "vuitton", "gucci", "dior", "golden", "goose",
    "–∏–≤", "—Å–∞–Ω", "–ª–æ—Ä–∞–Ω", "—Å–µ–Ω", "—à–∞–Ω–µ–ª", "—à–∞–Ω–µ–ª—å", "–¥–∂–∏–º–∏", "–¥–∂–∏–º–º–∏", "—á—É",
    # General words that are not product names
    "–º–æ–∂–Ω–æ", "–±—É–¥–µ—Ç", "–ø—Ä–∏–µ—Ö–∞—Ç—å", "–ø—Ä–∏–º–µ—Ä–∫—É", "–ø—Ä–∏–º–µ—Ä–∫–∞", "—Å–Ω–∞—á–∞–ª–∞", "–ø–æ—Ç–æ–º",
    "–∫–æ–≥–¥–∞", "–≥–¥–µ", "–∫–∞–∫", "–≤–∞–º", "–≤–∞—Å", "–Ω–∞–º", "–Ω–∞—Å", "–º–Ω–µ", "—Å–µ–±–µ",
    "—Ö–æ—á—É", "—Ö–æ—Ç–µ–ª–∞", "—Ö–æ—Ç–µ–ª", "–º–æ–≥—É", "–º–æ–∂–µ—Ç", "–º–æ–∂–µ—Ç–µ", "–Ω—É–∂–Ω–æ", "–Ω–∞–¥–æ",
    "–ø–æ–∂–∞–ª—É–π—Å—Ç–∞", "—Å–ø–∞—Å–∏–±–æ", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ", "–ø—Ä–∏–≤–µ—Ç", "–¥–æ–±—Ä—ã–π", "–¥–µ–Ω—å",
    "—É—Ç—Ä–æ", "–≤–µ—á–µ—Ä", "–¥–æ—Å—Ç–∞–≤–∫–∞", "–¥–æ—Å—Ç–∞–≤–∫—É", "–æ–ø–ª–∞—Ç–∞", "–æ–ø–ª–∞—Ç—É", "–∑–∞–∫–∞–∑",
    "–∑–∞–∫–∞–∑–∞—Ç—å", "–∫—É–ø–∏—Ç—å", "–≤–∑—è—Ç—å", "–ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å", "–ø–æ–¥—Ä–æ–±–Ω–µ–µ", "–ø–æ–¥—Å–∫–∞–∂–∏—Ç–µ",
    "—Å–∫–∞–∂–∏—Ç–µ", "–æ—Ç–≤–µ—Ç—å—Ç–µ", "–Ω–∞–ø–∏—à–∏—Ç–µ", "–æ—Ç–ø—Ä–∞–≤—å—Ç–µ", "–ø—Ä–∏—à–ª–∏—Ç–µ",
    "—É–≤–∏–¥–µ–ª–∞", "—É–≤–∏–¥–µ–ª", "—É–≤–∏–¥–µ–ª–∏", "–≤–∏–¥–µ–ª–∞", "–≤–∏–¥–µ–ª", "–≤–∏–¥–µ–ª–∏",
    "–∏–Ω—Å—Ç–∞–≥—Ä–∞–º", "instagram", "–∏–Ω—Å—Ç–∞", "—Å–∞–π—Ç", "—Å–∞–π—Ç–µ",
    "–≤–∞—à", "–≤–∞—à–∞", "–≤–∞—à–µ", "–≤–∞—à–∏", "–≤–∞—à–µ–º", "–≤–∞—à—É",
}
_TYPE_FALLBACK_ALTERNATIVES = {
    "shoes": ["Golden Goose Super-Star", "Saint Laurent Opyum", "Chanel Classic Slingbacks", "Jimmy Choo Azia 95"],
    "bag": ["Chanel Jumbo Classic Flap", "Yves Saint Laurent Monogram", "Louis Vuitton Pochette Felicie", "Miu Miu Arcadie", "Miu Miu Wander"],
}


def _clean_product_name(name: str) -> str:
    """–£–±—Ä–∞—Ç—å —Å–ª—É–∂–µ–±–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã ('–¢–æ–≤–∞—Ä:', '–ú–æ–¥–µ–ª—å:') –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞."""
    n = (name or "").strip()
    n = re.sub(r'^(?:–¢–æ–≤–∞—Ä|–ú–æ–¥–µ–ª—å)\s*:\s*', '', n, flags=re.IGNORECASE)
    return n.strip()


def _extract_product_name_from_result(result: dict) -> str:
    meta = (result.get("metadata") or {})
    name = _clean_product_name((meta.get("product_name") or "").strip())
    if name:
        return name
    text = (result.get("text") or "").strip()
    if not text:
        return ""
    m = re.search(r"[üë†üëüüëú]\s*([^\n]+)", text)
    candidate = (m.group(1) if m else text.splitlines()[0]).strip()
    candidate = re.split(r"\s+[‚Äî-]\s+", candidate)[0].strip()
    candidate = re.sub(r"\s{2,}.*$", "", candidate).strip()
    candidate = candidate[:120]
    return candidate if _looks_like_product_name(candidate) else ""


_BRAND_NAMES_EN = {
    "chanel", "saint laurent", "ysl", "yves saint laurent",
    "jimmy choo", "miu miu", "louis vuitton",
    "gucci", "dior", "golden goose", "prada",
    "balenciaga", "fendi", "versace", "dolce gabbana",
    "bottega veneta", "celine", "loewe", "valentino",
    "burberry", "hermes",
}

_BRAND_PATTERN = re.compile(
    r"\b(" + "|".join(re.escape(b) for b in sorted(_BRAND_NAMES_EN, key=len, reverse=True)) + r")\b\s*([\w\-]+(?:\s+[\w\-]+){0,2})?",
    re.IGNORECASE,
)


def _extract_product_mention(text: str) -> str:
    """Extract first brand + model mention from text. Returns short product name or empty string."""
    if not text:
        return ""
    m = _BRAND_PATTERN.search(text)
    if not m:
        return ""
    brand = m.group(1).strip()
    rest = (m.group(2) or "").strip()
    if rest:
        return f"{brand} {rest}"
    return brand


def _infer_result_product_type(result: dict) -> str:
    name = _extract_product_name_from_result(result)
    text = (result.get("text") or "")[:260]
    return _infer_product_type_from_text(f"{name} {text}")


def _looks_like_product_name(name: str) -> bool:
    n = (name or "").strip()
    if not n:
        return False
    low = n.lower()
    if any(bad in low for bad in ["–∏–º–µ–Ω–Ω–æ –ø–æ", "–æ–ø–∏—Å–∞–Ω–∏–µ", "—Ü–µ–Ω—ã", "–≤–º–µ—Å—Ç–µ —Å —Ü–µ–Ω–æ–π", "–ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ"]):
        return False
    if ":" in n and not any(h in n.lower() for h in ["chanel", "saint", "laurent", "jimmy", "miu", "louis", "golden"]):
        return False
    words = re.findall(r"[a-zA-Z–∞-—è–ê-–Ø—ë–Å0-9]+", n.lower())
    if len(words) > 8:
        return False
    tokens = tokenize_text(n)
    if tokens & _PRODUCT_HINT_TOKENS:
        return True
    if any(b in n.lower() for b in ["chanel", "saint", "laurent", "jimmy", "miu", "louis", "golden", "ysl"]):
        return True
    return False


def _filter_photos_by_requested_type(photos: list[dict], requested_type: str) -> list[dict]:
    if not photos or not requested_type:
        return photos
    matched = []
    for p in photos:
        filename = p.get("filename", "")
        p_type = _infer_product_type_from_text(filename)
        if p_type == requested_type:
            matched.append(p)
    return matched


def _build_fallback_photo_queries(user_message: str, requested_type: str) -> list[str]:
    t = (user_message or "").lower()
    queries: list[str] = []
    if requested_type == "shoes":
        if any(x in t for x in ["—Å–∞–Ω –ª–æ—Ä–∞–Ω", "–∏–≤ —Å–∞–Ω", "saint laurent", "ysl"]):
            queries.append("Saint Laurent Opyum")
    if requested_type == "bag":
        if any(x in t for x in ["—Å–∞–Ω –ª–æ—Ä–∞–Ω", "–∏–≤ —Å–∞–Ω", "saint laurent", "ysl"]):
            queries.append("Yves Saint Laurent Monogram")
    return queries


def _is_availability_request(text: str) -> bool:
    t = (text or "").lower()
    return any(h in t for h in _AVAILABILITY_HINTS)


def _extract_specific_query_tokens(text: str) -> set[str]:
    tokens = tokenize_text(text or "")
    specific = set()
    for tok in tokens:
        if not tok or tok.isdigit() or len(tok) < 3:
            continue
        if tok in _MODEL_QUERY_IGNORE_TOKENS:
            continue
        if tok in _COLOR_PREFIXES.values():
            continue
        if any(tok.startswith(prefix) for prefix in _COLOR_PREFIXES):
            continue
        specific.add(tok)
    return specific


def _match_name_overlap(query_text: str, product_name: str) -> int:
    q = tokenize_text(query_text or "")
    p = tokenize_text(product_name or "")
    return len(q & p)


def _pick_primary_product_match(product_results: list[dict], query_text: str) -> str:
    best_name = ""
    best_score = -1
    for r in product_results:
        name = _extract_product_name_from_result(r)
        if not name:
            continue
        score = _match_name_overlap(query_text, name)
        if score > best_score:
            best_score = score
            best_name = name
    return best_name


def _collect_similar_product_names(
    product_results: list[dict],
    requested_type: str = "",
    exclude_names: set[str] | None = None,
    limit: int = 3,
) -> list[str]:
    excluded = {(x or "").strip().lower() for x in (exclude_names or set()) if x}
    names: list[str] = []
    seen = set()
    for r in product_results:
        name = _extract_product_name_from_result(r)
        if not name:
            continue
        name_l = name.lower()
        if name_l in seen or name_l in excluded:
            continue
        if requested_type:
            r_type = _infer_result_product_type(r)
            if r_type and r_type != requested_type:
                continue
        seen.add(name_l)
        names.append(name)
        if len(names) >= limit:
            break
    return names


def _append_similar_products_text(base_text: str, similar_names: list[str]) -> str:
    if not similar_names:
        return base_text
    # –ß–∏—Å—Ç–∏–º –Ω–∞–∑–≤–∞–Ω–∏—è –æ—Ç —Å–ª—É–∂–µ–±–Ω—ã—Ö –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤ "–¢–æ–≤–∞—Ä:", "–ú–æ–¥–µ–ª—å:"
    clean_names = [_clean_product_name(n) for n in similar_names]
    clean_names = [n for n in clean_names if n]
    if not clean_names:
        return base_text
    variants = "; ".join(clean_names)
    return f"{base_text}|||–ü–æ—Ö–æ–∂–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã: {variants}. –ö–∞–∫–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –ø–æ–∫–∞–∑–∞—Ç—å?"


def _fallback_alternative_names(product_type: str, exclude_names: set[str] | None = None, limit: int = 3) -> list[str]:
    excluded = {(x or "").strip().lower() for x in (exclude_names or set()) if x}
    candidates = _TYPE_FALLBACK_ALTERNATIVES.get(product_type or "", [])
    result = []
    for name in candidates:
        if name.lower() in excluded:
            continue
        result.append(name)
        if len(result) >= limit:
            break
    return result


def _dedupe_response_parts(text: str) -> str:
    if not text:
        return text
    parts = [p.strip() for p in text.split("|||") if p.strip()]
    if not parts:
        return text
    seen = set()
    kept = []
    for part in parts:
        key = re.sub(r"\s+", " ", part.lower())
        key = re.sub(r"[^\w\s–∞-—è—ë]", "", key)
        if key in seen:
            continue
        seen.add(key)
        kept.append(part)
    return "|||".join(kept)


def _format_color_unavailable_message(product_name: str, requested_color: str, available_colors: set[str]) -> str:
    product = product_name or "—ç—Ç–æ–π –º–æ–¥–µ–ª–∏"
    if available_colors:
        colors_text = ", ".join(sorted(available_colors))
        if len(available_colors) == 1:
            only_color = next(iter(available_colors))
            return (
                f"–ü–æ –º–æ–¥–µ–ª–∏ {product} —Ü–≤–µ—Ç–∞ {requested_color} —Å–µ–π—á–∞—Å –Ω–µ—Ç. "
                f"–ï—Å—Ç—å —Ç–æ–ª—å–∫–æ {only_color}. –ü–æ–¥–æ–π–¥–µ—Ç —ç—Ç–æ—Ç –≤–∞—Ä–∏–∞–Ω—Ç?"
            )
        return (
            f"–ü–æ –º–æ–¥–µ–ª–∏ {product} —Ü–≤–µ—Ç–∞ {requested_color} —Å–µ–π—á–∞—Å –Ω–µ—Ç. "
            f"–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ü–≤–µ—Ç–∞: {colors_text}. –ö–∞–∫–æ–π —Ü–≤–µ—Ç –≤—ã–±–∏—Ä–∞–µ—Ç–µ?"
        )
    return (
        f"–ü–æ –º–æ–¥–µ–ª–∏ {product} —Ü–≤–µ—Ç {requested_color} —Å–µ–π—á–∞—Å –Ω–µ –≤–∏–∂—É –≤ –Ω–∞–ª–∏—á–∏–∏. "
        "–ü–æ–¥—Å–∫–∞–∂–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∫–∞–∫–æ–π —Ü–≤–µ—Ç —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö?"
    )


def _format_order_context_for_prompt(order_ctx: dict, missing_fields: list[str], color_required: bool) -> str:
    fields_ru = {
        "city": "–≥–æ—Ä–æ–¥",
        "product": "—Ç–æ–≤–∞—Ä",
        "size": "—Ä–∞–∑–º–µ—Ä",
        "color": "—Ü–≤–µ—Ç",
        "address": "–∞–¥—Ä–µ—Å",
    }
    missing_ru = ", ".join(fields_ru[f] for f in missing_fields) if missing_fields else "–Ω–µ—Ç"

    # –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –µ—â–µ –Ω–µ –≤—ã–±—Ä–∞–ª —Ç–æ–≤–∞—Ä - —è–≤–Ω–æ –∑–∞–ø—Ä–µ—Ç–∏—Ç—å —Å–æ–±–∏—Ä–∞—Ç—å –≥–æ—Ä–æ–¥
    product_warning = ""
    if not order_ctx.get("product"):
        product_warning = "\n‚ö†Ô∏è –í–ê–ñ–ù–û: –ö–ª–∏–µ–Ω—Ç –µ—â–µ –ù–ï –í–´–ë–†–ê–õ —Ç–æ–≤–∞—Ä. –ù–ï —Å–ø—Ä–∞—à–∏–≤–∞–π –≥–æ—Ä–æ–¥! –ü–æ–º–æ–≥–∏ —Å –≤—ã–±–æ—Ä–æ–º, –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã.\n"

    # –î–ª—è —Å—É–º–æ–∫ —Ä–∞–∑–º–µ—Ä –Ω–µ –Ω—É–∂–µ–Ω
    bag_note = ""
    if order_ctx.get("product_type") == "bag":
        bag_note = "\n‚ö†Ô∏è –¢–∏–ø —Ç–æ–≤–∞—Ä–∞ ‚Äî —Å—É–º–∫–∞. –£ —Å—É–º–æ–∫ –ù–ï–¢ —Ä–∞–∑–º–µ—Ä–∞, –ù–ï —Å–ø—Ä–∞—à–∏–≤–∞–π —Ä–∞–∑–º–µ—Ä!\n"

    return (
        "–ö–û–ù–¢–ï–ö–°–¢ –ó–ê–ö–ê–ó–ê:\n"
        f"- –≥–æ—Ä–æ–¥: {order_ctx.get('city') or '-'}\n"
        f"- —Ç–æ–≤–∞—Ä: {order_ctx.get('product') or '-'}\n"
        f"- —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞: {order_ctx.get('product_type') or '-'}\n"
        f"- —Ä–∞–∑–º–µ—Ä: {order_ctx.get('size') or '-'}\n"
        f"- —Ü–≤–µ—Ç: {order_ctx.get('color') or '-'}\n"
        f"- –∞–¥—Ä–µ—Å: {order_ctx.get('address') or '-'}\n"
        f"- —Ü–≤–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω: {'–¥–∞' if color_required else '–Ω–µ—Ç'}\n"
        f"- –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø–æ–ª—è: {missing_ru}\n"
        + product_warning
        + bag_note +
        "–ü–†–ê–í–ò–õ–û: —Ñ—Ä–∞–∑—É '–•–æ—Ä–æ—à–æ, –æ—Ñ–æ—Ä–º–ª—è–µ–º –∑–∞–∫–∞–∑' –º–æ–∂–Ω–æ –ø–∏—Å–∞—Ç—å —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –ø–æ–ª–µ–π –Ω–µ—Ç.\n"
        "–ü–†–ê–í–ò–õ–û: –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –∑–∞–¥–∞—ë—Ç –≤–æ–ø—Ä–æ—Å (—Ü–µ–Ω–∞, –∫–∞—á–µ—Å—Ç–≤–æ, –¥–æ—Å—Ç–∞–≤–∫–∞) ‚Äî –°–ù–ê–ß–ê–õ–ê –æ—Ç–≤–µ—Ç—å –Ω–∞ –µ–≥–æ –≤–æ–ø—Ä–æ—Å, –ü–û–¢–û–ú —Å–æ–±–∏—Ä–∞–π –¥–∞–Ω–Ω—ã–µ –∑–∞–∫–∞–∑–∞. –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏–≥–Ω–æ—Ä–∏—Ä—É–π –≤–æ–ø—Ä–æ—Å –∫–ª–∏–µ–Ω—Ç–∞."
    )


async def _extract_order_fields(
    user_message: str, history: list[dict], current_ctx: dict, product_names: list[str] | None = None
) -> dict:
    history_text = "\n".join(
        f"{m.get('role')}: {m.get('content')}" for m in history[-8:]
    )
    catalog_hint = ""
    if product_names:
        catalog_hint = (
            "\n–ù–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞ (–∏—Å–ø–æ–ª—å–∑—É–π –ò–ú–ï–ù–ù–û —ç—Ç–∏ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è –ø–æ–ª—è product): "
            + ", ".join(product_names[:10])
            + "\n"
        )
    system_text = (
        "–ò–∑–≤–ª–µ–∫–∏ –¥–∞–Ω–Ω—ã–µ –∑–∞–∫–∞–∑–∞ –¢–û–õ–¨–ö–û –∏–∑ –¢–ï–ö–£–©–ï–ì–û —Å–æ–æ–±—â–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞. –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ JSON.\n"
        "–ü–æ–ª—è JSON: city, product, product_type, size, color, address, ready_to_order.\n"
        "–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –∏–∑–≤–ª–µ–∫–∞–π –¥–∞–Ω–Ω—ã–µ –¢–û–õ–¨–ö–û –∏–∑ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è, –ù–ï –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –ø–µ—Ä–µ–ø–∏—Å–∫–∏.\n"
        "–ï—Å–ª–∏ –≤ —Ç–µ–∫—É—â–µ–º —Å–æ–æ–±—â–µ–Ω–∏–∏ –Ω–µ—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –ø–æ–ª—è ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–π –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è —ç—Ç–æ–≥–æ –ø–æ–ª—è.\n"
        "–ù–ï –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–π –∏ –ù–ï –ø–æ–≤—Ç–æ—Ä—è–π –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ—Ñ–∏–ª—è.\n"
        "–í–ê–ñ–ù–û –¥–ª—è –ø–æ–ª—è product: –∏—Å–ø–æ–ª—å–∑—É–π –¢–û–ß–ù–û–ï –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å).\n"
        "–ù–µ –∫–æ–ø–∏—Ä—É–π —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç –∫–ª–∏–µ–Ω—Ç–∞. –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –Ω–∞–ø–∏—Å–∞–ª '—Å—É–º–∫—É —Å–∞–Ω –ª–æ—Ä–∞–Ω —á–µ—Ä–Ω—É—é', "
        "–∞ –≤ –∫–∞—Ç–∞–ª–æ–≥–µ –µ—Å—Ç—å 'Yves Saint Laurent Monogram' ‚Äî –≤–µ—Ä–Ω–∏ 'Yves Saint Laurent Monogram'.\n"
        "product_type —Ç–æ–ª—å–∫–æ: shoes, bag, accessory, other, unknown.\n"
        "–ï—Å–ª–∏ –ø–æ–ª–µ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–π –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É.\n"
        "ready_to_order = true —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç —è–≤–Ω–æ –≥–æ—Ç–æ–≤ –æ—Ñ–æ—Ä–º–∏—Ç—å/–∫—É–ø–∏—Ç—å."
        + catalog_hint
    )
    user_text = (
        f"–¢–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: {user_message}\n"
        f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ—Ñ–∏–ª—è: {json.dumps(current_ctx, ensure_ascii=False)}\n"
        f"–ò—Å—Ç–æ—Ä–∏—è: {history_text}"
    )
    try:
        completion = await openai_client.chat.completions.create(
            model=OPENAI_MODEL,
            temperature=0,
            max_tokens=220,
            response_format={"type": "json_object"},
            messages=[
                {"role": "system", "content": system_text},
                {"role": "user", "content": user_text},
            ],
        )
        raw = completion.choices[0].message.content or "{}"
        parsed = json.loads(raw)
        return {
            "city": str(parsed.get("city") or ""),
            "product": str(parsed.get("product") or ""),
            "product_type": str(parsed.get("product_type") or ""),
            "size": str(parsed.get("size") or ""),
            "color": str(parsed.get("color") or ""),
            "address": str(parsed.get("address") or ""),
            "ready_to_order": bool(parsed.get("ready_to_order", False)),
        }
    except Exception as e:
        logger.warning(f"Failed to extract order fields: {e}")
        return {
            "city": "",
            "product": "",
            "product_type": "",
            "size": "",
            "color": "",
            "address": "",
            "ready_to_order": False,
        }


def _strip_duplicate_trust_message(text: str, history: list[dict]) -> str:
    """–£–±–∏—Ä–∞–µ–º –ø–æ–≤—Ç–æ—Ä '–≤–∞–∂–Ω—ã–π –º–æ–º–µ–Ω—Ç' / trust message, –µ—Å–ª–∏ –±–æ—Ç —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª—è–ª –µ–≥–æ —Ä–∞–Ω–µ–µ."""
    trust_already_sent = False
    for m in history:
        if m.get("role") == "assistant":
            content = (m.get("content") or "").lower()
            if any(marker in content for marker in _TRUST_MSG_MARKERS):
                trust_already_sent = True
                break
    if not trust_already_sent:
        return text
    # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ ||| –∏ —É–±–∏—Ä–∞–µ–º —á–∞—Å—Ç–∏, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ trust –º–∞—Ä–∫–µ—Ä—ã
    parts = [p.strip() for p in text.split("|||") if p.strip()]
    kept = []
    for part in parts:
        part_lower = part.lower()
        if any(marker in part_lower for marker in _TRUST_MSG_MARKERS):
            continue
        kept.append(part)
    return "|||".join(kept) if kept else text


def _strip_duplicate_greeting(text: str, history: list[dict]) -> str:
    """–£–±–∏—Ä–∞–µ–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –∏–∑ –æ—Ç–≤–µ—Ç–∞ GPT, –µ—Å–ª–∏ –±–æ—Ç —É–∂–µ –∑–¥–æ—Ä–æ–≤–∞–ª—Å—è –≤ —ç—Ç–æ–π –ø–µ—Ä–µ–ø–∏—Å–∫–µ."""
    bot_already_greeted = False
    for m in history:
        if m.get("role") == "assistant":
            content = (m.get("content") or "").lower()
            if any(g in content for g in _GREETING_WORDS):
                bot_already_greeted = True
                break

    if not bot_already_greeted:
        return text

    # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ ||| –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—É—é —á–∞—Å—Ç—å
    parts = [p.strip() for p in text.split("|||") if p.strip()]
    if not parts:
        return text

    first_lower = parts[0].lower().strip()
    # –ï—Å–ª–∏ –ø–µ—Ä–≤–∞—è —á–∞—Å—Ç—å ‚Äî –∫–æ—Ä–æ—Ç–∫–æ–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ (–¥–æ 30 —Å–∏–º–≤–æ–ª–æ–≤), —É–±–∏—Ä–∞–µ–º
    if any(first_lower.startswith(g) for g in _GREETING_WORDS) and len(first_lower) < 30:
        parts = parts[1:]

    if not parts:
        return text

    return "|||".join(parts)


def _caption_from_filename(filename: str) -> str:
    """'–∫—Ä–æ—Å—Å–æ–≤–∫–∏ —á–µ—Ä–Ω—ã–µ Golden Goose Ball Star.jpg' -> 'Golden Goose Ball Star'"""
    # 1. –£–¥–∞–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
    name = re.sub(r'\.\w+$', '', filename)
    # 2. –£–¥–∞–ª—è–µ–º –∫–∏—Ä–∏–ª–ª–∏—Ü—É (–ª—é–±—ã–µ —Ä—É—Å—Å–∫–∏–µ —Å–ª–æ–≤–∞ –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏)
    name = re.sub(r'[–∞-—è–ê-–Ø—ë–Å]+', '', name)
    # 2a. –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥–ª–∏ –æ—Å—Ç–∞—Ç—å—Å—è (–∑–∞–ø—è—Ç—ã–µ, —Ç–∏—Ä–µ –ø–æ –∫—Ä–∞—è–º)
    name = re.sub(r'^[^\w\d]+|[^\w\d]+$', '', name) # Trim non-alphanumeric from ends
    name = re.sub(r'[,.;:]', ' ', name) # Replace punctuation with spaces
    # 3. –£–¥–∞–ª—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–µ–∫—Å—ã –≤ –∫–æ–Ω—Ü–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, " 1", " 02")
    name = re.sub(r'\s+\d{1,2}$', '', name.strip())
    # 4. –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥–ª–∏ –æ—Å—Ç–∞—Ç—å—Å—è –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è —Ä—É—Å—Å–∫–∏—Ö —Å–ª–æ–≤
    name = re.sub(r'\s{2,}', ' ', name)
    return name.strip()


# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–≤–µ—Ç–∞ –≤ —Ç–µ–∫—Å—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
_COLOR_PREFIXES = {
    "—Ä–æ–∑–æ–≤": "—Ä–æ–∑–æ–≤—ã–µ", "pink": "—Ä–æ–∑–æ–≤—ã–µ",
    "—á–µ—Ä–Ω": "—á–µ—Ä–Ω—ã–µ", "black": "—á–µ—Ä–Ω—ã–µ",
    "–±–µ–∂": "–±–µ–∂–µ–≤—ã–µ", "beige": "–±–µ–∂–µ–≤—ã–µ",
    "–±–µ–ª": "–±–µ–ª—ã–µ", "white": "–±–µ–ª—ã–µ",
    "–∫—Ä–∞—Å–Ω": "–∫—Ä–∞—Å–Ω—ã–µ", "red": "–∫—Ä–∞—Å–Ω—ã–µ",
    "—Å–∏–Ω–∏–π": "—Å–∏–Ω–∏–µ", "—Å–∏–Ω–∏—Ö": "—Å–∏–Ω–∏–µ", "—Å–∏–Ω–∏–µ": "—Å–∏–Ω–∏–µ",
    "–∑–æ–ª–æ—Ç": "–∑–æ–ª–æ—Ç—ã–µ", "gold": "–∑–æ–ª–æ—Ç—ã–µ",
    "—Å–µ—Ä–µ–±—Ä": "—Å–µ—Ä–µ–±—Ä—è–Ω—ã–µ", "silver": "—Å–µ—Ä–µ–±—Ä—è–Ω—ã–µ",
    "–∫–æ—Ä–∏—á–Ω–µ–≤": "–∫–æ—Ä–∏—á–Ω–µ–≤—ã–µ", "brown": "–∫–æ—Ä–∏—á–Ω–µ–≤—ã–µ",
    "–∑–µ–ª–µ–Ω": "–∑–µ–ª–µ–Ω—ã–µ", "green": "–∑–µ–ª–µ–Ω—ã–µ",
}


def _detect_color_in_text(text: str) -> str | None:
    """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ü–≤–µ—Ç, —É–ø–æ–º—è–Ω—É—Ç—ã–π –≤ —Ç–µ–∫—Å—Ç–µ. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∫–ª—é—á –∏–ª–∏ None."""
    t = text.lower()
    for prefix, color_key in _COLOR_PREFIXES.items():
        if prefix in t:
            return color_key
    return None


def _detect_color_from_filename(filename: str) -> str:
    f = (filename or "").lower()
    for prefix, color_name in _COLOR_PREFIXES.items():
        if prefix in f:
            return color_name
    return ""


async def _is_color_required(product_name: str) -> bool:
    product = (product_name or "").strip().lower()
    if not product:
        return False
    cached = _COLOR_REQUIREMENT_CACHE.get(product)
    if cached is not None:
        value, ts = cached
        if time.time() - ts < _COLOR_CACHE_TTL:
            return value
    try:
        photos = await find_product_photos(product_name=product_name)
        colors = {_detect_color_from_filename(p.get("filename", "")) for p in photos}
        colors.discard("")
        required = len(colors) > 1
        _COLOR_REQUIREMENT_CACHE[product] = (required, time.time())
        return required
    except Exception as e:
        logger.warning(f"Failed to detect color requirement for '{product_name}': {e}")
        return False


async def _get_available_colors_for_product(product_name: str) -> set[str]:
    product = (product_name or "").strip()
    if not product:
        return set()
    try:
        photos = await find_product_photos(product_name=product)
        colors = {_detect_color_from_filename(p.get("filename", "")) for p in photos}
        colors.discard("")
        return colors
    except Exception as e:
        logger.warning(f"Failed to list available colors for '{product_name}': {e}")
        return set()


def _product_key_from_filename(filename: str) -> str:
    """–ò–∑–≤–ª–µ—á—å –∫–ª—é—á —Ç–æ–≤–∞—Ä–∞ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏.
    '–°—É–º–∫–∞ —á–µ—Ä–Ω–∞—è Chanel 25 2.jpg' ‚Üí '—Å—É–º–∫–∞ —á–µ—Ä–Ω–∞—è chanel 25'
    '—Å—É–º–∫–∞ Miu Miu Arcadie 1.jpg' ‚Üí '—Å—É–º–∫–∞ miu miu arcadie'
    """
    name = filename.lower()
    name = re.sub(r'\.\w+$', '', name)  # —É–±—Ä–∞—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
    name = re.sub(r'\s+\d+$', '', name)  # —É–±—Ä–∞—Ç—å –ø–æ—Ä—è–¥–∫–æ–≤—ã–π –Ω–æ–º–µ—Ä —Ñ–æ—Ç–æ
    return name.strip()


def _pick_product_photos(
    found_photos: list[dict],
    requested_color: str | None = None,
    max_showcase: int | None = None,
) -> list[dict]:
    """
    –í—ã–±—Ä–∞—Ç—å —Ñ–æ—Ç–æ —Ç–æ–≤–∞—Ä–∞.
    - requested_color –∑–∞–¥–∞–Ω ‚Üí –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–æ —Ü–≤–µ—Ç—É, –æ—Ç–¥–∞—Ç—å –≤—Å–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ
    - requested_color = None ‚Üí –æ–±–∑–æ—Ä–Ω—ã–π —Ä–µ–∂–∏–º:
      - –µ—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ ‚Üí –ø–æ 1 —Ñ–æ—Ç–æ –∫–∞–∂–¥–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ (–≤–∏—Ç—Ä–∏–Ω–∞)
      - –µ—Å–ª–∏ –æ–¥–∏–Ω —Ç–æ–≤–∞—Ä ‚Üí –ø–æ 1 —Ñ–æ—Ç–æ –∫–∞–∂–¥–æ–≥–æ —Ü–≤–µ—Ç–∞
    """
    limit = max_showcase or MAX_PHOTOS_PRODUCT_SHOWCASE
    if requested_color:
        # –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ü–≤–µ—Ç ‚Äî —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –∏ –æ—Ç–¥–∞—ë–º –≤—Å–µ
        color_prefixes = [p for p, key in _COLOR_PREFIXES.items() if key == requested_color]
        matching = [
            img for img in found_photos
            if any(cp in img.get("filename", "").lower() for cp in color_prefixes)
        ]
        # –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –∑–∞–ø—Ä–æ—Å–∏–ª –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ü–≤–µ—Ç –∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ—Ç, –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥—Ä—É–≥–æ–π —Ü–≤–µ—Ç.
        source = matching
        source = _dedupe_photos(source)
        return [
            {
                "file_id": p["file_id"],
                "caption": _caption_from_filename(p["filename"]),
                "filename": p["filename"],
            }
            for p in source[:limit]
        ]
    else:
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–æ–≤–∞—Ä—É (–±–µ–∑ –Ω–æ–º–µ—Ä–∞ —Ñ–æ—Ç–æ –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è)
        product_groups: dict[str, list[dict]] = {}
        for p in found_photos:
            key = _product_key_from_filename(p.get("filename", ""))
            product_groups.setdefault(key, []).append(p)

        if len(product_groups) > 1:
            # –í–∏—Ç—Ä–∏–Ω–∞: –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ ‚Üí –ø–æ 1 —Ñ–æ—Ç–æ –∫–∞–∂–¥–æ–≥–æ
            picked = []
            for key in product_groups:
                picked.append(product_groups[key][0])
                if len(picked) >= limit:
                    break
            picked = _dedupe_photos(picked)
        else:
            # –û–¥–∏–Ω —Ç–æ–≤–∞—Ä ‚Äî –ø–æ 1 —Ñ–æ—Ç–æ –∫–∞–∂–¥–æ–≥–æ —Ü–≤–µ—Ç–∞
            picked = select_photos_with_color_variety(
                found_photos,
                max_total=limit,
                max_per_color=1,
            )
            picked = _dedupe_photos(picked)
        return [
            {
                "file_id": p["file_id"],
                "caption": _caption_from_filename(p["filename"]),
                "filename": p["filename"],
            }
            for p in picked
        ]


async def generate_response(chat_id: str, user_message: str, sender_name: str) -> dict:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –±–æ—Ç–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: {'text': str, 'photos': list[dict]}
    """
    # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ö–æ–¥—è—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    await save_message(chat_id, "user", user_message, sender_name)

    # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –¥–æ–∂–∏–º –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç –æ—Ç–≤–µ—á–∞–µ—Ç
    await reset_nudge_state(chat_id)

    # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–µ—Å—Ç–∞—Ö –Ω–∏–∂–µ)
    user_tokens = tokenize_text(user_message)

    # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —á–∏—Ç–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞–∫–∞–∑–∞, —á—Ç–æ–±—ã –Ω–µ —Ç–µ—Ä—è—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–π —Ç–æ–≤–∞—Ä
    current_order_ctx = await get_order_context(chat_id)
    requested_product_type = _infer_product_type_from_text(user_message)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –ø—Ä–æ—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç –ª–∏ –∫–ª–∏–µ–Ω—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é ("–∫–∞–∫–∏–µ —Å—É–º–∫–∏ –µ—Å—Ç—å?")
    browsing_category = _is_category_browsing(user_message)
    browsing_type = _detect_browsing_category(user_message) if browsing_category else ""

    # –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –ø–µ—Ä–µ–∫–ª—é—á–∏–ª—Å—è –Ω–∞ –î–†–£–ì–£–Æ –∫–∞—Ç–µ–≥–æ—Ä–∏—é ‚Äî —Å–±—Ä–æ—Å–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞–∫–∞–∑–∞
    if browsing_category and current_order_ctx.get("product"):
        old_type = current_order_ctx.get("product_type", "")
        if browsing_type and old_type and browsing_type != old_type:
            logger.info(f"[{chat_id}] Category switch: {old_type} -> {browsing_type}, resetting order context")
            current_order_ctx = {"product_type": browsing_type}
            await upsert_order_context(chat_id, current_order_ctx)
        elif browsing_category:
            # –¢–∞ –∂–µ –∏–ª–∏ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è, –Ω–æ –∫–ª–∏–µ–Ω—Ç —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç "–∫–∞–∫–∏–µ –µ—Å—Ç—å" ‚Äî —Å–±—Ä–æ—Å —Ç–æ–≤–∞—Ä–∞
            logger.info(f"[{chat_id}] Category browsing detected, clearing product from order context")
            current_order_ctx["product"] = ""
            current_order_ctx["size"] = ""
            current_order_ctx["color"] = ""
            current_order_ctx["address"] = ""
            if browsing_type:
                current_order_ctx["product_type"] = browsing_type
            await upsert_order_context(chat_id, current_order_ctx)

    product_query = user_message
    if _should_use_active_product_query(user_message, current_order_ctx.get("product", "")):
        product_query = current_order_ctx.get("product", "") or user_message

    # 2. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –∏—â–µ–º –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
    product_results, script_results = await asyncio.gather(
        search_products(product_query),
        search_scripts(user_message),
    )
    if requested_product_type:
        filtered_results = []
        for r in product_results:
            result_type = _infer_result_product_type(r)
            if not result_type or result_type == requested_product_type:
                filtered_results.append(r)
        product_results = filtered_results
    primary_product_match = _pick_primary_product_match(product_results, user_message)
    specific_query_tokens = _extract_specific_query_tokens(user_message)

    # 3. –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã
    product_context = "\n---\n".join([r["text"] for r in product_results])
    product_context = product_context or "–ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –≤ –±–∞–∑–µ."

    sales_context = "\n---\n".join([r["text"] for r in script_results])
    sales_context = sales_context or "–ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å–∫—Ä–∏–ø—Ç–æ–≤."

    # 4. –ò—Å—Ç–æ—Ä–∏—è –ø–µ—Ä–µ–ø–∏—Å–∫–∏
    history = await get_conversation_history(chat_id)
    is_new_client = len(history) <= 1
    history_text = "\n".join(
        [f"{'–ö–ª–∏–µ–Ω—Ç' if m['role'] == 'user' else '–ê–ª–∏–Ω–∞'}: {m['content']}"
         for m in history
         if not m['content'].startswith("[–ü–æ–∫–∞–∑–∞–Ω—ã —Ñ–æ—Ç–æ:")]
    )

    order_ctx = current_order_ctx
    # –°–æ–±–∏—Ä–∞–µ–º –∫–∞–Ω–æ–Ω–∏—á–Ω—ã–µ –∏–º–µ–Ω–∞ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ RAG –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
    _rag_product_names = []
    for r in product_results:
        _name = _extract_product_name_from_result(r)
        if _name and _name not in _rag_product_names:
            _rag_product_names.append(_name)
    extracted_fields = await _extract_order_fields(user_message, history, order_ctx, _rag_product_names)
    llm_ready_to_order = bool(extracted_fields.get("ready_to_order", False))

    rag_product_name = ""
    if product_results:
        rag_product_name = _extract_product_name_from_result(product_results[0]) or ""
    target_product_type = requested_product_type or _infer_product_type_from_text(primary_product_match or rag_product_name)

    # –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —Ä–∞—Å–ø–ª—ã–≤—á–∞—Ç–æ–µ ("–ö–∞–∫–∏–µ?", "–ü–æ–∫–∞–∂–∏") –∏ —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω ‚Äî
    # –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    assistant_context_hint = ""
    if not target_product_type and _is_vague_followup(user_message) and history:
        for m in reversed(history):
            if m.get("role") == "assistant":
                last_assistant_text = m.get("content", "")
                inferred_type = _infer_product_type_from_assistant_message(last_assistant_text)
                if inferred_type:
                    target_product_type = inferred_type
                    assistant_context_hint = _extract_search_hint_from_assistant(last_assistant_text)
                    logger.info(
                        f"[{chat_id}] Vague followup '{user_message}' ‚Äî inferred type "
                        f"'{target_product_type}' from assistant: '{last_assistant_text[:80]}'"
                    )
                break

    similar_product_names = _collect_similar_product_names(
        product_results,
        requested_type=target_product_type,
        exclude_names={primary_product_match} if primary_product_match else set(),
        limit=3,
    )

    # –ü—Ä–∏ browse –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ù–ï –Ω–∞–∑–Ω–∞—á–∞–µ–º RAG –ø—Ä–æ–¥—É–∫—Ç –≤ –∑–∞–∫–∞–∑ (–∫–ª–∏–µ–Ω—Ç –µ—â—ë –Ω–µ –≤—ã–±—Ä–∞–ª)
    # –¢–∞–∫–∂–µ –Ω–µ –Ω–∞–∑–Ω–∞—á–∞–µ–º –µ—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å —Ç–æ–≤–∞—Ä–æ–º (–Ω–∞–ø—Ä. "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ")
    if (
        rag_product_name
        and not extracted_fields.get("product")
        and not order_ctx.get("product")
        and not browsing_category
        and (user_tokens & tokenize_text(rag_product_name))  # —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ —É–ø–æ–º–∏–Ω–∞—Ç—å —Ç–æ–≤–∞—Ä
    ):
        extracted_fields["product"] = rag_product_name
    if not extracted_fields.get("product_type"):
        extracted_fields["product_type"] = _infer_product_type_from_text(
            extracted_fields.get("product") or rag_product_name
        )
    if target_product_type:
        extracted_fields["product_type"] = target_product_type

    # Before merge ‚Äî capture what WAS missing (for is_answering_missing_field check later)
    color_required_pre = await _is_color_required(order_ctx.get("product", ""))
    pre_merge_missing = _build_missing_fields(order_ctx, color_required_pre)

    order_ctx = _merge_order_context(order_ctx, extracted_fields)
    if (
        not order_ctx.get("product")
        and rag_product_name
        and not browsing_category
        and (user_tokens & tokenize_text(rag_product_name))
    ):
        order_ctx["product"] = rag_product_name
    if not order_ctx.get("product_type"):
        order_ctx["product_type"] = _infer_product_type_from_text(order_ctx.get("product", ""))

    await upsert_order_context(chat_id, order_ctx)

    # ‚îÄ‚îÄ –ë—ã—Å—Ç—Ä—ã–π –ø—É—Ç—å: –æ–∂–∏–¥–∞–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –∑–∞–∫–∞–∑–∞ –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞ ‚îÄ‚îÄ
    pending_confirm = await get_order_pending_confirm(chat_id)
    if pending_confirm:
        if _is_order_confirmation(user_message):
            # –ö–ª–∏–µ–Ω—Ç –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª ‚Äî –æ—Ñ–æ—Ä–º–ª—è–µ–º –∑–∞–∫–∞–∑
            confirm_text = "–û—Ç–ª–∏—á–Ω–æ, –æ—Ñ–æ—Ä–º–ª—è—é –∑–∞–∫–∞–∑! –°–∫–æ—Ä–æ —Å–≤—è–∂–µ–º—Å—è —Å –≤–∞–º–∏ –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è –¥–µ—Ç–∞–ª–µ–π –¥–æ—Å—Ç–∞–≤–∫–∏ ‚ú®"
            await save_message(chat_id, "assistant", confirm_text, "–ê–ª–∏–Ω–∞")
            await set_order_pending_confirm(chat_id, False)
            asyncio.create_task(notify_order_confirmed(chat_id, order_ctx, sender_name))
            asyncio.create_task(notify_order_to_group(chat_id, order_ctx, sender_name))
            logger.info(f"[{chat_id}] Order confirmed by client, notifications sent")
            return {"text": confirm_text, "photos": []}
        else:
            await set_order_pending_confirm(chat_id, False)
            logger.info(f"[{chat_id}] Client did not confirm order, resetting pending flag")
            if order_ctx.get("order_type") == "preorder":
                order_ctx.update({
                    "product": "", "product_type": "", "size": "",
                    "color": "", "order_type": "alternatives_offered",
                })
                await upsert_order_context(chat_id, order_ctx)
                clarify_text = (
                    "–•–æ—Ä–æ—à–æ! –î–∞–≤–∞–π—Ç–µ –ø–æ–¥–±–µ—Ä—ë–º –¥—Ä—É–≥–æ–π –≤–∞—Ä–∏–∞–Ω—Ç. "
                    "–£—Ç–æ—á–Ω–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞ ‚Äî –¥—Ä—É–≥–æ–π —Ü–≤–µ—Ç, —Ä–∞–∑–º–µ—Ä –∏–ª–∏ —Å–æ–≤—Å–µ–º –¥—Ä—É–≥–∞—è –º–æ–¥–µ–ª—å? ‚ú®"
                )
                await save_message(chat_id, "assistant", clarify_text, "–ê–ª–∏–Ω–∞")
                logger.info(f"[{chat_id}] Pre-order declined ‚Äî cleared product fields, offering alternatives")
                return {"text": clarify_text, "photos": [], "is_new_client": is_new_client,
                        "order_context": order_ctx, "missing_order_fields": []}

    # ‚îÄ‚îÄ –ö–ª–∏–µ–Ω—Ç –Ω–µ –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω –ø–æ—Å–ª–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤ ‚Üí –ø—Ä–∏–≥–ª–∞—à–∞–µ–º –Ω–∞ –ø—Ä–∏–º–µ—Ä–∫—É ‚îÄ‚îÄ
    if order_ctx.get("order_type") == "alternatives_offered":
        if _is_negative_or_undecided(user_message):
            order_ctx["order_type"] = ""
            await upsert_order_context(chat_id, order_ctx)
            store_text = (
                "–ë—É–¥–µ–º —Ä–∞–¥—ã –≤–∏–¥–µ—Ç—å –≤–∞—Å –≤ –Ω–∞—à–µ–º —à–æ—É—Ä—É–º–µ! üë† "
                "–í—ã —Å–º–æ–∂–µ—Ç–µ –ø—Ä–∏–º–µ—Ä–∏—Ç—å –∏ –≤—ã–±—Ä–∞—Ç—å –∏–¥–µ–∞–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –≤–∂–∏–≤—É—é."
                "|||üìç –ê–¥—Ä–µ—Å: –≥. –ê–ª–º–∞—Ç—ã, –ï–≥–∏–∑–±–∞–µ–≤–∞ 7/2"
                "\nüïô –†–∞–±–æ—Ç–∞–µ–º –µ–∂–µ–¥–Ω–µ–≤–Ω–æ —Å 10:00 –¥–æ 22:00"
                "\nhttps://2gis.kz/almaty/geo/70000001107511471"
            )
            tg_text = (
                "–¢–∞–∫–∂–µ –≤—ã –º–æ–∂–µ—Ç–µ —Å–ª–µ–¥–∏—Ç—å –∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º–∏ —Ç–æ–≤–∞—Ä–æ–≤ –≤ –Ω–∞—à–µ–º —Ç–µ–ª–µ–≥—Ä–∞–º –∫–∞–Ω–∞–ª–µ ‚ú®"
                "|||https://t.me/kzottenokkz"
            )
            full_text = store_text + "|||" + tg_text
            clean = full_text.replace("|||", " ").strip()
            await save_message(chat_id, "assistant", clean, "–ê–ª–∏–Ω–∞")
            logger.info(f"[{chat_id}] Client declined alternatives ‚Äî sent store address + Telegram")
            return {
                "text": full_text,
                "photos": [],
                "is_new_client": is_new_client,
                "order_context": order_ctx,
                "missing_order_fields": [],
            }
        else:
            # –ö–ª–∏–µ–Ω—Ç –≤—Å—ë –∂–µ –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç—Å—è —á–µ–º-—Ç–æ –¥—Ä—É–≥–∏–º ‚Äî —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥, –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π —Ñ–ª–æ—É
            order_ctx["order_type"] = ""
            await upsert_order_context(chat_id, order_ctx)

    color_required = await _is_color_required(order_ctx.get("product", ""))
    missing_order_fields = _build_missing_fields(order_ctx, color_required)

    # ‚îÄ‚îÄ –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–æ–≤–∞—Ä–∞ –ø–µ—Ä–µ–¥ —Å–±–æ—Ä–æ–º –∞–¥—Ä–µ—Å–∞ ‚îÄ‚îÄ
    # –ö–æ–≥–¥–∞ –≤—Å–µ –ø–æ–ª—è –∫—Ä–æ–º–µ –∞–¥—Ä–µ—Å–∞ —Å–æ–±—Ä–∞–Ω—ã (–∏–ª–∏ –≤—Å–µ —Å–æ–±—Ä–∞–Ω—ã) ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤ –∫–∞—Ç–∞–ª–æ–≥–µ.
    # –ï—Å–ª–∏ —Ç–æ–≤–∞—Ä–∞ –Ω–µ—Ç ‚Äî –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º –ø—Ä–µ–¥–∑–∞–∫–∞–∑ –≤–º–µ—Å—Ç–æ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è.
    if (
        not order_ctx.get("order_type")          # –µ—â—ë –Ω–µ –æ–ø—Ä–µ–¥–µ–ª—è–ª–∏ —Ç–∏–ø –∑–∞–∫–∞–∑–∞
        and order_ctx.get("product")
        and order_ctx.get("city")
        and (missing_order_fields == ["address"] or not missing_order_fields)
    ):
        try:
            availability = check_product_availability(
                order_ctx.get("product", ""),
                order_ctx.get("size", ""),
                order_ctx.get("color", ""),
            )
            logger.info(
                f"[{chat_id}] Inventory check for '{order_ctx['product']}' "
                f"size='{order_ctx.get('size')}' color='{order_ctx.get('color')}': "
                f"available={availability['available']}, qty={availability['quantity']}"
            )
            if not availability["available"]:
                item_desc = _build_item_desc(order_ctx)
                preorder_text = (
                    f"–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, {item_desc} —Å–µ–π—á–∞—Å –Ω–µ—Ç –≤ –Ω–∞–ª–∏—á–∏–∏. "
                    "–ù–æ –º—ã –º–æ–∂–µ–º –æ—Ñ–æ—Ä–º–∏—Ç—å –ø—Ä–µ–¥–∑–∞–∫–∞–∑ ‚Äî 50% –ø—Ä–µ–¥–æ–ø–ª–∞—Ç–∞, –æ—Å—Ç–∞—Ç–æ–∫ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏."
                    "|||–ü–æ—á–µ–º—É –ø—Ä–µ–¥–∑–∞–∫–∞–∑ —ç—Ç–æ —É–¥–æ–±–Ω–æ –¥–ª—è –≤–∞—Å:\n\n"
                    "‚Ä¢ –ú—ã –≤—ã–∫—É–ø–∞–µ–º —Ç–æ–≤–∞—Ä –Ω–∞–ø—Ä—è–º—É—é —É –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞, –±–µ–∑ –ø–µ—Ä–µ–∫—É–ø–æ–≤ ‚Äî –ø–æ—ç—Ç–æ–º—É —Ü–µ–Ω–∞ –Ω–∏–∂–µ, —á–µ–º —É –±–∞–π–µ—Ä–æ–≤.\n"
                    "‚Ä¢ –¢–æ–≤–∞—Ä —Ç–∞–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –º—ã –Ω–∞—à–ª–∏ –Ω–µ —Å –ø–µ—Ä–≤–æ–≥–æ —Ä–∞–∑–∞. –°–º–æ—Ç—Ä–µ–ª–∏ –≤—Å—é –±–∞—Ä–∞—Ö–æ–ª–∫—É, –≤–µ–∑–¥–µ –ø—Ä–æ–¥–∞—é—Ç —Å—Ä–µ–¥–Ω–µ–µ –ª–∏–±–æ –Ω–∏–∂–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞. –ò –ø—Ä–æ–¥–∞—é—Ç –ª—é–¥—è–º. –î–ª—è –Ω–∞—Å —ç—Ç–æ –Ω–µ —ç—Ç–∏—á–Ω–æ. –ü–æ—Ç–æ–º—É —á—Ç–æ —Ü–µ–Ω—ã —É –Ω–∏—Ö –≤ 80% —Å–ª—É—á–∞–µ–≤ –Ω–µ —Å—Ç–æ—è—Ç —Ç–æ–≥–æ.\n"
                    "‚Ä¢ –í–∞–º –Ω–µ –Ω—É–∂–Ω–æ –ø–ª–∞—Ç–∏—Ç—å 100%, –∫–∞–∫ —Ç—Ä–µ–±—É—é—Ç –±–∞–π–µ—Ä—ã. –ú—ã –±–µ—Ä–µ–º –≤—Å–µ–≥–æ 50% –ø—Ä–µ–¥–æ–ø–ª–∞—Ç—É, –æ—Å—Ç–∞–ª—å–Ω–æ–µ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏.\n"
                    "‚Ä¢ –¢–æ–≤–∞—Ä –∑–∞–∫—Ä–µ–ø–ª—è–µ—Ç—Å—è –∏–º–µ–Ω–Ω–æ –∑–∞ –≤–∞–º–∏ ‚Äî —Ä–∞–∑–º–µ—Ä/—Ü–≤–µ—Ç —Ä–µ–∑–µ—Ä–≤–∏—Ä—É–µ–º, –∏ –Ω–∏–∫—Ç–æ –¥—Ä—É–≥–æ–π —É–∂–µ –Ω–µ –∫—É–ø–∏—Ç.\n\n"
                    "–ï—Å–ª–∏ –ø–æ—Å—Ç–∞–≤—â–∏–∫ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∏–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –ø—Ä–∏—Ö–æ–¥–∏—Ç ‚Äî –º—ã –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–ø–ª–∞—Ç—É. –≠—Ç–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ."
                    "|||–ö–∞–∫ –ø—Ä–æ—Ö–æ–¥–∏—Ç –ø—Ä–æ—Ü–µ—Å—Å:\n"
                    "1. –í—ã –æ—Å—Ç–∞–≤–ª—è–µ—Ç–µ —Ä–∞–∑–º–µ—Ä –∏ –≤–Ω–æ—Å–∏—Ç–µ 50% –ø—Ä–µ–¥–æ–ø–ª–∞—Ç—É.\n"
                    "2. –ú—ã –≤—ã–∫—É–ø–∞–µ–º —Ç–æ–≤–∞—Ä –Ω–∞–ø—Ä—è–º—É—é.\n"
                    "3. –°—Ä–∞–∑—É –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤–∞–º —á–µ–∫/—Å–∫—Ä–∏–Ω –∑–∞–∫—É–ø–∞ –∏ –¥–∞—Ç—É –ø—Ä–∏–±—ã—Ç–∏—è."
                    "|||–û—Ñ–æ—Ä–º–ª—è–µ–º –ø—Ä–µ–¥–∑–∞–∫–∞–∑? ‚ú®"
                )
                order_ctx["order_type"] = "preorder"
                await upsert_order_context(chat_id, order_ctx)
                await set_order_pending_confirm(chat_id, True)
                clean_text = preorder_text.replace("|||", " ").strip()
                await save_message(chat_id, "assistant", clean_text, "–ê–ª–∏–Ω–∞")
                logger.info(f"[{chat_id}] Product unavailable ‚Äî offering pre-order for '{item_desc}'")
                return {
                    "text": preorder_text,
                    "photos": [],
                    "is_new_client": is_new_client,
                    "order_context": order_ctx,
                    "missing_order_fields": [],
                }
        except Exception as e:
            logger.warning(f"[{chat_id}] Inventory check failed: {e}")

    order_guard_prompt = _format_order_context_for_prompt(order_ctx, missing_order_fields, color_required)

    system_prompt = SYSTEM_PROMPT.format(
        product_context=product_context,
        sales_context=sales_context,
        conversation_history=history_text,
    ) + "\n\n" + order_guard_prompt

    # 6. –í—ã–∑—ã–≤–∞–µ–º GPT
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_message},
    ]

    completion = await openai_client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=messages,
        temperature=0.7,
        max_tokens=700,
    )

    assistant_text = completion.choices[0].message.content
    logger.info(f"[{chat_id}] RAW GPT response: {assistant_text[:500]}")
    logger.info(f"[{chat_id}] product_context (first 300): {product_context[:300]}")
    logger.info(f"[{chat_id}] order_guard_prompt: {order_guard_prompt[:300]}")

    # 7a. –£–±–∏—Ä–∞–µ–º –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –∏ trust message –Ω–∞ —É—Ä–æ–≤–Ω–µ –∫–æ–¥–∞
    assistant_text = _strip_duplicate_greeting(assistant_text, history)
    assistant_text = _strip_duplicate_trust_message(assistant_text, history)
    user_order_intent = _has_order_intent(user_message)
    logger.info(f"[{chat_id}] user_order_intent={user_order_intent}, user_message={user_message[:100]}")
    # –ù–µ —Å—á–∏—Ç–∞–µ–º –∑–∞–∫–∞–∑ "–≥–æ—Ç–æ–≤—ã–º" —Ç–æ–ª—å–∫–æ –ø–æ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏—é LLM –±–µ–∑ —è–≤–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ –∫–ª–∏–µ–Ω—Ç–∞.
    ready_to_order = user_order_intent
    address_just_collected = bool((extracted_fields.get("address") or "").strip())
    if not user_order_intent:
        stripped = _strip_checkout_prompts(assistant_text)
        logger.info(f"[{chat_id}] After _strip_checkout_prompts: '{stripped[:300]}'")
        if stripped:
            assistant_text = stripped
        elif not missing_order_fields and (llm_ready_to_order or address_just_collected):
            # –í—Å–µ –ø–æ–ª—è —Å–æ–±—Ä–∞–Ω—ã, –∑–∞–∫–∞–∑ –±—É–¥–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω –Ω–∏–∂–µ ‚Äî –Ω–µ –Ω—É–∂–µ–Ω fallback
            assistant_text = ""
        else:
            assistant_text = "–°–µ–π—á–∞—Å —É—Ç–æ—á–Ω—é –ø–æ –º–æ–¥–µ–ª–∏ –∏ –Ω–∞–ª–∏—á–∏—é."

    # 7b. –ñ–µ—Å—Ç–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –¥–æ —Å–±–æ—Ä–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –∑–∞–∫–∞–∑ –Ω–µ –æ—Ñ–æ—Ä–º–ª—è–µ–º
    if missing_order_fields:
        if _contains_order_confirm(assistant_text):
            assistant_text = _strip_order_confirm(assistant_text)
        # –ó–∞–¥–∞–µ–º –≤–æ–ø—Ä–æ—Å –æ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –ø–æ–ª—è—Ö –µ—Å–ª–∏:
        # 1. –ö–ª–∏–µ–Ω—Ç —Ö–æ—á–µ—Ç –∑–∞–∫–∞–∑–∞—Ç—å –ò–õ–ò —Ç–æ–ª—å–∫–æ —á—Ç–æ –¥–∞–ª–∏ –∞–¥—Ä–µ—Å (–∫–∞–∫ —Ä–∞–Ω—å—à–µ)
        # 2. –ò–õ–ò —Ç–æ–≤–∞—Ä –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –≤ order_ctx (–∫–ª–∏–µ–Ω—Ç –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç—Å—è —Ç–æ–≤–∞—Ä–æ–º)
        # 3. –ù–û –ù–ï –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–∏ (is_new_client) - —Ç–æ–≥–¥–∞ –ø—Ä–æ–º–ø—Ç —Å–∞–º –∑–∞–¥–∞—Å—Ç –≤–æ–ø—Ä–æ—Å
        should_force_missing_question = (
            not is_new_client  # –î–æ–±–∞–≤–ª–µ–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞: –Ω–µ –∑–∞–¥–∞–µ–º –¥–æ–ø. –≤–æ–ø—Ä–æ—Å—ã –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∫–æ–Ω—Ç–∞–∫—Ç–µ
            and not browsing_category  # –ù–ï –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –ø—Ä–∏ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            and (
                ready_to_order
                or address_just_collected
                or bool(order_ctx.get("product"))
            )
        )
        if should_force_missing_question and not _assistant_already_requests_missing(assistant_text, missing_order_fields) and not _has_question(assistant_text):
            assistant_text = f"{assistant_text}|||{_question_for_missing(missing_order_fields[0])}".strip("|")
    elif (ready_to_order or address_just_collected or llm_ready_to_order):
        # –í—Å–µ –ø–æ–ª—è —Å–æ–±—Ä–∞–Ω—ã ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–≤–æ–¥–∫—É –∏ –∂–¥—ë–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞
        assistant_text = _build_order_summary(order_ctx)
        await set_order_pending_confirm(chat_id, True)
        logger.info(f"[{chat_id}] All fields collected, showing order summary for confirmation")

    assistant_text = _dedupe_response_parts(assistant_text)

    # 8. –ò—â–µ–º —Ñ–æ—Ç–æ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ Google Drive
    photos = []

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º —Ñ–æ—Ç–æ: –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ü–≤–µ—Ç ‚Üí –≤—Å–µ —Ñ–æ—Ç–æ —ç—Ç–æ–≥–æ —Ü–≤–µ—Ç–∞, –∏–Ω–∞—á–µ ‚Üí –ø–æ 1 –∫–∞–∂–¥–æ–≥–æ —Ü–≤–µ—Ç–∞
    requested_color = _detect_color_in_text(user_message)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Ç–≤–µ—á–∞–µ—Ç –ª–∏ –∫–ª–∏–µ–Ω—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –æ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –ø–æ–ª—è—Ö
    # –ï—Å–ª–∏ –¥–∞ - –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–æ—Ç–æ –∑–∞–Ω–æ–≤–æ
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º pre_merge_missing (–¥–æ —Å–ª–∏—è–Ω–∏—è), —Ç.–∫. –ø–æ—Å–ª–µ merge –ø–æ–ª–µ —É–∂–µ –Ω–µ "missing"
    is_answering_missing_field = False
    if pre_merge_missing and extracted_fields:
        for field in pre_merge_missing:
            if extracted_fields.get(field):
                is_answering_missing_field = True
                break

    # –ü—Ä–∏ browse –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ ‚Äî —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π –ª–∏–º–∏—Ç —Ñ–æ—Ç–æ, —á—Ç–æ–±—ã –ø–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –º–æ–¥–µ–ª–∏
    photo_showcase_limit = MAX_PHOTOS_PRODUCT_SHOWCASE
    if browsing_category:
        photo_showcase_limit = max(MAX_PHOTOS_PRODUCT_SHOWCASE, 10)

    # Primary: search photos by user message text (most reliable)
    # –ö–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –æ –Ω–µ–¥–æ—Å—Ç–∞—é—â–µ–º –ø–æ–ª–µ (—Ü–≤–µ—Ç, —Ä–∞–∑–º–µ—Ä, –≥–æ—Ä–æ–¥),
    # –∏—â–µ–º –ø–æ —Ç–æ–≤–∞—Ä—É –∏–∑ –∑–∞–∫–∞–∑–∞, –∞ –Ω–µ –ø–æ —Å—ã—Ä–æ–º—É —Å–æ–æ–±—â–µ–Ω–∏—é ("–ß–µ—Ä–Ω—ã–µ" ‚Üí –≤—Å–µ —á—ë—Ä–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã)
    primary_search_query = user_message
    if is_answering_missing_field and order_ctx.get("product"):
        primary_search_query = order_ctx["product"]
        logger.info(f"[{chat_id}] Answering missing field ‚Äî photo search by order product: {primary_search_query}")
    try:
        found_photos = await find_product_photos(product_name=primary_search_query)
        if found_photos:
            photos.extend(_pick_product_photos(found_photos, requested_color, max_showcase=photo_showcase_limit))
    except Exception as e:
        logger.warning(f"[{chat_id}] Failed to find photos by message text: {e}")

    if (
        not photos
        and not is_answering_missing_field
        and order_ctx.get("product")
        and (
            not target_product_type
            or _infer_product_type_from_text(order_ctx.get("product", "")) in {"", target_product_type}
        )
    ):
        try:
            found_photos = await find_product_photos(product_name=order_ctx["product"])
            if found_photos:
                photos.extend(_pick_product_photos(found_photos, requested_color))
        except Exception as e:
            logger.warning(f"[{chat_id}] Failed to find photos by order context: {e}")

    # Fallback: search by RAG metadata (—Ç–æ–≤–∞—Ä—ã –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π)
    # –ü—Ä–æ–±—É–µ–º –≤—Å–µ product_name –∏–∑ RAG, –Ω–µ —Ç–æ–ª—å–∫–æ —Ç–µ —á—Ç–æ —Å–æ–≤–ø–∞–ª–∏ —Å —Ç–µ–∫—É—â–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º ‚Äî
    # –∫–ª–∏–µ–Ω—Ç –º–æ–≥ –Ω–∞–ø–∏—Å–∞—Ç—å "—Å –∞–ª–º–∞—Ç—ã, 38", –∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –ø—Ä–æ –±–∞–ª–µ—Ç–∫–∏
    if not photos and not is_answering_missing_field:
        for result in product_results:
            meta = result.get("metadata", {})
            photo_folder_id = meta.get("photo_folder_id", "")
            product_name = meta.get("product_name", "")

            if not (photo_folder_id or product_name):
                continue
            # –ï—Å–ª–∏ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –µ—Å—Ç—å —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ ‚Äî –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç; –∏–Ω–∞—á–µ –≤—Å—ë —Ä–∞–≤–Ω–æ –ø—Ä–æ–±—É–µ–º (–¥–∏–∞–ª–æ–≥ —É–∂–µ –ø—Ä–æ —Ç–æ–≤–∞—Ä)
            if product_name and user_tokens:
                product_tokens = tokenize_text(product_name)
                if not (user_tokens & product_tokens) and len(history) <= 2:
                    continue
            try:
                folder_photos = await find_product_photos(
                    folder_id=photo_folder_id or None,
                    product_name=product_name or None,
                )
                if folder_photos:
                    photos.extend(_pick_product_photos(folder_photos, requested_color))
                    break
            except Exception as e:
                logger.warning(f"[{chat_id}] Failed to find photos for {product_name}: {e}")

    # Stage 3: search by product mention in GPT response (not full text)
    if not photos and not is_answering_missing_field:
        gpt_product = _extract_product_mention(assistant_text)
        if gpt_product:
            try:
                found_photos = await find_product_photos(product_name=gpt_product)
                if found_photos:
                    photos.extend(_pick_product_photos(found_photos, requested_color))
            except Exception as e:
                logger.warning(f"[{chat_id}] Failed to find photos by GPT response product '{gpt_product}': {e}")

    # Stage 4: –µ—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –ø—Ä–æ—Å–∏—Ç —Ñ–æ—Ç–æ ("–ø–æ–∫–∞–∂–∏—Ç–µ —Ñ–æ—Ç–∫—É"), –∞ —Ç–æ–≤–∞—Ä –Ω–µ –≤ —Ç–µ–∫—É—â–µ–º —Å–æ–æ–±—â–µ–Ω–∏–∏ ‚Äî
    # –∏—â–µ–º –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É —Å–æ–æ–±—â–µ–Ω–∏—é –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞, –≥–¥–µ –±—ã–ª –æ–ø–∏—Å–∞–Ω —Ç–æ–≤–∞—Ä (—Ü–µ–Ω–∞, –º–æ–¥–µ–ª—å)
    if not photos and not is_answering_missing_field and len(history) >= 2 and _is_photo_request(user_message):
        last_product_text = None
        for m in reversed(history):
            if m.get("role") != "assistant":
                continue
            content = (m.get("content") or "").strip()
            if len(content) < 20:
                continue
            if "—Ü–µ–Ω–∞" in content.lower() or "‚Ç∏" in content or "–º–æ–¥–µ–ª" in content.lower() or "chanel" in content.lower():
                last_product_text = content
                break
        if last_product_text:
            try:
                found_photos = await find_product_photos(product_name=last_product_text)
                if found_photos:
                    photos.extend(_pick_product_photos(found_photos, requested_color))
                    logger.info(f"[{chat_id}] Found {len(photos)} photos by last assistant product message")
            except Exception as e:
                logger.warning(f"[{chat_id}] Failed to find photos by last assistant message: {e}")

    # Stage 5: vague followup ‚Äî –∏—â–µ–º –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    if not photos and not is_answering_missing_field and assistant_context_hint:
        try:
            found_photos = await find_product_photos(product_name=assistant_context_hint)
            if found_photos:
                photos.extend(_pick_product_photos(found_photos, requested_color))
                logger.info(
                    f"[{chat_id}] Found {len(photos)} photos by assistant context hint "
                    f"'{assistant_context_hint}'"
                )
        except Exception as e:
            logger.warning(f"[{chat_id}] Failed to find photos by assistant hint '{assistant_context_hint}': {e}")

    if not photos and target_product_type:
        for q in _build_fallback_photo_queries(user_message, target_product_type):
            try:
                found_photos = await find_product_photos(product_name=q)
                if found_photos:
                    photos.extend(_pick_product_photos(found_photos, requested_color))
                    break
            except Exception as e:
                logger.warning(f"[{chat_id}] Failed fallback photo query '{q}': {e}")

    # –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –ø—Ä–æ—Å–∏—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ü–≤–µ—Ç, –Ω–æ —ç—Ç–æ–≥–æ —Ü–≤–µ—Ç–∞ –Ω–µ—Ç –≤ —Ñ–æ—Ç–æ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞,
    # –Ω–µ –ø–æ–¥–º–µ–Ω—è–µ–º –æ—Ç–≤–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ–º –¥—Ä—É–≥–æ–≥–æ —Ü–≤–µ—Ç–∞.
    color_unavailable = False
    color_alternatives: list[str] = []
    if requested_color:
        active_product_name = order_ctx.get("product", "") or rag_product_name
        if active_product_name:
            available_colors = await _get_available_colors_for_product(active_product_name)
            if not available_colors:
                available_colors = _get_product_color_overrides(active_product_name)

            if available_colors and requested_color not in available_colors:
                assistant_text = _format_color_unavailable_message(
                    active_product_name,
                    requested_color,
                    available_colors,
                )
                photos = []
                color_unavailable = True
                if order_ctx.get("color") == requested_color:
                    order_ctx["color"] = ""
                    await upsert_order_context(chat_id, order_ctx)
            elif not photos and available_colors and requested_color in available_colors:
                # –¶–≤–µ—Ç –∑–∞—è–≤–ª–µ–Ω –∫–∞–∫ –¥–æ—Å—Ç—É–ø–Ω—ã–π, –Ω–æ —Ñ–æ—Ç–æ —ç—Ç–æ–≥–æ —Ü–≤–µ—Ç–∞ –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –Ω–µ –ø–æ–¥–º–µ–Ω—è–µ–º –¥—Ä—É–≥–∏–º —Ü–≤–µ—Ç–æ–º.
                assistant_text = (
                    f"–ü–æ –º–æ–¥–µ–ª–∏ {active_product_name} —Ü–≤–µ—Ç {requested_color} –µ—Å—Ç—å, "
                    "—Å–µ–π—á–∞—Å —É—Ç–æ—á–Ω—é –∏ –æ—Ç–ø—Ä–∞–≤–ª—é –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ñ–æ—Ç–æ."
                )
            elif not photos:
                assistant_text = _format_color_unavailable_message(
                    active_product_name,
                    requested_color,
                    available_colors,
                )
                color_unavailable = True

    if color_unavailable:
        color_alternatives = similar_product_names or _fallback_alternative_names(
            target_product_type,
            exclude_names={order_ctx.get("product", ""), rag_product_name},
            limit=3,
        )
        assistant_text = _append_similar_products_text(assistant_text, color_alternatives)
        if not photos:
            for alt in color_alternatives:
                try:
                    found_alt = await find_product_photos(product_name=alt)
                    if not found_alt:
                        continue
                    alt_photos = _pick_product_photos(found_alt, None)
                    if target_product_type:
                        alt_photos = _filter_photos_by_requested_type(alt_photos, target_product_type)
                    if alt_photos:
                        photos = alt_photos
                        break
                except Exception as e:
                    logger.warning(f"[{chat_id}] Failed to get color-alternative photos for '{alt}': {e}")

    if target_product_type:
        photos = _filter_photos_by_requested_type(photos, target_product_type)
        if not photos:
            for q in _build_fallback_photo_queries(user_message, target_product_type):
                try:
                    found_photos = await find_product_photos(product_name=q)
                    if found_photos:
                        photos.extend(_pick_product_photos(found_photos, requested_color))
                        photos = _filter_photos_by_requested_type(photos, target_product_type)
                        if photos:
                            break
                except Exception as e:
                    logger.warning(f"[{chat_id}] Failed typed fallback photo query '{q}': {e}")

    if _is_photo_request(user_message) and not photos:
        product_label = order_ctx.get("product", "") or rag_product_name or "—ç—Ç—É –º–æ–¥–µ–ª—å"
        if target_product_type == "shoes":
            assistant_text = (
                f"–ü–æ –∑–∞–ø—Ä–æ—Å—É –Ω–∞ —Ç—É—Ñ–ª–∏ —Ñ–æ—Ç–æ —Å–µ–π—á–∞—Å –Ω–µ –≤–∏–∂—É. "
                f"–ú–æ–≥—É –ø–æ–¥–æ–±—Ä–∞—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ {product_label}. "
                "–ü–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ –µ—Å—Ç—å –≤ –Ω–∞–ª–∏—á–∏–∏?"
            )
        elif target_product_type == "bag":
            assistant_text = (
                f"–ü–æ –∑–∞–ø—Ä–æ—Å—É –Ω–∞ —Å—É–º–∫—É —Ñ–æ—Ç–æ —Å–µ–π—á–∞—Å –Ω–µ –≤–∏–∂—É. "
                f"–ú–æ–≥—É –ø–æ–∫–∞–∑–∞—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ {product_label}. "
                "–ü–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ –µ—Å—Ç—å –≤ –Ω–∞–ª–∏—á–∏–∏?"
            )
        else:
            assistant_text = (
                f"–ü–æ –∑–∞–ø—Ä–æ—Å—É —Ñ–æ—Ç–æ —Å–µ–π—á–∞—Å –Ω–µ –≤–∏–∂—É –≤ –∫–∞—Ç–∞–ª–æ–≥–µ –¥–ª—è {product_label}. "
                "–ú–æ–≥—É –ø–æ–¥–æ–±—Ä–∞—Ç—å –±–ª–∏–∂–∞–π—à–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏ –ø–æ–∫–∞–∑–∞—Ç—å –∏—Ö."
            )

    model_unavailable = False
    if (
        _is_availability_request(user_message)
        and specific_query_tokens
        and not browsing_category
        and primary_product_match
        and not photos  # –ï—Å–ª–∏ —Ñ–æ—Ç–æ —É–∂–µ –Ω–∞—à–ª–∏—Å—å ‚Äî —Ç–æ–≤–∞—Ä –µ—Å—Ç—å, –Ω–µ –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã–π
    ):
        match_tokens = tokenize_text(primary_product_match or "")
        if not (specific_query_tokens & match_tokens):
            model_unavailable = True

    if model_unavailable:
        # –ò—Å–∫–ª—é—á–∞–µ–º —Ç–æ–≤–∞—Ä—ã, —Ñ–æ—Ç–æ –∫–æ—Ç–æ—Ä—ã—Ö —É–∂–µ –±—ã–ª–∏ –Ω–∞–π–¥–µ–Ω—ã/–ø–æ–∫–∞–∑–∞–Ω—ã –≤ —ç—Ç–æ–º –∑–∞–ø—Ä–æ—Å–µ
        _shown_product_names = set()
        for p in photos:
            cap = _caption_from_filename(p.get("filename", ""))
            if cap:
                _shown_product_names.add(cap.lower())
        _exclude = {primary_product_match, rag_product_name, order_ctx.get("product", "")} | _shown_product_names
        alternatives = _collect_similar_product_names(
            product_results,
            requested_type=target_product_type,
            exclude_names=_exclude,
            limit=3,
        )
        if not alternatives:
            alternatives = _collect_similar_product_names(product_results, requested_type="", exclude_names=_exclude, limit=3)
        if not alternatives:
            alternatives = _fallback_alternative_names(
                target_product_type,
                exclude_names={order_ctx.get("product", ""), rag_product_name},
                limit=3,
            )
        assistant_text = "–¢–∞–∫–æ–π –º–æ–¥–µ–ª–∏ —Å–µ–π—á–∞—Å –Ω–µ—Ç –≤ –Ω–∞–ª–∏—á–∏–∏."
        assistant_text = _append_similar_products_text(assistant_text, alternatives)
        photos = []
        for alt in alternatives:
            try:
                found_alt = await find_product_photos(product_name=alt)
                if not found_alt:
                    continue
                alt_photos = _pick_product_photos(found_alt, None)
                if target_product_type:
                    alt_photos = _filter_photos_by_requested_type(alt_photos, target_product_type)
                if alt_photos:
                    photos = alt_photos
                    break
            except Exception as e:
                logger.warning(f"[{chat_id}] Failed to get similar product photos for '{alt}': {e}")

    photos = _dedupe_photos(photos)
    photos = _normalize_photo_captions(photos)

    # –ü–æ—Å–ª–µ –ø–æ–∫–∞–∑–∞ —Ñ–æ—Ç–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ ‚Äî –¥–æ–±–∞–≤–∏—Ç—å –≤–æ–ø—Ä–æ—Å "–ö–∞–∫—É—é –≤—ã–±–∏—Ä–∞–µ—Ç–µ?"
    if browsing_category and photos and "?" not in assistant_text:
        assistant_text = f"{assistant_text}|||–ö–∞–∫—É—é –º–æ–¥–µ–ª—å —Ö–æ—Ç–∏—Ç–µ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –ø–æ–±–ª–∏–∂–µ? üòä"

    assistant_text = _dedupe_response_parts(assistant_text)
    clean_text = assistant_text.replace("|||", " ").strip()
    clean_text = re.sub(r'\s{2,}', ' ', clean_text)
    await save_message(chat_id, "assistant", clean_text)

    if photos:
        logger.info(f"[{chat_id}] Found {len(photos)} photos")

    return {
        "text": assistant_text,
        "photos": photos[:photo_showcase_limit],
        "is_new_client": is_new_client,
        "order_context": order_ctx,
        "missing_order_fields": missing_order_fields,
    }


async def handle_message(chat_id: str, sender_name: str, text: str):
    """
    –û—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π (–≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ webhook).
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —á–µ—Ä–µ–∑ Green API.
    """
    try:
        # Manager handoff commands (sent from manager's number to bot)
        if chat_id in MANAGER_CHAT_IDS:
            action, target_chat_id = _parse_handoff_command(text)
            if action:
                if not target_chat_id:
                    await send_text(
                        chat_id,
                        "–£–∫–∞–∂–∏—Ç–µ –Ω–æ–º–µ—Ä –∫–ª–∏–µ–Ω—Ç–∞. –ü—Ä–∏–º–µ—Ä: /handoff on 77064071507",
                    )
                    return
                if action == "status":
                    enabled = await get_handoff_state(target_chat_id)
                    await send_text(
                        chat_id,
                        f"–°—Ç–∞—Ç—É—Å –¥–ª—è {target_chat_id}: {'ON' if enabled else 'OFF'}",
                    )
                    return
                if action == "on":
                    await set_handoff_state(target_chat_id, True)
                    await send_text(chat_id, f"–•—ç–Ω–¥-–æ—Ñ—Ñ –≤–∫–ª—é—á–µ–Ω –¥–ª—è {target_chat_id}")
                    return
                if action == "off":
                    await set_handoff_state(target_chat_id, False)
                    await send_text(chat_id, f"–•—ç–Ω–¥-–æ—Ñ—Ñ –≤—ã–∫–ª—é—á–µ–Ω –¥–ª—è {target_chat_id}")
                    return

        # If handoff enabled for this client, save message but don't reply
        if await get_handoff_state(chat_id):
            await save_message(chat_id, "user", text, sender_name)
            await update_last_client_message(chat_id, text)
            logger.info(f"[{chat_id}] Handoff enabled; saved message, bot skipped reply.")
            return

        result = await generate_response(chat_id, text, sender_name)

        # For new clients: insert trust message right after greeting
        is_new = result.get("is_new_client", False)

        # Split response by ||| and send as separate messages
        # Filter out internal markers that GPT may reproduce from history
        parts = [
            p.strip() for p in result["text"].split("|||")
            if p.strip() and not p.strip().startswith("[–ü–æ–∫–∞–∑–∞–Ω—ã —Ñ–æ—Ç–æ:")
        ]

        if is_new and parts:
            # Insert trust message after the first part (greeting)
            trust_msg = (
                "–°—Ä–∞–∑—É —Å–∫–∞–∂—É –≤–∞–∂–Ω—ã–π –º–æ–º–µ–Ω—Ç, —á—Ç–æ–±—ã –≤—ã –Ω–µ –ø–µ—Ä–µ–∂–∏–≤–∞–ª–∏: "
                "–º—ã –º–∞–≥–∞–∑–∏–Ω Ottenok, –Ω–µ –±–∞–π–µ—Ä—ã ‚Äî —É –Ω–∞—Å –µ—Å—Ç—å –º–∞–≥–∞–∑–∏–Ω, –ø—Ä–∏–º–µ—Ä–∫–∞, –æ–±–º–µ–Ω –∏ –≤–æ–∑–≤—Ä–∞—Ç. "
                "–ò –ø–æ —Ü–µ–Ω–µ –º—ã –Ω–∏–∂–µ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –±–∞–π–µ—Ä–æ–≤, –ø–æ—Ç–æ–º—É —á—Ç–æ —Ä–∞–±–æ—Ç–∞–µ–º –Ω–∞–ø—Ä—è–º—É—é —Å –ª—É—á—à–∏–º–∏ —Ñ–∞–±—Ä–∏–∫–∞–º–∏"
            )
            parts.insert(1, trust_msg)
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º trust message –≤ –∏—Å—Ç–æ—Ä–∏—é, —á—Ç–æ–±—ã GPT –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–ª –µ–≥–æ
            await save_message(chat_id, "assistant", trust_msg, "–ê–ª–∏–Ω–∞")

        # Determine if we should send photos
        should_send_photos = False
        if result["photos"]:
            is_photo_request = _is_photo_request(text)
            product_key = _build_product_key(tokenize_text(text), result["photos"])

            if is_photo_request or _is_category_browsing(text):
                # –ö–ª–∏–µ–Ω—Ç –ø—Ä–æ—Å–∏—Ç –ø–æ–∫–∞–∑–∞—Ç—å/–ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–∂–µ –µ—Å–ª–∏ —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏
                should_send_photos = True
            elif product_key and not await has_sent_product_photos(chat_id, product_key):
                # –ù–æ–≤—ã–π —Ç–æ–≤–∞—Ä, —Ñ–æ—Ç–æ –µ—â—ë –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏
                should_send_photos = True

        if should_send_photos:
            # Send text BEFORE photos, then photos, then follow-up question AFTER photos
            follow_up = None
            # –û—Ç–¥–µ–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —á–∞—Å—Ç—å –∫–∞–∫ follow_up, –µ—Å–ª–∏ –æ–Ω–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –∑–Ω–∞–∫
            if parts and "?" in parts[-1]:
                follow_up = parts[-1]
                parts = parts[:-1]

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —á–∞—Å—Ç–∏ –î–û —Ñ–æ—Ç–æ
            for part in parts:
                await send_text(chat_id, part)
                if len(parts) > 1:
                    await asyncio.sleep(0.8)

            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–ø–∏—Å–∏ –∫ —Ñ–æ—Ç–æ (–Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏) –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ reply
            photos_with_captions = []
            photo_names = []
            for img in result["photos"]:
                fname = img.get("filename", "")
                caption = _product_key_from_filename(fname) if fname else ""
                # –ö—Ä–∞—Å–∏–≤–∞—è –ø–æ–¥–ø–∏—Å—å: —É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã, capitalize
                caption = re.sub(r'\s+', ' ', caption).strip()
                if caption:
                    caption = caption[0].upper() + caption[1:]
                photo_names.append(caption or fname)
                photos_with_captions.append({**img, "caption": caption})

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–æ—Ç–æ
            await send_multiple_images(chat_id, photos_with_captions)
            if product_key:
                await mark_product_photos_sent(chat_id, product_key)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ –ø–æ–∫–∞–∑–∞–Ω–Ω—ã—Ö —Ñ–æ—Ç–æ –≤ –∏—Å—Ç–æ—Ä–∏—é, —á—Ç–æ–±—ã GPT –∑–Ω–∞–ª –∫–æ–Ω—Ç–µ–∫—Å—Ç
            unique_names = list(dict.fromkeys(photo_names))  # —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–æ—Ä—è–¥–æ–∫, —É–±—Ä–∞—Ç—å –¥—É–±–ª–∏
            if unique_names:
                photo_note = "[–ü–æ–∫–∞–∑–∞–Ω—ã —Ñ–æ—Ç–æ: " + ", ".join(unique_names) + "]"
                await save_message(chat_id, "assistant", photo_note, "")

            # –°–æ–æ–±—â–µ–Ω–∏–µ –æ –∫–∞—á–µ—Å—Ç–≤–µ ‚Äî —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–ª—å–∫–æ 1 —Ä–∞–∑ –∑–∞ –¥–∏–∞–ª–æ–≥
            is_specific_product = not _is_category_browsing(text)
            quality_already_sent = await has_sent_product_photos(chat_id, "__quality_msg__")
            if is_specific_product and not quality_already_sent:
                await asyncio.sleep(0.8)
                quality_msg = (
                    "–≠—Ç–æ 1:1 –ª—é–∫—Å-–∫–∞—á–µ—Å—Ç–≤–æ ‚Äî –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–µ —à–≤—ã, –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞, "
                    "–∫–æ–∂–∞ –ø–ª–æ—Ç–Ω–∞—è, –Ω–∏—á–µ–≥–æ –Ω–µ —Ç–æ—Ä—á–∏—Ç.\n\n"
                    "–ú—ã —Ç–∞–∫–∏–µ –º–æ–¥–µ–ª–∏ –æ—Ç–±–∏—Ä–∞–µ–º –¥–æ–ª–≥–æ, –ø–æ—Ç–æ–º—É —á—Ç–æ —Å—Ä–∞–∑—É –≤–∏–¥–Ω–æ —É—Ä–æ–≤–µ–Ω—å."
                )
                await send_text(chat_id, quality_msg)
                await mark_product_photos_sent(chat_id, "__quality_msg__")

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤–æ–ø—Ä–æ—Å –ü–û–°–õ–ï —Ñ–æ—Ç–æ
            if follow_up:
                await asyncio.sleep(0.8)
                await send_text(chat_id, follow_up)
        else:
            for part in parts:
                await send_text(chat_id, part)
                if len(parts) > 1:
                    await asyncio.sleep(0.8)

    except Exception as e:
        logger.error(f"[{chat_id}] Error handling message: {e}", exc_info=True)
        await notify_error("handle_message", f"chat_id={chat_id} error={e}")
        try:
            await send_text(
                chat_id,
                "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–±–æ–ª—å—à–∞—è –æ—à–∏–±–∫–∞. –ù–∞—à –º–µ–Ω–µ–¥–∂–µ—Ä —Å–∫–æ—Ä–æ —Å –≤–∞–º–∏ —Å–≤—è–∂–µ—Ç—Å—è!",
            )
        except Exception:
            logger.error(f"[{chat_id}] Failed to send error fallback", exc_info=True)

