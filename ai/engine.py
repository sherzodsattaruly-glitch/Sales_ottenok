"""
AI-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä: —Å–≤—è–∑—ã–≤–∞–µ—Ç RAG, GPT –∏ Google Drive.
–ì–ª–∞–≤–Ω–∞—è —Ç–æ—á–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π.
"""

import asyncio
import json
import logging
import re

from openai import AsyncOpenAI

from ai.prompts import SYSTEM_PROMPT
from ai.rag import search_products, search_scripts
from db.conversations import (
    get_conversation_history,
    save_message,
    has_sent_product_photos,
    mark_product_photos_sent,
    get_handoff_state,
    set_handoff_state,
    get_order_context,
    upsert_order_context,
    reset_nudge_state,
    update_last_client_message,
)
from gdrive.photo_mapper import find_product_photos, tokenize_text, select_photos_with_color_variety
from inventory.stock_checker import check_product_availability, format_availability_message
from greenapi.client import send_text, send_multiple_images
from config import (
    OPENAI_API_KEY,
    OPENAI_MODEL,
    MAX_PHOTOS_PER_MESSAGE,
    MAX_PHOTOS_PRODUCT_SHOWCASE,
    MAX_PHOTOS_PER_COLOR,
    MANAGER_CHAT_IDS,
)

logger = logging.getLogger(__name__)

openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)

_PHOTO_REQUEST_PATTERNS = [
    "—Ñ–æ—Ç–æ", "—Ñ–æ—Ç–∫—É", "—Ñ–æ—Ç–∫–∏", "—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é", "—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é", "—Å–Ω–∏–º–æ–∫",
    "–ø–æ–∫–∞–∂–∏", "–ø–æ–∫–∞–∂–∏—Ç–µ", "–ø–æ–∫–∞–∂–µ—à—å", "–ø–æ–∫–∞–∑–∞—Ç—å", "–ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å",
    "—Å–∫–∏–Ω—å", "—Å–∫–∏–Ω—å—Ç–µ", "–ø—Ä–∏—à–ª–∏", "–ø—Ä–∏—à–ª–∏—Ç–µ", "–∫–∏–Ω—å", "–∫–∏–Ω—å—Ç–µ",
    "–æ—Ç–ø—Ä–∞–≤—å", "–æ—Ç–ø—Ä–∞–≤—å—Ç–µ",
]

_PRODUCT_HINT_TOKENS = {
    "chanel", "—à–∞–Ω–µ–ª", "—à–∞–Ω–µ–ª—å", "miu", "miu miu", "–¥–∂–∏–º–º–∏", "jimmy", "choo",
    "gucci", "dior", "saint", "laurent", "golden", "goose", "jimbo", "–¥–∂—É–º–±–æ",
    "classic", "flap", "arcadie", "azia", "saeda", "opyum", "25", "yves",
}
_PRODUCT_RAW_HINTS = [
    "—à–∞–Ω–µ–ª", "chanel", "–¥–∂—É–º–±–æ", "jumbo", "–∫–ª–∞—Å—Å–∏–∫", "classic", "flap",
    "–¥–∂–∏–º–º–∏", "jimmy", "—á—É", "choo", "—Å–∞–µ–¥–∞", "saeda", "–∞–∑–∏—è", "azia",
    "–º–∏—É", "miu", "arcadie", "—Å–ª–∏–Ω–≥–±—ç–∫", "slingback",
]


def _is_photo_request(text: str) -> bool:
    t = text.lower()
    if any(p in t for p in _PHOTO_REQUEST_PATTERNS):
        return True
    if re.search(r"–∫–∞–∫\s+–æ–Ω\s+–≤—ã–≥–ª—è–¥", t):
        return True
    if re.search(r"–∫–∞–∫\s+–≤—ã–≥–ª—è–¥–∏—Ç", t):
        return True
    return False


def _build_product_key(user_tokens: set[str], photos: list[dict]) -> str:
    if photos:
        tokens = tokenize_text(photos[0].get("filename", ""))
    else:
        tokens = set(user_tokens)
    tokens = [t for t in tokens if t]
    if not tokens:
        return ""
    return "|".join(sorted(tokens))


def _should_use_active_product_query(user_message: str, active_product: str) -> bool:
    if not active_product:
        return False
    user_tokens = tokenize_text(user_message)
    product_tokens = tokenize_text(active_product)
    if user_tokens & product_tokens:
        return False
    text_l = user_message.lower()
    if any(h in text_l for h in _PRODUCT_RAW_HINTS):
        return False
    # If user explicitly names another product/brand, keep current message as query.
    if any(tok in _PRODUCT_HINT_TOKENS for tok in user_tokens):
        return False
    return True


def _dedupe_photos(photos: list[dict]) -> list[dict]:
    seen = set()
    result = []
    for p in photos:
        key = p.get("file_id") or p.get("filename") or p.get("direct_url")
        if not key or key in seen:
            continue
        seen.add(key)
        result.append(p)
    return result


def _normalize_photo_captions(photos: list[dict]) -> list[dict]:
    """–û—Å—Ç–∞–≤–ª—è–µ—Ç –ø–æ–¥–ø–∏—Å—å —É –∫–∞–∂–¥–æ–π —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ (–Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏)."""
    if not photos:
        return photos
    normalized = []
    for p in photos:
        item = dict(p)
        # –ë–æ–ª—å—à–µ –Ω–µ –æ—á–∏—â–∞–µ–º –ø–æ–¥–ø–∏—Å—å –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö —Ñ–æ—Ç–æ, –∫–∞–∫ –ø—Ä–æ—Å–∏–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
        normalized.append(item)
    return normalized


def _extract_chat_id(text: str) -> str:
    # Prefer explicit chatId
    m = re.search(r"(\d{8,15})@c\.us", text)
    if m:
        return f"{m.group(1)}@c.us"
    # Fallback to digits
    digits = re.findall(r"\d{8,15}", text)
    if digits:
        return f"{digits[-1]}@c.us"
    # Fallback: join all digits (handles spaces in phone numbers)
    digits_all = re.sub(r"\D", "", text)
    if 8 <= len(digits_all) <= 15:
        return f"{digits_all}@c.us"
    return ""


def _parse_handoff_command(text: str) -> tuple[str | None, str | None]:
    t = text.strip().lower()
    if not (t.startswith("/handoff") or t.startswith("handoff") or t.startswith("/human") or t.startswith("human")):
        return None, None
    if " on" in t or t.endswith(" on"):
        action = "on"
    elif " off" in t or t.endswith(" off"):
        action = "off"
    elif " status" in t or t.endswith(" status"):
        action = "status"
    else:
        action = None
    target = _extract_chat_id(text)
    return action, target


_GREETING_WORDS = ["–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ", "–ø—Ä–∏–≤–µ—Ç", "–¥–æ–±—Ä—ã–π –¥–µ–Ω—å", "–¥–æ–±—Ä—ã–π –≤–µ—á–µ—Ä", "–¥–æ–±—Ä–æ–µ —É—Ç—Ä–æ"]

_ORDER_CONFIRM_TEXT = "–•–æ—Ä–æ—à–æ, –æ—Ñ–æ—Ä–º–ª—è–µ–º –∑–∞–∫–∞–∑"
_SIZE_REQUIRED_TYPES = {"shoes", "clothes"}
_COLOR_REQUIREMENT_CACHE: dict[str, bool] = {}
_ORDER_INTENT_PATTERNS = [
    "–æ—Ñ–æ—Ä–º", "–∑–∞–∫–∞–∑", "–±–µ—Ä—É", "–≤–æ–∑—å–º—É", "–ø–æ–∫—É–ø", "–∫—É–ø–ª—é", "–∑–∞—Ñ–∏–∫—Å", "–∞–¥—Ä–µ—Å –¥–æ—Å—Ç–∞–≤–∫–∏",
]
_CHECKOUT_HINTS = [
    "–∑–∞—Ñ–∏–∫—Å", "–æ—Ñ–æ—Ä–º–∏—Ç—å –∑–∞–∫–∞–∑", "–æ—Ñ–æ—Ä–º–ª—è–µ–º –∑–∞–∫–∞–∑", "–∞–¥—Ä–µ—Å –¥–æ—Å—Ç–∞–≤–∫–∏", "–Ω–∞–ø–∏—à–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∞–¥—Ä–µ—Å", "–∫—É–¥–∞ –æ—Ç–ø—Ä–∞–≤",
]
_FIELD_PROMPT_HINTS = {
    "city": ["–≥–æ—Ä–æ–¥", "–∏–∑ –∫–∞–∫–æ–≥–æ", "–æ—Ç–∫—É–¥–∞"],
    "product": ["–∫–∞–∫—É—é –º–æ–¥–µ–ª—å", "–∫–∞–∫–æ–π —Ç–æ–≤–∞—Ä", "—á—Ç–æ –æ—Ñ–æ—Ä–º–ª—è–µ–º"],
    "size": ["—Ä–∞–∑–º–µ—Ä"],
    "color": ["—Ü–≤–µ—Ç", "—Ä–∞—Å—Ü–≤–µ—Ç–∫"],
    "address": ["–∞–¥—Ä–µ—Å", "—É–ª–∏—Ü", "–¥–æ–º", "–∫–≤–∞—Ä—Ç–∏"],
}
_PRODUCT_COLOR_OVERRIDES = {
    "chanel jumbo classic flap": {"—á–µ—Ä–Ω—ã–µ"},
    "—à–∞–Ω–µ–ª—å –¥–∂—É–º–±–æ": {"—á–µ—Ä–Ω—ã–µ"},
    "—à–∞–Ω–µ–ª –¥–∂—É–º–±–æ": {"—á–µ—Ä–Ω—ã–µ"},
}
_AVAILABILITY_HINTS = [
    "–µ—Å—Ç—å", "–∏–º–µ–µ—Ç—Å—è", "–≤ –Ω–∞–ª–∏—á–∏–∏", "–±—ã–≤–∞–µ—Ç", "–±—ã–ª–∏", "–±—É–¥–µ—Ç",
]
_MODEL_QUERY_IGNORE_TOKENS = {
    "–µ—Å—Ç—å", "–∫–∞–∫–æ–π", "–∫–∞–∫–∞—è", "–∫–∞–∫–∏–µ", "–Ω—É–∂–µ–Ω", "–Ω—É–∂–Ω–∞", "–Ω—É–∂–Ω—ã",
    "–ø–æ–∫–∞–∂–∏", "–ø–æ–∫–∞–∑–∞—Ç—å", "–ø—Ä–∏—à–ª–∏", "—Å–∫–∏–Ω—å", "–º–æ–¥–µ–ª—å", "–º–æ–¥–µ–ª–∏",
    "—Ü–≤–µ—Ç", "—Ä–∞–∑–º–µ—Ä", "—Ä–∞–∑–º–µ—Ä—ã", "–≥–æ—Ä–æ–¥", "–∞–¥—Ä–µ—Å", "—Å—É–º–∫–∞", "—Å—É–º–∫–∏", "—Ç—É—Ñ–ª–∏",
    "–æ–±—É–≤—å", "–∞–∫—Å–µ—Å—Å—É–∞—Ä", "–∞–∫—Å–µ—Å—Å—É–∞—Ä—ã", "–≤", "–Ω–∞", "–∏", "–∏–ª–∏",
    "–µ—â–µ", "–µ—â—ë", "—Ü–µ–Ω–∞", "—Ü–µ–Ω—ã", "—Å–∫–æ–ª—å–∫–æ", "—Å—Ç–æ–∏—Ç", "–Ω–∞–ª–∏—á–∏–∏", "–Ω–∞–ª–∏—á–∏–µ",
    "–∫—Ä–æ—Å—Å–æ–≤–∫–∏", "–∫—Ä–æ—Å–æ–≤–∫–∏", "–∫–µ–¥—ã", "–±–∞–ª–µ—Ç–∫–∏", "–ª–æ—Ñ–µ—Ä—ã", "—Å–ª–∏–Ω–≥–±—ç–∫–∏", "—Å–ª–∏–Ω–≥–±—ç–∫",
    "chanel", "saint", "laurent", "ysl", "yves", "jimmy", "choo", "miu",
    "louis", "vuitton", "gucci", "dior", "golden", "goose",
    "–∏–≤", "—Å–∞–Ω", "–ª–æ—Ä–∞–Ω", "—Å–µ–Ω", "—à–∞–Ω–µ–ª", "—à–∞–Ω–µ–ª—å", "–¥–∂–∏–º–∏", "–¥–∂–∏–º–º–∏", "—á—É",
}
_TYPE_FALLBACK_ALTERNATIVES = {
    "shoes": ["Golden Goose Super-Star", "Saint Laurent Opyum", "Chanel Classic Slingbacks", "Jimmy Choo Azia 95"],
    "bag": ["Chanel Jumbo Classic Flap", "Yves Saint Laurent Monogram", "Louis Vuitton Pochette Felicie", "Miu Miu Arcadie", "Miu Miu Wander"],
}


def _normalize_product_type(value: str) -> str:
    v = (value or "").strip().lower()
    if v in {"shoes", "–æ–±—É–≤—å", "shoe"}:
        return "shoes"
    if v in {"clothes", "–æ–¥–µ–∂–¥–∞", "clothing"}:
        return "clothes"
    if v in {"bag", "bags", "—Å—É–º–∫–∞", "—Å—É–º–∫–∏"}:
        return "bag"
    if v in {"other", "–¥—Ä—É–≥–æ–µ"}:
        return "other"
    return ""


def _infer_product_type_from_text(text: str) -> str:
    t = (text or "").lower()
    if "üë†" in (text or "") or "üëü" in (text or ""):
        return "shoes"
    if "üëú" in (text or ""):
        return "bag"
    if any(x in t for x in [
        "—Ç—É—Ñ", "–∫—Ä–æ—Å", "–±–æ—Ç–∏–Ω", "–ª–æ—Ñ–µ—Ä", "–±–∞–ª–µ—Ç–∫", "–æ–±—É–≤", "–∫–∞–±–ª—É–∫", "–ª–æ–¥–æ—á",
        "slingback", "–¥–∂–∏–º–º–∏ —á—É", "jimmy choo", "saeda", "azia", "opyum", "–æ–ø–∏—É–º",
        "sneaker", "–∫–µ–¥",
    ]):
        return "shoes"
    if any(x in t for x in ["–ø–ª–∞—Ç—å", "—é–±–∫", "–∫—É—Ä—Ç–∫", "–ø–∞–ª—å—Ç", "–±—Ä—é–∫", "–¥–∂–∏–Ω—Å", "—Ñ—É—Ç–±–æ–ª–∫", "–æ–¥–µ–∂–¥"]):
        return "clothes"
    if any(x in t for x in [
        "—Å—É–º–∫", "bag", "chanel 25", "arcadie", "pochette", "flap",
        "–∫–æ—à–µ–ª–µ–∫", "–∫–æ—à–µ–ª—ë–∫", "wallet", "monogram", "jumbo",
    ]):
        return "bag"
    return ""


def _extract_product_name_from_result(result: dict) -> str:
    meta = (result.get("metadata") or {})
    name = (meta.get("product_name") or "").strip()
    if name:
        return name
    text = (result.get("text") or "").strip()
    if not text:
        return ""
    m = re.search(r"[üë†üëüüëú]\s*([^\n]+)", text)
    candidate = (m.group(1) if m else text.splitlines()[0]).strip()
    candidate = re.split(r"\s+[‚Äî-]\s+", candidate)[0].strip()
    candidate = re.sub(r"\s{2,}.*$", "", candidate).strip()
    candidate = candidate[:120]
    return candidate if _looks_like_product_name(candidate) else ""


_BRAND_NAMES_EN = {
    "chanel", "saint laurent", "ysl", "yves saint laurent",
    "jimmy choo", "miu miu", "louis vuitton",
    "gucci", "dior", "golden goose", "prada",
    "balenciaga", "fendi", "versace", "dolce gabbana",
    "bottega veneta", "celine", "loewe", "valentino",
    "burberry", "hermes",
}

_BRAND_PATTERN = re.compile(
    r"\b(" + "|".join(re.escape(b) for b in sorted(_BRAND_NAMES_EN, key=len, reverse=True)) + r")\b\s*([\w\-]+(?:\s+[\w\-]+){0,2})?",
    re.IGNORECASE,
)


def _extract_product_mention(text: str) -> str:
    """Extract first brand + model mention from text. Returns short product name or empty string."""
    if not text:
        return ""
    m = _BRAND_PATTERN.search(text)
    if not m:
        return ""
    brand = m.group(1).strip()
    rest = (m.group(2) or "").strip()
    if rest:
        return f"{brand} {rest}"
    return brand


def _infer_result_product_type(result: dict) -> str:
    name = _extract_product_name_from_result(result)
    text = (result.get("text") or "")[:260]
    return _infer_product_type_from_text(f"{name} {text}")


def _looks_like_product_name(name: str) -> bool:
    n = (name or "").strip()
    if not n:
        return False
    low = n.lower()
    if any(bad in low for bad in ["–∏–º–µ–Ω–Ω–æ –ø–æ", "–æ–ø–∏—Å–∞–Ω–∏–µ", "—Ü–µ–Ω—ã", "–≤–º–µ—Å—Ç–µ —Å —Ü–µ–Ω–æ–π", "–ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ"]):
        return False
    if ":" in n and not any(h in n.lower() for h in ["chanel", "saint", "laurent", "jimmy", "miu", "louis", "golden"]):
        return False
    words = re.findall(r"[a-zA-Z–∞-—è–ê-–Ø—ë–Å0-9]+", n.lower())
    if len(words) > 8:
        return False
    tokens = tokenize_text(n)
    if tokens & _PRODUCT_HINT_TOKENS:
        return True
    if any(b in n.lower() for b in ["chanel", "saint", "laurent", "jimmy", "miu", "louis", "golden", "ysl"]):
        return True
    return False


def _filter_photos_by_requested_type(photos: list[dict], requested_type: str) -> list[dict]:
    if not photos or not requested_type:
        return photos
    matched = []
    for p in photos:
        filename = p.get("filename", "")
        p_type = _infer_product_type_from_text(filename)
        if p_type == requested_type:
            matched.append(p)
    return matched


def _build_fallback_photo_queries(user_message: str, requested_type: str) -> list[str]:
    t = (user_message or "").lower()
    queries: list[str] = []
    if requested_type == "shoes":
        if any(x in t for x in ["—Å–∞–Ω –ª–æ—Ä–∞–Ω", "–∏–≤ —Å–∞–Ω", "saint laurent", "ysl"]):
            queries.append("Saint Laurent Opyum")
    if requested_type == "bag":
        if any(x in t for x in ["—Å–∞–Ω –ª–æ—Ä–∞–Ω", "–∏–≤ —Å–∞–Ω", "saint laurent", "ysl"]):
            queries.append("Yves Saint Laurent Monogram")
    return queries


def _is_availability_request(text: str) -> bool:
    t = (text or "").lower()
    return any(h in t for h in _AVAILABILITY_HINTS)


def _extract_specific_query_tokens(text: str) -> set[str]:
    tokens = tokenize_text(text or "")
    specific = set()
    for tok in tokens:
        if not tok or tok.isdigit() or len(tok) < 3:
            continue
        if tok in _MODEL_QUERY_IGNORE_TOKENS:
            continue
        if tok in _COLOR_PREFIXES.values():
            continue
        if any(tok.startswith(prefix) for prefix in _COLOR_PREFIXES):
            continue
        specific.add(tok)
    return specific


def _match_name_overlap(query_text: str, product_name: str) -> int:
    q = tokenize_text(query_text or "")
    p = tokenize_text(product_name or "")
    return len(q & p)


def _pick_primary_product_match(product_results: list[dict], query_text: str) -> str:
    best_name = ""
    best_score = -1
    for r in product_results:
        name = _extract_product_name_from_result(r)
        if not name:
            continue
        score = _match_name_overlap(query_text, name)
        if score > best_score:
            best_score = score
            best_name = name
    return best_name


def _collect_similar_product_names(
    product_results: list[dict],
    requested_type: str = "",
    exclude_names: set[str] | None = None,
    limit: int = 3,
) -> list[str]:
    excluded = {(x or "").strip().lower() for x in (exclude_names or set()) if x}
    names: list[str] = []
    seen = set()
    for r in product_results:
        name = _extract_product_name_from_result(r)
        if not name:
            continue
        name_l = name.lower()
        if name_l in seen or name_l in excluded:
            continue
        if requested_type:
            r_type = _infer_result_product_type(r)
            if r_type and r_type != requested_type:
                continue
        seen.add(name_l)
        names.append(name)
        if len(names) >= limit:
            break
    return names


def _append_similar_products_text(base_text: str, similar_names: list[str]) -> str:
    if not similar_names:
        return base_text
    variants = "; ".join(similar_names)
    return f"{base_text}|||–ü–æ—Ö–æ–∂–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã: {variants}. –ö–∞–∫–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –ø–æ–∫–∞–∑–∞—Ç—å?"


def _fallback_alternative_names(product_type: str, exclude_names: set[str] | None = None, limit: int = 3) -> list[str]:
    excluded = {(x or "").strip().lower() for x in (exclude_names or set()) if x}
    candidates = _TYPE_FALLBACK_ALTERNATIVES.get(product_type or "", [])
    result = []
    for name in candidates:
        if name.lower() in excluded:
            continue
        result.append(name)
        if len(result) >= limit:
            break
    return result


def _sanitize_order_context(ctx: dict) -> dict:
    return {
        "city": (ctx.get("city") or "").strip(),
        "product": (ctx.get("product") or "").strip(),
        "product_type": _normalize_product_type(ctx.get("product_type") or ""),
        "size": (ctx.get("size") or "").strip(),
        "color": (ctx.get("color") or "").strip(),
        "address": (ctx.get("address") or "").strip(),
    }


def _merge_order_context(base: dict, updates: dict) -> dict:
    merged = _sanitize_order_context(base)
    incoming = _sanitize_order_context(updates)
    for key in ("city", "product", "size", "color", "address"):
        if incoming.get(key):
            merged[key] = incoming[key]
    if incoming.get("product_type"):
        merged["product_type"] = incoming["product_type"]
    if not merged.get("product_type"):
        merged["product_type"] = _infer_product_type_from_text(merged.get("product", ""))
    return merged


def _contains_order_confirm(text: str) -> bool:
    t = (text or "").lower()
    if "—Ö–æ—Ä–æ—à–æ, –æ—Ñ–æ—Ä–º–ª—è–µ–º –∑–∞–∫–∞–∑" in t or "—Ö–æ—Ä–æ—à–æ –æ—Ñ–æ—Ä–º–ª—è–µ–º –∑–∞–∫–∞–∑" in t:
        return True
    if "–æ—Ñ–æ—Ä–º" in t and "–∑–∞–∫–∞–∑" in t:
        return True
    return re.search(r"–æ—Ñ–æ—Ä–º\w*\s+–∑–∞–∫–∞–∑", t) is not None


def _strip_order_confirm(text: str) -> str:
    if not text:
        return text
    cleaned = re.sub(
        r"(?i)\b—Ö–æ—Ä–æ—à–æ,?\s*–æ—Ñ–æ—Ä–º–ª—è–µ–º\s*–∑–∞–∫–∞–∑\b[.!]?",
        "",
        text,
    )
    cleaned = re.sub(
        r"(?i)\b–æ—Ñ–æ—Ä–º\w*\s+–∑–∞–∫–∞–∑\b[.!]?",
        "",
        cleaned,
    )
    cleaned = re.sub(r"(?i)\b–æ—Ñ–æ—Ä–º–∏–º\s+–∑–∞–∫–∞–∑\b[.!]?", "", cleaned)
    cleaned = re.sub(r"(?i)\b–æ—Ñ–æ—Ä–º–ª—è–µ–º\s+–∑–∞–∫–∞–∑\b[.!]?", "", cleaned)
    cleaned = re.sub(r"\|\|\|\s*\|\|\|", "|||", cleaned)
    cleaned = re.sub(r"\s{2,}", " ", cleaned).strip(" |")
    return cleaned.strip() or "–°–µ–π—á–∞—Å —É—Ç–æ—á–Ω—é –¥–µ—Ç–∞–ª–∏ –∑–∞–∫–∞–∑–∞."


def _build_missing_fields(order_ctx: dict, color_required: bool) -> list[str]:
    missing = []
    # –°–Ω–∞—á–∞–ª–∞ —Å–æ–±–∏—Ä–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
    if not order_ctx.get("city"):
        missing.append("city")
    if not order_ctx.get("product"):
        missing.append("product")
    if order_ctx.get("product_type") in _SIZE_REQUIRED_TYPES and not order_ctx.get("size"):
        missing.append("size")
    if color_required and not order_ctx.get("color"):
        missing.append("color")
    
    # –ê–¥—Ä–µ—Å –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¢–û–õ–¨–ö–û –ø–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ —Å–æ–±—Ä–∞–Ω—ã –≤—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    # (–≥–æ—Ä–æ–¥, —Ç–æ–≤–∞—Ä, —Ä–∞–∑–º–µ—Ä –µ—Å–ª–∏ –Ω—É–∂–µ–Ω, —Ü–≤–µ—Ç –µ—Å–ª–∏ –Ω—É–∂–µ–Ω)
    basic_fields_collected = (
        order_ctx.get("city") 
        and order_ctx.get("product")
        and (order_ctx.get("product_type") not in _SIZE_REQUIRED_TYPES or order_ctx.get("size"))
        and (not color_required or order_ctx.get("color"))
    )
    
    if basic_fields_collected and not order_ctx.get("address"):
        missing.append("address")
    
    return missing


def _question_for_missing(field: str) -> str:
    if field == "city":
        return "–ü–æ–¥—Å–∫–∞–∂–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏–∑ –∫–∞–∫–æ–≥–æ –≤—ã –≥–æ—Ä–æ–¥–∞?"
    if field == "product":
        return "–£—Ç–æ—á–Ω–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∫–∞–∫—É—é –º–æ–¥–µ–ª—å –æ—Ñ–æ—Ä–º–ª—è–µ–º?"
    if field == "size":
        return "–ü–æ–¥—Å–∫–∞–∂–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∫–∞–∫–æ–π —Ä–∞–∑–º–µ—Ä –≤–∞–º –Ω—É–∂–µ–Ω?"
    if field == "color":
        return "–ü–æ–¥—Å–∫–∞–∂–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∫–∞–∫–æ–π —Ü–≤–µ—Ç –≤—ã–±–∏—Ä–∞–µ—Ç–µ?"
    if field == "address":
        return "–ù–∞–ø–∏—à–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∞–¥—Ä–µ—Å –¥–æ—Å—Ç–∞–≤–∫–∏?"
    return "–ü–æ–¥—Å–∫–∞–∂–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –∑–∞–∫–∞–∑–∞?"


def _has_question(text: str) -> bool:
    return "?" in (text or "")


def _has_order_intent(text: str) -> bool:
    t = (text or "").lower()
    return any(p in t for p in _ORDER_INTENT_PATTERNS)


def _asks_for_field(text: str, field: str) -> bool:
    t = (text or "").lower()
    hints = _FIELD_PROMPT_HINTS.get(field, [])
    return any(h in t for h in hints)


def _assistant_already_requests_missing(text: str, missing_fields: list[str]) -> bool:
    return any(_asks_for_field(text, f) for f in missing_fields)


def _strip_checkout_prompts(text: str) -> str:
    if not text:
        return text
    parts = [p.strip() for p in text.split("|||") if p.strip()]
    kept = []
    for p in parts:
        low = p.lower()
        if any(h in low for h in _CHECKOUT_HINTS) and len(p) <= 120:
            continue
        kept.append(p)
    if not kept:
        return ""
    return "|||".join(kept)


def _dedupe_response_parts(text: str) -> str:
    if not text:
        return text
    parts = [p.strip() for p in text.split("|||") if p.strip()]
    if not parts:
        return text
    seen = set()
    kept = []
    for part in parts:
        key = re.sub(r"\s+", " ", part.lower())
        key = re.sub(r"[^\w\s–∞-—è—ë]", "", key)
        if key in seen:
            continue
        seen.add(key)
        kept.append(part)
    return "|||".join(kept)


def _get_product_color_overrides(product_name: str) -> set[str]:
    product = (product_name or "").strip().lower()
    if not product:
        return set()
    result = set()
    for pattern, colors in _PRODUCT_COLOR_OVERRIDES.items():
        if pattern in product:
            result.update(colors)
    return result


def _format_color_unavailable_message(product_name: str, requested_color: str, available_colors: set[str]) -> str:
    product = product_name or "—ç—Ç–æ–π –º–æ–¥–µ–ª–∏"
    if available_colors:
        colors_text = ", ".join(sorted(available_colors))
        if len(available_colors) == 1:
            only_color = next(iter(available_colors))
            return (
                f"–ü–æ –º–æ–¥–µ–ª–∏ {product} —Ü–≤–µ—Ç–∞ {requested_color} —Å–µ–π—á–∞—Å –Ω–µ—Ç. "
                f"–ï—Å—Ç—å —Ç–æ–ª—å–∫–æ {only_color}. –ü–æ–¥–æ–π–¥–µ—Ç —ç—Ç–æ—Ç –≤–∞—Ä–∏–∞–Ω—Ç?"
            )
        return (
            f"–ü–æ –º–æ–¥–µ–ª–∏ {product} —Ü–≤–µ—Ç–∞ {requested_color} —Å–µ–π—á–∞—Å –Ω–µ—Ç. "
            f"–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ü–≤–µ—Ç–∞: {colors_text}. –ö–∞–∫–æ–π —Ü–≤–µ—Ç –≤—ã–±–∏—Ä–∞–µ—Ç–µ?"
        )
    return (
        f"–ü–æ –º–æ–¥–µ–ª–∏ {product} —Ü–≤–µ—Ç {requested_color} —Å–µ–π—á–∞—Å –Ω–µ –≤–∏–∂—É –≤ –Ω–∞–ª–∏—á–∏–∏. "
        "–ü–æ–¥—Å–∫–∞–∂–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∫–∞–∫–æ–π —Ü–≤–µ—Ç —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö?"
    )


def _format_order_context_for_prompt(order_ctx: dict, missing_fields: list[str], color_required: bool) -> str:
    fields_ru = {
        "city": "–≥–æ—Ä–æ–¥",
        "product": "—Ç–æ–≤–∞—Ä",
        "size": "—Ä–∞–∑–º–µ—Ä",
        "color": "—Ü–≤–µ—Ç",
        "address": "–∞–¥—Ä–µ—Å",
    }
    missing_ru = ", ".join(fields_ru[f] for f in missing_fields) if missing_fields else "–Ω–µ—Ç"
    return (
        "–ö–û–ù–¢–ï–ö–°–¢ –ó–ê–ö–ê–ó–ê:\n"
        f"- –≥–æ—Ä–æ–¥: {order_ctx.get('city') or '-'}\n"
        f"- —Ç–æ–≤–∞—Ä: {order_ctx.get('product') or '-'}\n"
        f"- —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞: {order_ctx.get('product_type') or '-'}\n"
        f"- —Ä–∞–∑–º–µ—Ä: {order_ctx.get('size') or '-'}\n"
        f"- —Ü–≤–µ—Ç: {order_ctx.get('color') or '-'}\n"
        f"- –∞–¥—Ä–µ—Å: {order_ctx.get('address') or '-'}\n"
        f"- —Ü–≤–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω: {'–¥–∞' if color_required else '–Ω–µ—Ç'}\n"
        f"- –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø–æ–ª—è: {missing_ru}\n"
        "–ü–†–ê–í–ò–õ–û: —Ñ—Ä–∞–∑—É '–•–æ—Ä–æ—à–æ, –æ—Ñ–æ—Ä–º–ª—è–µ–º –∑–∞–∫–∞–∑' –º–æ–∂–Ω–æ –ø–∏—Å–∞—Ç—å —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –ø–æ–ª–µ–π –Ω–µ—Ç."
    )


async def _extract_order_fields(user_message: str, history: list[dict], current_ctx: dict) -> dict:
    history_text = "\n".join(
        f"{m.get('role')}: {m.get('content')}" for m in history[-8:]
    )
    system_text = (
        "–ò–∑–≤–ª–µ–∫–∏ –¥–∞–Ω–Ω—ã–µ –∑–∞–∫–∞–∑–∞ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞. –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ JSON.\n"
        "–ü–æ–ª—è JSON: city, product, product_type, size, color, address, ready_to_order.\n"
        "product_type —Ç–æ–ª—å–∫–æ: shoes, clothes, bag, other, unknown.\n"
        "–ï—Å–ª–∏ –ø–æ–ª–µ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–π –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É.\n"
        "ready_to_order = true —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç —è–≤–Ω–æ –≥–æ—Ç–æ–≤ –æ—Ñ–æ—Ä–º–∏—Ç—å/–∫—É–ø–∏—Ç—å."
    )
    user_text = (
        f"–¢–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: {user_message}\n"
        f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ—Ñ–∏–ª—è: {json.dumps(current_ctx, ensure_ascii=False)}\n"
        f"–ò—Å—Ç–æ—Ä–∏—è: {history_text}"
    )
    try:
        completion = await openai_client.chat.completions.create(
            model=OPENAI_MODEL,
            temperature=0,
            max_tokens=220,
            response_format={"type": "json_object"},
            messages=[
                {"role": "system", "content": system_text},
                {"role": "user", "content": user_text},
            ],
        )
        raw = completion.choices[0].message.content or "{}"
        parsed = json.loads(raw)
        return {
            "city": parsed.get("city") or "",
            "product": parsed.get("product") or "",
            "product_type": parsed.get("product_type") or "",
            "size": parsed.get("size") or "",
            "color": parsed.get("color") or "",
            "address": parsed.get("address") or "",
            "ready_to_order": bool(parsed.get("ready_to_order", False)),
        }
    except Exception as e:
        logger.warning(f"Failed to extract order fields: {e}")
        return {
            "city": "",
            "product": "",
            "product_type": "",
            "size": "",
            "color": "",
            "address": "",
            "ready_to_order": False,
        }


def _strip_duplicate_greeting(text: str, history: list[dict]) -> str:
    """–£–±–∏—Ä–∞–µ–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –∏–∑ –æ—Ç–≤–µ—Ç–∞ GPT, –µ—Å–ª–∏ –±–æ—Ç —É–∂–µ –∑–¥–æ—Ä–æ–≤–∞–ª—Å—è –≤ —ç—Ç–æ–π –ø–µ—Ä–µ–ø–∏—Å–∫–µ."""
    bot_already_greeted = False
    for m in history:
        if m.get("role") == "assistant":
            content = (m.get("content") or "").lower()
            if any(g in content for g in _GREETING_WORDS):
                bot_already_greeted = True
                break

    if not bot_already_greeted:
        return text

    # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ ||| –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—É—é —á–∞—Å—Ç—å
    parts = [p.strip() for p in text.split("|||") if p.strip()]
    if not parts:
        return text

    first_lower = parts[0].lower().strip()
    # –ï—Å–ª–∏ –ø–µ—Ä–≤–∞—è —á–∞—Å—Ç—å ‚Äî –∫–æ—Ä–æ—Ç–∫–æ–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ (–¥–æ 30 —Å–∏–º–≤–æ–ª–æ–≤), —É–±–∏—Ä–∞–µ–º
    if any(first_lower.startswith(g) for g in _GREETING_WORDS) and len(first_lower) < 30:
        parts = parts[1:]

    if not parts:
        return text

    return "|||".join(parts)


def _caption_from_filename(filename: str) -> str:
    """'–∫—Ä–æ—Å—Å–æ–≤–∫–∏ —á–µ—Ä–Ω—ã–µ Golden Goose Ball Star.jpg' -> 'Golden Goose Ball Star'"""
    # 1. –£–¥–∞–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
    name = re.sub(r'\.\w+$', '', filename)
    # 2. –£–¥–∞–ª—è–µ–º –∫–∏—Ä–∏–ª–ª–∏—Ü—É (–ª—é–±—ã–µ —Ä—É—Å—Å–∫–∏–µ —Å–ª–æ–≤–∞ –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏)
    name = re.sub(r'[–∞-—è–ê-–Ø—ë–Å]+', '', name)
    # 2a. –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥–ª–∏ –æ—Å—Ç–∞—Ç—å—Å—è (–∑–∞–ø—è—Ç—ã–µ, —Ç–∏—Ä–µ –ø–æ –∫—Ä–∞—è–º)
    name = re.sub(r'^[^\w\d]+|[^\w\d]+$', '', name) # Trim non-alphanumeric from ends
    name = re.sub(r'[,.;:]', ' ', name) # Replace punctuation with spaces
    # 3. –£–¥–∞–ª—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–µ–∫—Å—ã –≤ –∫–æ–Ω—Ü–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, " 1", " 02")
    name = re.sub(r'\s+\d{1,2}$', '', name.strip())
    # 4. –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥–ª–∏ –æ—Å—Ç–∞—Ç—å—Å—è –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è —Ä—É—Å—Å–∫–∏—Ö —Å–ª–æ–≤
    name = re.sub(r'\s{2,}', ' ', name)
    return name.strip()


# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–≤–µ—Ç–∞ –≤ —Ç–µ–∫—Å—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
_COLOR_PREFIXES = {
    "—Ä–æ–∑–æ–≤": "—Ä–æ–∑–æ–≤—ã–µ", "pink": "—Ä–æ–∑–æ–≤—ã–µ",
    "—á–µ—Ä–Ω": "—á–µ—Ä–Ω—ã–µ", "black": "—á–µ—Ä–Ω—ã–µ",
    "–±–µ–∂": "–±–µ–∂–µ–≤—ã–µ", "beige": "–±–µ–∂–µ–≤—ã–µ",
    "–±–µ–ª": "–±–µ–ª—ã–µ", "white": "–±–µ–ª—ã–µ",
    "–∫—Ä–∞—Å–Ω": "–∫—Ä–∞—Å–Ω—ã–µ", "red": "–∫—Ä–∞—Å–Ω—ã–µ",
    "—Å–∏–Ω–∏–π": "—Å–∏–Ω–∏–µ", "—Å–∏–Ω–∏—Ö": "—Å–∏–Ω–∏–µ", "—Å–∏–Ω–∏–µ": "—Å–∏–Ω–∏–µ",
    "–∑–æ–ª–æ—Ç": "–∑–æ–ª–æ—Ç—ã–µ", "gold": "–∑–æ–ª–æ—Ç—ã–µ",
    "—Å–µ—Ä–µ–±—Ä": "—Å–µ—Ä–µ–±—Ä—è–Ω—ã–µ", "silver": "—Å–µ—Ä–µ–±—Ä—è–Ω—ã–µ",
    "–∫–æ—Ä–∏—á–Ω–µ–≤": "–∫–æ—Ä–∏—á–Ω–µ–≤—ã–µ", "brown": "–∫–æ—Ä–∏—á–Ω–µ–≤—ã–µ",
    "–∑–µ–ª–µ–Ω": "–∑–µ–ª–µ–Ω—ã–µ", "green": "–∑–µ–ª–µ–Ω—ã–µ",
}


def _detect_color_in_text(text: str) -> str | None:
    """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ü–≤–µ—Ç, —É–ø–æ–º—è–Ω—É—Ç—ã–π –≤ —Ç–µ–∫—Å—Ç–µ. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∫–ª—é—á –∏–ª–∏ None."""
    t = text.lower()
    for prefix, color_key in _COLOR_PREFIXES.items():
        if prefix in t:
            return color_key
    return None


def _detect_color_from_filename(filename: str) -> str:
    f = (filename or "").lower()
    for prefix, color_name in _COLOR_PREFIXES.items():
        if prefix in f:
            return color_name
    return ""


async def _is_color_required(product_name: str) -> bool:
    product = (product_name or "").strip().lower()
    if not product:
        return False
    if product in _COLOR_REQUIREMENT_CACHE:
        return _COLOR_REQUIREMENT_CACHE[product]
    try:
        photos = await find_product_photos(product_name=product_name)
        colors = {_detect_color_from_filename(p.get("filename", "")) for p in photos}
        colors.discard("")
        required = len(colors) > 1
        _COLOR_REQUIREMENT_CACHE[product] = required
        return required
    except Exception as e:
        logger.warning(f"Failed to detect color requirement for '{product_name}': {e}")
        return False


async def _get_available_colors_for_product(product_name: str) -> set[str]:
    product = (product_name or "").strip()
    if not product:
        return set()
    try:
        photos = await find_product_photos(product_name=product)
        colors = {_detect_color_from_filename(p.get("filename", "")) for p in photos}
        colors.discard("")
        return colors
    except Exception as e:
        logger.warning(f"Failed to list available colors for '{product_name}': {e}")
        return set()


def _pick_product_photos(found_photos: list[dict], requested_color: str | None = None) -> list[dict]:
    """
    –í—ã–±—Ä–∞—Ç—å —Ñ–æ—Ç–æ —Ç–æ–≤–∞—Ä–∞.
    - requested_color –∑–∞–¥–∞–Ω ‚Üí –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–æ —Ü–≤–µ—Ç—É, –æ—Ç–¥–∞—Ç—å –≤—Å–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ
    - requested_color = None ‚Üí –æ–±–∑–æ—Ä–Ω—ã–π —Ä–µ–∂–∏–º: –ø–æ 1 —Ñ–æ—Ç–æ –∫–∞–∂–¥–æ–≥–æ —Ü–≤–µ—Ç–∞
    """
    if requested_color:
        # –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ü–≤–µ—Ç ‚Äî —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –∏ –æ—Ç–¥–∞—ë–º –≤—Å–µ
        color_prefixes = [p for p, key in _COLOR_PREFIXES.items() if key == requested_color]
        matching = [
            img for img in found_photos
            if any(cp in img.get("filename", "").lower() for cp in color_prefixes)
        ]
        # –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –∑–∞–ø—Ä–æ—Å–∏–ª –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ü–≤–µ—Ç –∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ—Ç, –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥—Ä—É–≥–æ–π —Ü–≤–µ—Ç.
        source = matching
        source = _dedupe_photos(source)
        return [
            {
                "file_id": p["file_id"],
                "caption": _caption_from_filename(p["filename"]),
                "filename": p["filename"],
            }
            for p in source[:MAX_PHOTOS_PRODUCT_SHOWCASE]
        ]
    else:
        # –û–±–∑–æ—Ä–Ω—ã–π —Ä–µ–∂–∏–º ‚Äî –ø–æ 1 —Ñ–æ—Ç–æ –∫–∞–∂–¥–æ–≥–æ —Ü–≤–µ—Ç–∞
        picked = select_photos_with_color_variety(
            found_photos,
            max_total=MAX_PHOTOS_PRODUCT_SHOWCASE,
            max_per_color=1,
        )
        picked = _dedupe_photos(picked)
        return [
            {
                "file_id": p["file_id"],
                "caption": _caption_from_filename(p["filename"]),
                "filename": p["filename"],
            }
            for p in picked
        ]


async def generate_response(chat_id: str, user_message: str, sender_name: str) -> dict:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –±–æ—Ç–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: {'text': str, 'photos': list[dict]}
    """
    # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ö–æ–¥—è—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    await save_message(chat_id, "user", user_message, sender_name)

    # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –¥–æ–∂–∏–º –∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç –æ—Ç–≤–µ—á–∞–µ—Ç
    await reset_nudge_state(chat_id)

    # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —á–∏—Ç–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞–∫–∞–∑–∞, —á—Ç–æ–±—ã –Ω–µ —Ç–µ—Ä—è—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–π —Ç–æ–≤–∞—Ä
    current_order_ctx = await get_order_context(chat_id)
    requested_product_type = _infer_product_type_from_text(user_message)
    product_query = user_message
    if _should_use_active_product_query(user_message, current_order_ctx.get("product", "")):
        product_query = current_order_ctx.get("product", "") or user_message

    # 2. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –∏—â–µ–º –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
    product_results, script_results = await asyncio.gather(
        search_products(product_query),
        search_scripts(user_message),
    )
    if requested_product_type:
        filtered_results = []
        for r in product_results:
            result_type = _infer_result_product_type(r)
            if not result_type or result_type == requested_product_type:
                filtered_results.append(r)
        product_results = filtered_results
    primary_product_match = _pick_primary_product_match(product_results, user_message)
    specific_query_tokens = _extract_specific_query_tokens(user_message)

    # 3. –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã
    product_context = "\n---\n".join([r["text"] for r in product_results])
    product_context = product_context or "–ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –≤ –±–∞–∑–µ."

    sales_context = "\n---\n".join([r["text"] for r in script_results])
    sales_context = sales_context or "–ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å–∫—Ä–∏–ø—Ç–æ–≤."

    # 4. –ò—Å—Ç–æ—Ä–∏—è –ø–µ—Ä–µ–ø–∏—Å–∫–∏
    history = await get_conversation_history(chat_id)
    is_new_client = len(history) <= 1
    history_text = "\n".join(
        [f"{'–ö–ª–∏–µ–Ω—Ç' if m['role'] == 'user' else '–ê–ª–∏–Ω–∞'}: {m['content']}" for m in history]
    )

    order_ctx = current_order_ctx
    extracted_fields = await _extract_order_fields(user_message, history, order_ctx)
    llm_ready_to_order = bool(extracted_fields.get("ready_to_order", False))

    rag_product_name = ""
    if product_results:
        rag_product_name = _extract_product_name_from_result(product_results[0]) or ""
    target_product_type = requested_product_type or _infer_product_type_from_text(primary_product_match or rag_product_name)
    similar_product_names = _collect_similar_product_names(
        product_results,
        requested_type=target_product_type,
        exclude_names={primary_product_match} if primary_product_match else set(),
        limit=3,
    )

    if rag_product_name and not extracted_fields.get("product") and not order_ctx.get("product"):
        extracted_fields["product"] = rag_product_name
    if not extracted_fields.get("product_type"):
        extracted_fields["product_type"] = _infer_product_type_from_text(
            extracted_fields.get("product") or rag_product_name
        )
    if target_product_type:
        extracted_fields["product_type"] = target_product_type

    # Before merge ‚Äî capture what WAS missing (for is_answering_missing_field check later)
    color_required_pre = await _is_color_required(order_ctx.get("product", ""))
    pre_merge_missing = _build_missing_fields(order_ctx, color_required_pre)

    order_ctx = _merge_order_context(order_ctx, extracted_fields)
    if not order_ctx.get("product") and rag_product_name:
        order_ctx["product"] = rag_product_name
    if not order_ctx.get("product_type"):
        order_ctx["product_type"] = _infer_product_type_from_text(order_ctx.get("product", ""))

    await upsert_order_context(chat_id, order_ctx)
    color_required = await _is_color_required(order_ctx.get("product", ""))
    missing_order_fields = _build_missing_fields(order_ctx, color_required)
    order_guard_prompt = _format_order_context_for_prompt(order_ctx, missing_order_fields, color_required)

    system_prompt = SYSTEM_PROMPT.format(
        product_context=product_context,
        sales_context=sales_context,
        conversation_history=history_text,
    ) + "\n\n" + order_guard_prompt

    # 6. –í—ã–∑—ã–≤–∞–µ–º GPT
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_message},
    ]

    completion = await openai_client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=messages,
        temperature=0.7,
        max_tokens=700,
    )

    assistant_text = completion.choices[0].message.content

    # 7a. –£–±–∏—Ä–∞–µ–º –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–∞ —É—Ä–æ–≤–Ω–µ –∫–æ–¥–∞
    assistant_text = _strip_duplicate_greeting(assistant_text, history)
    user_order_intent = _has_order_intent(user_message)
    # –ù–µ —Å—á–∏—Ç–∞–µ–º –∑–∞–∫–∞–∑ "–≥–æ—Ç–æ–≤—ã–º" —Ç–æ–ª—å–∫–æ –ø–æ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏—é LLM –±–µ–∑ —è–≤–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ –∫–ª–∏–µ–Ω—Ç–∞.
    ready_to_order = user_order_intent
    address_just_collected = bool((extracted_fields.get("address") or "").strip())
    if not user_order_intent:
        assistant_text = _strip_checkout_prompts(assistant_text) or "–°–µ–π—á–∞—Å —É—Ç–æ—á–Ω—é –ø–æ –º–æ–¥–µ–ª–∏ –∏ –Ω–∞–ª–∏—á–∏—é."

    # 7b. –ñ–µ—Å—Ç–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –¥–æ —Å–±–æ—Ä–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –∑–∞–∫–∞–∑ –Ω–µ –æ—Ñ–æ—Ä–º–ª—è–µ–º
    if missing_order_fields:
        if _contains_order_confirm(assistant_text):
            assistant_text = _strip_order_confirm(assistant_text)
        # –ó–∞–¥–∞–µ–º –≤–æ–ø—Ä–æ—Å –æ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –ø–æ–ª—è—Ö –µ—Å–ª–∏:
        # 1. –ö–ª–∏–µ–Ω—Ç —Ö–æ—á–µ—Ç –∑–∞–∫–∞–∑–∞—Ç—å –ò–õ–ò —Ç–æ–ª—å–∫–æ —á—Ç–æ –¥–∞–ª–∏ –∞–¥—Ä–µ—Å (–∫–∞–∫ —Ä–∞–Ω—å—à–µ)
        # 2. –ò–õ–ò —Ç–æ–≤–∞—Ä –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –≤ order_ctx (–∫–ª–∏–µ–Ω—Ç –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç—Å—è —Ç–æ–≤–∞—Ä–æ–º)
        # 3. –ù–û –ù–ï –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–∏ (is_new_client) - —Ç–æ–≥–¥–∞ –ø—Ä–æ–º–ø—Ç —Å–∞–º –∑–∞–¥–∞—Å—Ç –≤–æ–ø—Ä–æ—Å
        should_force_missing_question = (
            not is_new_client  # –î–æ–±–∞–≤–ª–µ–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞: –Ω–µ –∑–∞–¥–∞–µ–º –¥–æ–ø. –≤–æ–ø—Ä–æ—Å—ã –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∫–æ–Ω—Ç–∞–∫—Ç–µ
            and (
                ready_to_order
                or address_just_collected
                or bool(order_ctx.get("product"))
            )
        )
        if should_force_missing_question and not _assistant_already_requests_missing(assistant_text, missing_order_fields) and not _has_question(assistant_text):
            assistant_text = f"{assistant_text}|||{_question_for_missing(missing_order_fields[0])}".strip("|")
    elif (ready_to_order or address_just_collected or llm_ready_to_order) and not _contains_order_confirm(assistant_text):
        # 7c. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–æ–≤–∞—Ä–∞ –ø–µ—Ä–µ–¥ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ–º –∑–∞–∫–∞–∑–∞
        product_name = order_ctx.get("product", "")
        size = order_ctx.get("size", "")
        color = order_ctx.get("color", "")

        if product_name:
            try:
                availability = check_product_availability(product_name, size, color)

                if not availability["available"]:
                    # –¢–æ–≤–∞—Ä–∞ –Ω–µ—Ç –≤ –Ω–∞–ª–∏—á–∏–∏ - –Ω–µ –æ—Ñ–æ—Ä–º–ª—è–µ–º –∑–∞–∫–∞–∑
                    logger.info(
                        "–¢–æ–≤–∞—Ä '%s' (size=%s, color=%s) –Ω–µ—Ç –≤ –Ω–∞–ª–∏—á–∏–∏",
                        product_name, size, color
                    )
                    assistant_text = format_availability_message(availability, product_name)

                    # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –µ—Å–ª–∏ –µ—Å—Ç—å
                    if similar_product_names:
                        alternatives_text = "–ú–æ–≥—É –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –ø–æ—Ö–æ–∂–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã: " + ", ".join(similar_product_names)
                        assistant_text = f"{assistant_text}|||{alternatives_text}".strip("|")

                else:
                    # –¢–æ–≤–∞—Ä –≤ –Ω–∞–ª–∏—á–∏–∏ - –º–æ–∂–Ω–æ –æ—Ñ–æ—Ä–º–ª—è—Ç—å –∑–∞–∫–∞–∑
                    logger.info(
                        "–¢–æ–≤–∞—Ä '%s' (size=%s, color=%s) –≤ –Ω–∞–ª–∏—á–∏–∏: quantity=%d, price=%s",
                        product_name, size, color,
                        availability["quantity"], availability["price"]
                    )
                    availability_msg = format_availability_message(availability, product_name)
                    assistant_text = f"{availability_msg}|||{_ORDER_CONFIRM_TEXT}".strip("|")

            except Exception as e:
                logger.error("–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–ª–∏—á–∏—è –¥–ª—è '%s': %s", product_name, e, exc_info=True)
                # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤—Å–µ —Ä–∞–≤–Ω–æ –ø—ã—Ç–∞–µ–º—Å—è –æ—Ñ–æ—Ä–º–∏—Ç—å –∑–∞–∫–∞–∑
                assistant_text = f"{assistant_text}|||{_ORDER_CONFIRM_TEXT}".strip("|")
        else:
            # –ï—Å–ª–∏ product_name –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω, –≤—Å–µ —Ä–∞–≤–Ω–æ –¥–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
            assistant_text = f"{assistant_text}|||{_ORDER_CONFIRM_TEXT}".strip("|")

    assistant_text = _dedupe_response_parts(assistant_text)

    # 8. –ò—â–µ–º —Ñ–æ—Ç–æ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ Google Drive
    photos = []
    user_tokens = tokenize_text(user_message)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º —Ñ–æ—Ç–æ: –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ü–≤–µ—Ç ‚Üí –≤—Å–µ —Ñ–æ—Ç–æ —ç—Ç–æ–≥–æ —Ü–≤–µ—Ç–∞, –∏–Ω–∞—á–µ ‚Üí –ø–æ 1 –∫–∞–∂–¥–æ–≥–æ —Ü–≤–µ—Ç–∞
    requested_color = _detect_color_in_text(user_message)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Ç–≤–µ—á–∞–µ—Ç –ª–∏ –∫–ª–∏–µ–Ω—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –æ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –ø–æ–ª—è—Ö
    # –ï—Å–ª–∏ –¥–∞ - –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–æ—Ç–æ –∑–∞–Ω–æ–≤–æ
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º pre_merge_missing (–¥–æ —Å–ª–∏—è–Ω–∏—è), —Ç.–∫. –ø–æ—Å–ª–µ merge –ø–æ–ª–µ —É–∂–µ –Ω–µ "missing"
    is_answering_missing_field = False
    if pre_merge_missing and extracted_fields:
        for field in pre_merge_missing:
            if extracted_fields.get(field):
                is_answering_missing_field = True
                break

    # Primary: search photos by user message text (most reliable)
    if not is_answering_missing_field:
        try:
            found_photos = await find_product_photos(product_name=user_message)
            if found_photos:
                photos.extend(_pick_product_photos(found_photos, requested_color))
        except Exception as e:
            logger.warning(f"Failed to find photos by message text: {e}")

    if (
        not photos
        and not is_answering_missing_field
        and order_ctx.get("product")
        and (
            not target_product_type
            or _infer_product_type_from_text(order_ctx.get("product", "")) in {"", target_product_type}
        )
    ):
        try:
            found_photos = await find_product_photos(product_name=order_ctx["product"])
            if found_photos:
                photos.extend(_pick_product_photos(found_photos, requested_color))
        except Exception as e:
            logger.warning(f"Failed to find photos by order context: {e}")

    # Fallback: search by RAG metadata (—Ç–æ–≤–∞—Ä—ã –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π)
    # –ü—Ä–æ–±—É–µ–º –≤—Å–µ product_name –∏–∑ RAG, –Ω–µ —Ç–æ–ª—å–∫–æ —Ç–µ —á—Ç–æ —Å–æ–≤–ø–∞–ª–∏ —Å —Ç–µ–∫—É—â–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º ‚Äî
    # –∫–ª–∏–µ–Ω—Ç –º–æ–≥ –Ω–∞–ø–∏—Å–∞—Ç—å "—Å –∞–ª–º–∞—Ç—ã, 38", –∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –ø—Ä–æ –±–∞–ª–µ—Ç–∫–∏
    if not photos and not is_answering_missing_field:
        for result in product_results:
            meta = result.get("metadata", {})
            photo_folder_id = meta.get("photo_folder_id", "")
            product_name = meta.get("product_name", "")

            if not (photo_folder_id or product_name):
                continue
            # –ï—Å–ª–∏ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –µ—Å—Ç—å —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ ‚Äî –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç; –∏–Ω–∞—á–µ –≤—Å—ë —Ä–∞–≤–Ω–æ –ø—Ä–æ–±—É–µ–º (–¥–∏–∞–ª–æ–≥ —É–∂–µ –ø—Ä–æ —Ç–æ–≤–∞—Ä)
            if product_name and user_tokens:
                product_tokens = tokenize_text(product_name)
                if not (user_tokens & product_tokens) and len(history) <= 2:
                    continue
            try:
                folder_photos = await find_product_photos(
                    folder_id=photo_folder_id or None,
                    product_name=product_name or None,
                )
                if folder_photos:
                    photos.extend(_pick_product_photos(folder_photos, requested_color))
                    break
            except Exception as e:
                logger.warning(f"Failed to find photos for {product_name}: {e}")

    # Stage 3: search by product mention in GPT response (not full text)
    if not photos and not is_answering_missing_field:
        gpt_product = _extract_product_mention(assistant_text)
        if gpt_product:
            try:
                found_photos = await find_product_photos(product_name=gpt_product)
                if found_photos:
                    photos.extend(_pick_product_photos(found_photos, requested_color))
            except Exception as e:
                logger.warning(f"Failed to find photos by GPT response product '{gpt_product}': {e}")

    # Stage 4: –µ—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –ø—Ä–æ—Å–∏—Ç —Ñ–æ—Ç–æ ("–ø–æ–∫–∞–∂–∏—Ç–µ —Ñ–æ—Ç–∫—É"), –∞ —Ç–æ–≤–∞—Ä –Ω–µ –≤ —Ç–µ–∫—É—â–µ–º —Å–æ–æ–±—â–µ–Ω–∏–∏ ‚Äî
    # –∏—â–µ–º –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É —Å–æ–æ–±—â–µ–Ω–∏—é –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞, –≥–¥–µ –±—ã–ª –æ–ø–∏—Å–∞–Ω —Ç–æ–≤–∞—Ä (—Ü–µ–Ω–∞, –º–æ–¥–µ–ª—å)
    if not photos and not is_answering_missing_field and len(history) >= 2 and _is_photo_request(user_message):
        last_product_text = None
        for m in reversed(history):
            if m.get("role") != "assistant":
                continue
            content = (m.get("content") or "").strip()
            if len(content) < 20:
                continue
            if "—Ü–µ–Ω–∞" in content.lower() or "‚Ç∏" in content or "–º–æ–¥–µ–ª" in content.lower() or "chanel" in content.lower():
                last_product_text = content
                break
        if last_product_text:
            try:
                found_photos = await find_product_photos(product_name=last_product_text)
                if found_photos:
                    photos.extend(_pick_product_photos(found_photos, requested_color))
                    logger.info(f"Found {len(photos)} photos by last assistant product message")
            except Exception as e:
                logger.warning(f"Failed to find photos by last assistant message: {e}")

    if not photos and target_product_type:
        for q in _build_fallback_photo_queries(user_message, target_product_type):
            try:
                found_photos = await find_product_photos(product_name=q)
                if found_photos:
                    photos.extend(_pick_product_photos(found_photos, requested_color))
                    break
            except Exception as e:
                logger.warning(f"Failed fallback photo query '{q}': {e}")

    # –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –ø—Ä–æ—Å–∏—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ü–≤–µ—Ç, –Ω–æ —ç—Ç–æ–≥–æ —Ü–≤–µ—Ç–∞ –Ω–µ—Ç –≤ —Ñ–æ—Ç–æ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞,
    # –Ω–µ –ø–æ–¥–º–µ–Ω—è–µ–º –æ—Ç–≤–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ–º –¥—Ä—É–≥–æ–≥–æ —Ü–≤–µ—Ç–∞.
    color_unavailable = False
    color_alternatives: list[str] = []
    if requested_color:
        active_product_name = order_ctx.get("product", "") or rag_product_name
        if active_product_name:
            available_colors = await _get_available_colors_for_product(active_product_name)
            if not available_colors:
                available_colors = _get_product_color_overrides(active_product_name)

            if available_colors and requested_color not in available_colors:
                assistant_text = _format_color_unavailable_message(
                    active_product_name,
                    requested_color,
                    available_colors,
                )
                photos = []
                color_unavailable = True
                if order_ctx.get("color") == requested_color:
                    order_ctx["color"] = ""
                    await upsert_order_context(chat_id, order_ctx)
            elif not photos and available_colors and requested_color in available_colors:
                # –¶–≤–µ—Ç –∑–∞—è–≤–ª–µ–Ω –∫–∞–∫ –¥–æ—Å—Ç—É–ø–Ω—ã–π, –Ω–æ —Ñ–æ—Ç–æ —ç—Ç–æ–≥–æ —Ü–≤–µ—Ç–∞ –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –Ω–µ –ø–æ–¥–º–µ–Ω—è–µ–º –¥—Ä—É–≥–∏–º —Ü–≤–µ—Ç–æ–º.
                assistant_text = (
                    f"–ü–æ –º–æ–¥–µ–ª–∏ {active_product_name} —Ü–≤–µ—Ç {requested_color} –µ—Å—Ç—å, "
                    "—Å–µ–π—á–∞—Å —É—Ç–æ—á–Ω—é –∏ –æ—Ç–ø—Ä–∞–≤–ª—é –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ñ–æ—Ç–æ."
                )
            elif not photos:
                assistant_text = _format_color_unavailable_message(
                    active_product_name,
                    requested_color,
                    available_colors,
                )
                color_unavailable = True

    if color_unavailable:
        color_alternatives = similar_product_names or _fallback_alternative_names(
            target_product_type,
            exclude_names={order_ctx.get("product", ""), rag_product_name},
            limit=3,
        )
        assistant_text = _append_similar_products_text(assistant_text, color_alternatives)
        if not photos:
            for alt in color_alternatives:
                try:
                    found_alt = await find_product_photos(product_name=alt)
                    if not found_alt:
                        continue
                    alt_photos = _pick_product_photos(found_alt, None)
                    if target_product_type:
                        alt_photos = _filter_photos_by_requested_type(alt_photos, target_product_type)
                    if alt_photos:
                        photos = alt_photos
                        break
                except Exception as e:
                    logger.warning(f"Failed to get color-alternative photos for '{alt}': {e}")

    if target_product_type:
        photos = _filter_photos_by_requested_type(photos, target_product_type)
        if not photos:
            for q in _build_fallback_photo_queries(user_message, target_product_type):
                try:
                    found_photos = await find_product_photos(product_name=q)
                    if found_photos:
                        photos.extend(_pick_product_photos(found_photos, requested_color))
                        photos = _filter_photos_by_requested_type(photos, target_product_type)
                        if photos:
                            break
                except Exception as e:
                    logger.warning(f"Failed typed fallback photo query '{q}': {e}")

    if _is_photo_request(user_message) and not photos:
        product_label = order_ctx.get("product", "") or rag_product_name or "—ç—Ç—É –º–æ–¥–µ–ª—å"
        if target_product_type == "shoes":
            assistant_text = (
                f"–ü–æ –∑–∞–ø—Ä–æ—Å—É –Ω–∞ —Ç—É—Ñ–ª–∏ —Ñ–æ—Ç–æ —Å–µ–π—á–∞—Å –Ω–µ –≤–∏–∂—É. "
                f"–ú–æ–≥—É –ø–æ–¥–æ–±—Ä–∞—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ {product_label}. "
                "–ü–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ –µ—Å—Ç—å –≤ –Ω–∞–ª–∏—á–∏–∏?"
            )
        elif target_product_type == "bag":
            assistant_text = (
                f"–ü–æ –∑–∞–ø—Ä–æ—Å—É –Ω–∞ —Å—É–º–∫—É —Ñ–æ—Ç–æ —Å–µ–π—á–∞—Å –Ω–µ –≤–∏–∂—É. "
                f"–ú–æ–≥—É –ø–æ–∫–∞–∑–∞—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ {product_label}. "
                "–ü–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ –µ—Å—Ç—å –≤ –Ω–∞–ª–∏—á–∏–∏?"
            )
        else:
            assistant_text = (
                f"–ü–æ –∑–∞–ø—Ä–æ—Å—É —Ñ–æ—Ç–æ —Å–µ–π—á–∞—Å –Ω–µ –≤–∏–∂—É –≤ –∫–∞—Ç–∞–ª–æ–≥–µ –¥–ª—è {product_label}. "
                "–ú–æ–≥—É –ø–æ–¥–æ–±—Ä–∞—Ç—å –±–ª–∏–∂–∞–π—à–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏ –ø–æ–∫–∞–∑–∞—Ç—å –∏—Ö."
            )

    model_unavailable = False
    if _is_availability_request(user_message) and specific_query_tokens:
        match_tokens = tokenize_text(primary_product_match or "")
        if not (specific_query_tokens & match_tokens):
            model_unavailable = True

    if model_unavailable:
        alternatives = _collect_similar_product_names(
            product_results,
            requested_type=target_product_type,
            exclude_names=set(),
            limit=3,
        )
        if not alternatives:
            alternatives = _collect_similar_product_names(product_results, requested_type="", exclude_names=set(), limit=3)
        if not alternatives:
            alternatives = _fallback_alternative_names(
                target_product_type,
                exclude_names={order_ctx.get("product", ""), rag_product_name},
                limit=3,
            )
        assistant_text = "–¢–∞–∫–æ–π –º–æ–¥–µ–ª–∏ —Å–µ–π—á–∞—Å –Ω–µ—Ç –≤ –Ω–∞–ª–∏—á–∏–∏."
        assistant_text = _append_similar_products_text(assistant_text, alternatives)
        photos = []
        for alt in alternatives:
            try:
                found_alt = await find_product_photos(product_name=alt)
                if not found_alt:
                    continue
                alt_photos = _pick_product_photos(found_alt, None)
                if target_product_type:
                    alt_photos = _filter_photos_by_requested_type(alt_photos, target_product_type)
                if alt_photos:
                    photos = alt_photos
                    break
            except Exception as e:
                logger.warning(f"Failed to get similar product photos for '{alt}': {e}")

    photos = _dedupe_photos(photos)
    photos = _normalize_photo_captions(photos)

    assistant_text = _dedupe_response_parts(assistant_text)
    clean_text = assistant_text.replace("|||", " ").strip()
    clean_text = re.sub(r'\s{2,}', ' ', clean_text)
    await save_message(chat_id, "assistant", clean_text)

    if photos:
        logger.info(f"Found {len(photos)} photos for chat {chat_id}")

    return {
        "text": assistant_text,
        "photos": photos[:MAX_PHOTOS_PRODUCT_SHOWCASE],
        "is_new_client": is_new_client,
        "order_context": order_ctx,
        "missing_order_fields": missing_order_fields,
    }


async def handle_message(chat_id: str, sender_name: str, text: str):
    """
    –û—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π (–≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ webhook).
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —á–µ—Ä–µ–∑ Green API.
    """
    try:
        # Manager handoff commands (sent from manager's number to bot)
        if chat_id in MANAGER_CHAT_IDS:
            action, target_chat_id = _parse_handoff_command(text)
            if action:
                if not target_chat_id:
                    await send_text(
                        chat_id,
                        "–£–∫–∞–∂–∏—Ç–µ –Ω–æ–º–µ—Ä –∫–ª–∏–µ–Ω—Ç–∞. –ü—Ä–∏–º–µ—Ä: /handoff on 77064071507",
                    )
                    return
                if action == "status":
                    enabled = await get_handoff_state(target_chat_id)
                    await send_text(
                        chat_id,
                        f"–°—Ç–∞—Ç—É—Å –¥–ª—è {target_chat_id}: {'ON' if enabled else 'OFF'}",
                    )
                    return
                if action == "on":
                    await set_handoff_state(target_chat_id, True)
                    await send_text(chat_id, f"–•—ç–Ω–¥-–æ—Ñ—Ñ –≤–∫–ª—é—á–µ–Ω –¥–ª—è {target_chat_id}")
                    return
                if action == "off":
                    await set_handoff_state(target_chat_id, False)
                    await send_text(chat_id, f"–•—ç–Ω–¥-–æ—Ñ—Ñ –≤—ã–∫–ª—é—á–µ–Ω –¥–ª—è {target_chat_id}")
                    return

        # If handoff enabled for this client, bot should not reply
        if await get_handoff_state(chat_id):
            logger.info(f"Handoff enabled for {chat_id}; bot skipped reply.")
            return

        result = await generate_response(chat_id, text, sender_name)

        # Split response by ||| and send as separate messages
        parts = [p.strip() for p in result["text"].split("|||") if p.strip()]

        # Determine if we should send photos
        should_send_photos = False
        if result["photos"]:
            is_photo_request = _is_photo_request(text)
            product_key = _build_product_key(tokenize_text(text), result["photos"])

            if is_photo_request:
                should_send_photos = True
            elif product_key and not await has_sent_product_photos(chat_id, product_key):
                should_send_photos = True

        if should_send_photos:
            # Send text BEFORE photos, then photos, then follow-up question AFTER photos
            follow_up = None
            # –û—Ç–¥–µ–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —á–∞—Å—Ç—å –∫–∞–∫ follow_up, –µ—Å–ª–∏ –æ–Ω–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –∑–Ω–∞–∫
            if parts and "?" in parts[-1]:
                follow_up = parts[-1]
                parts = parts[:-1]

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —á–∞—Å—Ç–∏ –î–û —Ñ–æ—Ç–æ
            for part in parts:
                await send_text(chat_id, part)
                if len(parts) > 1:
                    await asyncio.sleep(0.8)

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–æ—Ç–æ
            await send_multiple_images(chat_id, result["photos"])
            if product_key:
                await mark_product_photos_sent(chat_id, product_key)

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤–æ–ø—Ä–æ—Å –ü–û–°–õ–ï —Ñ–æ—Ç–æ
            if follow_up:
                await asyncio.sleep(0.8)
                await send_text(chat_id, follow_up)
        else:
            for part in parts:
                await send_text(chat_id, part)
                if len(parts) > 1:
                    await asyncio.sleep(0.8)

    except Exception as e:
        logger.error(f"Error handling message from {chat_id}: {e}", exc_info=True)
        try:
            await send_text(
                chat_id,
                "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–±–æ–ª—å—à–∞—è –æ—à–∏–±–∫–∞. –ù–∞—à –º–µ–Ω–µ–¥–∂–µ—Ä —Å–∫–æ—Ä–æ —Å –≤–∞–º–∏ —Å–≤—è–∂–µ—Ç—Å—è!",
            )
        except Exception:
            logger.error(f"Failed to send error fallback to {chat_id}", exc_info=True)

